{
  "model_type": "pytorch_interpretability_probe",
  "training_history": {
    "train_loss": [
      0.4520045003798454,
      0.42976335616416583,
      0.4260489134347602,
      0.4241779266631222,
      0.4229032148237098,
      0.4221344746343077,
      0.4215584759298525,
      0.42116488975613087,
      0.4208511077037685,
      0.4206296993445044,
      0.42042719062468775,
      0.4202196667115438,
      0.4201550014895391,
      0.42004482295006923,
      0.41991806873992155,
      0.4198576644335163,
      0.41980410309414884,
      0.419710077447434,
      0.419669062783729,
      0.41960396471361044
    ],
    "train_accuracy": [
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244,
      0.8273278630039244
    ],
    "val_loss": [
      0.4292523124001243,
      0.4262316790494052,
      0.4254172758622603,
      0.4242814844304865,
      0.4240278244018555,
      0.4238082018765536,
      0.4236607118086381,
      0.42352997172962537,
      0.42350508949973364,
      0.42347363558682527,
      0.4233990755948153,
      0.42344629114324395,
      0.4233964573253285,
      0.4233859148892489,
      0.42345785661177204,
      0.4234081441705877,
      0.42341514934193003,
      0.4234326275912198,
      0.42346630096435545,
      0.4234092018821023
    ],
    "val_accuracy": [
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022,
      0.8310502283105022
    ],
    "val_f1": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "val_auroc": [
      0.6076464379687035,
      0.6164041037087912,
      0.6241222684093778,
      0.6269479042916544,
      0.6302304971738566,
      0.6319486177884616,
      0.6327166419939858,
      0.6331536587884243,
      0.6342285446289353,
      0.6348820758000445,
      0.6348901243920775,
      0.635565771063818,
      0.6357522663675007,
      0.6362902168566231,
      0.6362354719288313,
      0.6367009125798189,
      0.6368267896588209,
      0.6372116718796406,
      0.6371945595578408,
      0.6375650848307098
    ],
    "learning_rate": [
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001
    ]
  },
  "metadata": {
    "dataset_info": {
      "total_assistant_tokens": 35038,
      "truth_tokens": 29014,
      "lie_tokens": 6024,
      "truth_ratio": 0.8280723785604202,
      "lie_ratio": 0.17192762143957988
    },
    "num_examples": 500,
    "num_assistant_tokens": 35038,
    "hidden_size": 4096,
    "config": {
      "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
      "max_length": 512,
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "hook_point": "blocks.2.hook_resid_pre",
      "hook_layer": 2,
      "device": "cuda",
      "dtype": "bfloat16",
      "batch_size": 32,
      "learning_rate": 0.001,
      "num_epochs": 20,
      "weight_decay": 0.001,
      "train_ratio": 0.8,
      "handle_class_imbalance": true,
      "optimizer_type": "AdamW",
      "scheduler_type": "cosine",
      "warmup_ratio": 0.1,
      "gradient_clip_norm": 1.0,
      "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
      "activation_batch_size": 16,
      "force_recache": false,
      "output_dir": "./ntml_4T1L_500samples_pytorch",
      "probe_name": "ntml_binary_4T1L_500samples_layer_2",
      "save_checkpoints": true,
      "checkpoint_every": 5,
      "verbose": true,
      "log_every": 10,
      "eval_every": 1,
      "ignore_system_tokens": true,
      "ignore_user_tokens": true,
      "min_tokens_per_statement": 1,
      "token_overlap_strategy": "majority",
      "probe_method": "pytorch",
      "sklearn_C": 1.0,
      "sklearn_C_sweep": false,
      "sklearn_C_values": [
        0.0001,
        0.001,
        0.01,
        0.1,
        1.0,
        10.0,
        100.0,
        1000.0,
        10000.0
      ],
      "sklearn_solver": "liblinear",
      "sklearn_max_iter": 1000,
      "pytorch_bias": true,
      "pytorch_normalize_weights": true
    },
    "training_history": {
      "train_loss": [
        0.4520045003798454,
        0.42976335616416583,
        0.4260489134347602,
        0.4241779266631222,
        0.4229032148237098,
        0.4221344746343077,
        0.4215584759298525,
        0.42116488975613087,
        0.4208511077037685,
        0.4206296993445044,
        0.42042719062468775,
        0.4202196667115438,
        0.4201550014895391,
        0.42004482295006923,
        0.41991806873992155,
        0.4198576644335163,
        0.41980410309414884,
        0.419710077447434,
        0.419669062783729,
        0.41960396471361044
      ],
      "train_accuracy": [
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244,
        0.8273278630039244
      ],
      "val_loss": [
        0.4292523124001243,
        0.4262316790494052,
        0.4254172758622603,
        0.4242814844304865,
        0.4240278244018555,
        0.4238082018765536,
        0.4236607118086381,
        0.42352997172962537,
        0.42350508949973364,
        0.42347363558682527,
        0.4233990755948153,
        0.42344629114324395,
        0.4233964573253285,
        0.4233859148892489,
        0.42345785661177204,
        0.4234081441705877,
        0.42341514934193003,
        0.4234326275912198,
        0.42346630096435545,
        0.4234092018821023
      ],
      "val_accuracy": [
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022,
        0.8310502283105022
      ],
      "val_f1": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "val_auroc": [
        0.6076464379687035,
        0.6164041037087912,
        0.6241222684093778,
        0.6269479042916544,
        0.6302304971738566,
        0.6319486177884616,
        0.6327166419939858,
        0.6331536587884243,
        0.6342285446289353,
        0.6348820758000445,
        0.6348901243920775,
        0.635565771063818,
        0.6357522663675007,
        0.6362902168566231,
        0.6362354719288313,
        0.6367009125798189,
        0.6368267896588209,
        0.6372116718796406,
        0.6371945595578408,
        0.6375650848307098
      ],
      "learning_rate": [
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001
      ]
    },
    "final_metrics": {
      "loss": 0.4234092018821023,
      "accuracy": 0.8310502283105022,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0,
      "auroc": 0.6375650848307098
    },
    "best_val_f1": 0.0,
    "training_time": 28.340617179870605,
    "num_parameters": 4097
  },
  "config": {
    "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
    "max_length": 512,
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "hook_point": "blocks.2.hook_resid_pre",
    "hook_layer": 2,
    "device": "cuda",
    "dtype": "bfloat16",
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_epochs": 20,
    "weight_decay": 0.001,
    "train_ratio": 0.8,
    "handle_class_imbalance": true,
    "optimizer_type": "AdamW",
    "scheduler_type": "cosine",
    "warmup_ratio": 0.1,
    "gradient_clip_norm": 1.0,
    "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
    "activation_batch_size": 16,
    "force_recache": false,
    "output_dir": "./ntml_4T1L_500samples_pytorch",
    "probe_name": "ntml_binary_4T1L_500samples_layer_2",
    "save_checkpoints": true,
    "checkpoint_every": 5,
    "verbose": true,
    "log_every": 10,
    "eval_every": 1,
    "ignore_system_tokens": true,
    "ignore_user_tokens": true,
    "min_tokens_per_statement": 1,
    "token_overlap_strategy": "majority",
    "probe_method": "pytorch",
    "sklearn_C": 1.0,
    "sklearn_C_sweep": false,
    "sklearn_C_values": [
      0.0001,
      0.001,
      0.01,
      0.1,
      1.0,
      10.0,
      100.0,
      1000.0,
      10000.0
    ],
    "sklearn_solver": "liblinear",
    "sklearn_max_iter": 1000,
    "pytorch_bias": true,
    "pytorch_normalize_weights": true
  }
}