{
  "model_type": "pytorch_interpretability_probe",
  "training_history": {
    "train_loss": [
      0.4325155056502721,
      0.41147486185102156,
      0.4039083106196634,
      0.3994138715746196,
      0.3965794183143742,
      0.3949745934643702,
      0.39364026833886967,
      0.3927075312085892,
      0.3920427832293184,
      0.3914317116821738,
      0.39080171970880195,
      0.390455774588672,
      0.3902157030693472,
      0.38985715670400556,
      0.38963192265872,
      0.38956447714539966,
      0.3894349386634892,
      0.38925196812169194,
      0.3890127633872642,
      0.38887706691543805
    ],
    "train_accuracy": [
      0.82739921512665,
      0.8276846236175526,
      0.828433820906172,
      0.828433820906172,
      0.8285408490902605,
      0.8288976097038887,
      0.8289332857652515,
      0.82904031394934,
      0.8290759900107029,
      0.8292900463788798,
      0.8295041027470568,
      0.8292543703175169,
      0.8294327506243311,
      0.8293970745629683,
      0.8292900463788798,
      0.8294684266856939,
      0.8295041027470568,
      0.8295041027470568,
      0.8293257224402426,
      0.8294684266856939
    ],
    "val_loss": [
      0.4158706101504239,
      0.4106271787123247,
      0.40741626132618297,
      0.4064522656527432,
      0.4052669568495317,
      0.404517108743841,
      0.4039424462751909,
      0.403864032571966,
      0.40319846760142936,
      0.4030436103994196,
      0.4031149604103782,
      0.40304101597179065,
      0.4027889641848477,
      0.4027918989008123,
      0.40298520868474785,
      0.4028366955843839,
      0.40272629911249336,
      0.40280244133689186,
      0.40267831628972833,
      0.40281200408935547
    ],
    "val_accuracy": [
      0.8307648401826484,
      0.83162100456621,
      0.831763698630137,
      0.83162100456621,
      0.83162100456621,
      0.8314783105022832,
      0.8314783105022832,
      0.83162100456621,
      0.83162100456621,
      0.831763698630137,
      0.8314783105022832,
      0.8314783105022832,
      0.8314783105022832,
      0.83162100456621,
      0.831906392694064,
      0.831763698630137,
      0.8314783105022832,
      0.83162100456621,
      0.8314783105022832,
      0.831906392694064
    ],
    "val_f1": [
      0.0,
      0.013377926421404682,
      0.015037593984962405,
      0.016666666666666666,
      0.016666666666666666,
      0.01828761429758936,
      0.01828761429758936,
      0.019933554817275746,
      0.02155887230514096,
      0.0231980115990058,
      0.021541010770505385,
      0.01991701244813278,
      0.021541010770505385,
      0.02155887230514096,
      0.026446280991735537,
      0.02481389578163772,
      0.021541010770505385,
      0.023178807947019868,
      0.021541010770505385,
      0.026446280991735537
    ],
    "val_auroc": [
      0.6782521725176874,
      0.6931223544119155,
      0.7060391386280915,
      0.708517743651892,
      0.714319210206329,
      0.7156145237318701,
      0.7167666054733368,
      0.7167695019704869,
      0.719409731535265,
      0.7205560202824316,
      0.721161750248954,
      0.7196670128946259,
      0.7216500996684669,
      0.7211885428475927,
      0.7218827608020517,
      0.721144443678482,
      0.7211766672092772,
      0.7218505372712565,
      0.7217644388934685,
      0.7225979783608492
    ],
    "learning_rate": [
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001
    ]
  },
  "metadata": {
    "dataset_info": {
      "total_assistant_tokens": 35038,
      "truth_tokens": 29014,
      "lie_tokens": 6024,
      "truth_ratio": 0.8280723785604202,
      "lie_ratio": 0.17192762143957988
    },
    "num_examples": 500,
    "num_assistant_tokens": 35038,
    "hidden_size": 4096,
    "config": {
      "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
      "max_length": 512,
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "hook_point": "blocks.5.hook_resid_pre",
      "hook_layer": 5,
      "device": "cuda",
      "dtype": "bfloat16",
      "batch_size": 32,
      "learning_rate": 0.001,
      "num_epochs": 20,
      "weight_decay": 0.001,
      "train_ratio": 0.8,
      "handle_class_imbalance": true,
      "optimizer_type": "AdamW",
      "scheduler_type": "cosine",
      "warmup_ratio": 0.1,
      "gradient_clip_norm": 1.0,
      "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
      "activation_batch_size": 16,
      "force_recache": false,
      "output_dir": "./ntml_4T1L_500samples_pytorch",
      "probe_name": "ntml_binary_4T1L_500samples_layer_5",
      "save_checkpoints": true,
      "checkpoint_every": 5,
      "verbose": true,
      "log_every": 10,
      "eval_every": 1,
      "ignore_system_tokens": true,
      "ignore_user_tokens": true,
      "min_tokens_per_statement": 1,
      "token_overlap_strategy": "majority",
      "probe_method": "pytorch",
      "sklearn_C": 1.0,
      "sklearn_C_sweep": false,
      "sklearn_C_values": [
        0.0001,
        0.001,
        0.01,
        0.1,
        1.0,
        10.0,
        100.0,
        1000.0,
        10000.0
      ],
      "sklearn_solver": "liblinear",
      "sklearn_max_iter": 1000,
      "pytorch_bias": true,
      "pytorch_normalize_weights": true
    },
    "training_history": {
      "train_loss": [
        0.4325155056502721,
        0.41147486185102156,
        0.4039083106196634,
        0.3994138715746196,
        0.3965794183143742,
        0.3949745934643702,
        0.39364026833886967,
        0.3927075312085892,
        0.3920427832293184,
        0.3914317116821738,
        0.39080171970880195,
        0.390455774588672,
        0.3902157030693472,
        0.38985715670400556,
        0.38963192265872,
        0.38956447714539966,
        0.3894349386634892,
        0.38925196812169194,
        0.3890127633872642,
        0.38887706691543805
      ],
      "train_accuracy": [
        0.82739921512665,
        0.8276846236175526,
        0.828433820906172,
        0.828433820906172,
        0.8285408490902605,
        0.8288976097038887,
        0.8289332857652515,
        0.82904031394934,
        0.8290759900107029,
        0.8292900463788798,
        0.8295041027470568,
        0.8292543703175169,
        0.8294327506243311,
        0.8293970745629683,
        0.8292900463788798,
        0.8294684266856939,
        0.8295041027470568,
        0.8295041027470568,
        0.8293257224402426,
        0.8294684266856939
      ],
      "val_loss": [
        0.4158706101504239,
        0.4106271787123247,
        0.40741626132618297,
        0.4064522656527432,
        0.4052669568495317,
        0.404517108743841,
        0.4039424462751909,
        0.403864032571966,
        0.40319846760142936,
        0.4030436103994196,
        0.4031149604103782,
        0.40304101597179065,
        0.4027889641848477,
        0.4027918989008123,
        0.40298520868474785,
        0.4028366955843839,
        0.40272629911249336,
        0.40280244133689186,
        0.40267831628972833,
        0.40281200408935547
      ],
      "val_accuracy": [
        0.8307648401826484,
        0.83162100456621,
        0.831763698630137,
        0.83162100456621,
        0.83162100456621,
        0.8314783105022832,
        0.8314783105022832,
        0.83162100456621,
        0.83162100456621,
        0.831763698630137,
        0.8314783105022832,
        0.8314783105022832,
        0.8314783105022832,
        0.83162100456621,
        0.831906392694064,
        0.831763698630137,
        0.8314783105022832,
        0.83162100456621,
        0.8314783105022832,
        0.831906392694064
      ],
      "val_f1": [
        0.0,
        0.013377926421404682,
        0.015037593984962405,
        0.016666666666666666,
        0.016666666666666666,
        0.01828761429758936,
        0.01828761429758936,
        0.019933554817275746,
        0.02155887230514096,
        0.0231980115990058,
        0.021541010770505385,
        0.01991701244813278,
        0.021541010770505385,
        0.02155887230514096,
        0.026446280991735537,
        0.02481389578163772,
        0.021541010770505385,
        0.023178807947019868,
        0.021541010770505385,
        0.026446280991735537
      ],
      "val_auroc": [
        0.6782521725176874,
        0.6931223544119155,
        0.7060391386280915,
        0.708517743651892,
        0.714319210206329,
        0.7156145237318701,
        0.7167666054733368,
        0.7167695019704869,
        0.719409731535265,
        0.7205560202824316,
        0.721161750248954,
        0.7196670128946259,
        0.7216500996684669,
        0.7211885428475927,
        0.7218827608020517,
        0.721144443678482,
        0.7211766672092772,
        0.7218505372712565,
        0.7217644388934685,
        0.7225979783608492
      ],
      "learning_rate": [
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001
      ]
    },
    "final_metrics": {
      "loss": 0.40281200408935547,
      "accuracy": 0.831906392694064,
      "precision": 0.6666666666666666,
      "recall": 0.013490725126475547,
      "f1": 0.026446280991735537,
      "auroc": 0.7225979783608492
    },
    "best_val_f1": 0.026446280991735537,
    "training_time": 29.22432780265808,
    "num_parameters": 4097
  },
  "config": {
    "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
    "max_length": 512,
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "hook_point": "blocks.5.hook_resid_pre",
    "hook_layer": 5,
    "device": "cuda",
    "dtype": "bfloat16",
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_epochs": 20,
    "weight_decay": 0.001,
    "train_ratio": 0.8,
    "handle_class_imbalance": true,
    "optimizer_type": "AdamW",
    "scheduler_type": "cosine",
    "warmup_ratio": 0.1,
    "gradient_clip_norm": 1.0,
    "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
    "activation_batch_size": 16,
    "force_recache": false,
    "output_dir": "./ntml_4T1L_500samples_pytorch",
    "probe_name": "ntml_binary_4T1L_500samples_layer_5",
    "save_checkpoints": true,
    "checkpoint_every": 5,
    "verbose": true,
    "log_every": 10,
    "eval_every": 1,
    "ignore_system_tokens": true,
    "ignore_user_tokens": true,
    "min_tokens_per_statement": 1,
    "token_overlap_strategy": "majority",
    "probe_method": "pytorch",
    "sklearn_C": 1.0,
    "sklearn_C_sweep": false,
    "sklearn_C_values": [
      0.0001,
      0.001,
      0.01,
      0.1,
      1.0,
      10.0,
      100.0,
      1000.0,
      10000.0
    ],
    "sklearn_solver": "liblinear",
    "sklearn_max_iter": 1000,
    "pytorch_bias": true,
    "pytorch_normalize_weights": true
  }
}