{
  "model_type": "pytorch_interpretability_probe",
  "training_history": {
    "train_loss": [
      0.39478055595262956,
      0.348987917853817,
      0.3325612563044513,
      0.3246770160587411,
      0.32002460272753075,
      0.3167643444995358,
      0.3149608227692238,
      0.3133799116973463,
      0.31225268508745657,
      0.3114672270539689,
      0.3107706638707962,
      0.3099844001199557,
      0.30965469114176214,
      0.309259303152289,
      0.309024944629299,
      0.3087507093061595,
      0.3082675585123502,
      0.3080978313945744,
      0.3081082158709226,
      0.30796683045554923
    ],
    "train_accuracy": [
      0.8353549768105601,
      0.84684266856939,
      0.8536211202283268,
      0.8564752051373529,
      0.8577238672850517,
      0.8596146985372815,
      0.8601855155190867,
      0.8606493043168034,
      0.8609347128077061,
      0.8617195861576882,
      0.8621120228326793,
      0.8617909382804139,
      0.8618622904031394,
      0.8620763467713164,
      0.8622904031394935,
      0.8622190510167678,
      0.8627185158758474,
      0.8628255440599358,
      0.8631466286122013,
      0.8632893328576525
    ],
    "val_loss": [
      0.3726677331057462,
      0.35250759585337205,
      0.34453518173911357,
      0.339896188269962,
      0.3367939385500821,
      0.33515898531133476,
      0.334144232489846,
      0.3329584728587757,
      0.3324280305342241,
      0.33175215937874536,
      0.3316526846452193,
      0.33113822638988494,
      0.3307158648967743,
      0.33083547760139814,
      0.33017660054293546,
      0.3298199111765081,
      0.33016523231159556,
      0.3299560546875,
      0.3295332648537376,
      0.3295236124233766
    ],
    "val_accuracy": [
      0.8356164383561644,
      0.846033105022831,
      0.8520262557077626,
      0.853310502283105,
      0.850884703196347,
      0.853167808219178,
      0.8503139269406392,
      0.8527397260273972,
      0.858019406392694,
      0.8547374429223744,
      0.8501712328767124,
      0.85587899543379,
      0.8543093607305936,
      0.8528824200913242,
      0.853310502283105,
      0.8563070776255708,
      0.855593607305936,
      0.8568778538812786,
      0.8548801369863014,
      0.8544520547945206
    ],
    "val_f1": [
      0.1165644171779141,
      0.23093371347113328,
      0.29407760381211706,
      0.2987721691678035,
      0.2748091603053435,
      0.2995234853641933,
      0.27203331020124916,
      0.29508196721311475,
      0.34236615994712494,
      0.31029810298102983,
      0.2698191933240612,
      0.32666666666666666,
      0.3049693669162696,
      0.2943189596167009,
      0.2968536251709986,
      0.32461435278336687,
      0.31805929919137466,
      0.3299933199732799,
      0.3114421123899797,
      0.3070652173913043
    ],
    "val_auroc": [
      0.8161669658632317,
      0.841256086735808,
      0.8542690103258265,
      0.8600525791878303,
      0.8664263877190446,
      0.8690194009829528,
      0.8711421368023119,
      0.872722206624297,
      0.8736246174963345,
      0.8747880100167039,
      0.875363006259022,
      0.8775272892791205,
      0.876042154101829,
      0.8763629750631716,
      0.8773051606444495,
      0.8773630147669811,
      0.8752367339646239,
      0.8766437377166338,
      0.8773542232091456,
      0.8771581856493416
    ],
    "learning_rate": [
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001
    ]
  },
  "metadata": {
    "dataset_info": {
      "total_assistant_tokens": 35038,
      "truth_tokens": 29014,
      "lie_tokens": 6024,
      "truth_ratio": 0.8280723785604202,
      "lie_ratio": 0.17192762143957988
    },
    "num_examples": 500,
    "num_assistant_tokens": 35038,
    "hidden_size": 4096,
    "config": {
      "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
      "max_length": 512,
      "model_name": "meta-llama/Llama-3.1-8B-Instruct",
      "hook_point": "blocks.9.hook_resid_pre",
      "hook_layer": 9,
      "device": "cuda",
      "dtype": "bfloat16",
      "batch_size": 32,
      "learning_rate": 0.001,
      "num_epochs": 20,
      "weight_decay": 0.001,
      "train_ratio": 0.8,
      "handle_class_imbalance": true,
      "optimizer_type": "AdamW",
      "scheduler_type": "cosine",
      "warmup_ratio": 0.1,
      "gradient_clip_norm": 1.0,
      "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
      "activation_batch_size": 16,
      "force_recache": false,
      "output_dir": "./ntml_4T1L_500samples_pytorch",
      "probe_name": "ntml_binary_4T1L_500samples_layer_9",
      "save_checkpoints": true,
      "checkpoint_every": 5,
      "verbose": true,
      "log_every": 10,
      "eval_every": 1,
      "ignore_system_tokens": true,
      "ignore_user_tokens": true,
      "min_tokens_per_statement": 1,
      "token_overlap_strategy": "majority",
      "probe_method": "pytorch",
      "sklearn_C": 1.0,
      "sklearn_C_sweep": false,
      "sklearn_C_values": [
        0.0001,
        0.001,
        0.01,
        0.1,
        1.0,
        10.0,
        100.0,
        1000.0,
        10000.0
      ],
      "sklearn_solver": "liblinear",
      "sklearn_max_iter": 1000,
      "pytorch_bias": true,
      "pytorch_normalize_weights": true
    },
    "training_history": {
      "train_loss": [
        0.39478055595262956,
        0.348987917853817,
        0.3325612563044513,
        0.3246770160587411,
        0.32002460272753075,
        0.3167643444995358,
        0.3149608227692238,
        0.3133799116973463,
        0.31225268508745657,
        0.3114672270539689,
        0.3107706638707962,
        0.3099844001199557,
        0.30965469114176214,
        0.309259303152289,
        0.309024944629299,
        0.3087507093061595,
        0.3082675585123502,
        0.3080978313945744,
        0.3081082158709226,
        0.30796683045554923
      ],
      "train_accuracy": [
        0.8353549768105601,
        0.84684266856939,
        0.8536211202283268,
        0.8564752051373529,
        0.8577238672850517,
        0.8596146985372815,
        0.8601855155190867,
        0.8606493043168034,
        0.8609347128077061,
        0.8617195861576882,
        0.8621120228326793,
        0.8617909382804139,
        0.8618622904031394,
        0.8620763467713164,
        0.8622904031394935,
        0.8622190510167678,
        0.8627185158758474,
        0.8628255440599358,
        0.8631466286122013,
        0.8632893328576525
      ],
      "val_loss": [
        0.3726677331057462,
        0.35250759585337205,
        0.34453518173911357,
        0.339896188269962,
        0.3367939385500821,
        0.33515898531133476,
        0.334144232489846,
        0.3329584728587757,
        0.3324280305342241,
        0.33175215937874536,
        0.3316526846452193,
        0.33113822638988494,
        0.3307158648967743,
        0.33083547760139814,
        0.33017660054293546,
        0.3298199111765081,
        0.33016523231159556,
        0.3299560546875,
        0.3295332648537376,
        0.3295236124233766
      ],
      "val_accuracy": [
        0.8356164383561644,
        0.846033105022831,
        0.8520262557077626,
        0.853310502283105,
        0.850884703196347,
        0.853167808219178,
        0.8503139269406392,
        0.8527397260273972,
        0.858019406392694,
        0.8547374429223744,
        0.8501712328767124,
        0.85587899543379,
        0.8543093607305936,
        0.8528824200913242,
        0.853310502283105,
        0.8563070776255708,
        0.855593607305936,
        0.8568778538812786,
        0.8548801369863014,
        0.8544520547945206
      ],
      "val_f1": [
        0.1165644171779141,
        0.23093371347113328,
        0.29407760381211706,
        0.2987721691678035,
        0.2748091603053435,
        0.2995234853641933,
        0.27203331020124916,
        0.29508196721311475,
        0.34236615994712494,
        0.31029810298102983,
        0.2698191933240612,
        0.32666666666666666,
        0.3049693669162696,
        0.2943189596167009,
        0.2968536251709986,
        0.32461435278336687,
        0.31805929919137466,
        0.3299933199732799,
        0.3114421123899797,
        0.3070652173913043
      ],
      "val_auroc": [
        0.8161669658632317,
        0.841256086735808,
        0.8542690103258265,
        0.8600525791878303,
        0.8664263877190446,
        0.8690194009829528,
        0.8711421368023119,
        0.872722206624297,
        0.8736246174963345,
        0.8747880100167039,
        0.875363006259022,
        0.8775272892791205,
        0.876042154101829,
        0.8763629750631716,
        0.8773051606444495,
        0.8773630147669811,
        0.8752367339646239,
        0.8766437377166338,
        0.8773542232091456,
        0.8771581856493416
      ],
      "learning_rate": [
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001
      ]
    },
    "final_metrics": {
      "loss": 0.3295236124233766,
      "accuracy": 0.8544520547945206,
      "precision": 0.889763779527559,
      "recall": 0.18555008210180624,
      "f1": 0.3070652173913043,
      "auroc": 0.8771581856493416
    },
    "best_val_f1": 0.34236615994712494,
    "training_time": 28.36604332923889,
    "num_parameters": 4097
  },
  "config": {
    "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
    "max_length": 512,
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "hook_point": "blocks.9.hook_resid_pre",
    "hook_layer": 9,
    "device": "cuda",
    "dtype": "bfloat16",
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_epochs": 20,
    "weight_decay": 0.001,
    "train_ratio": 0.8,
    "handle_class_imbalance": true,
    "optimizer_type": "AdamW",
    "scheduler_type": "cosine",
    "warmup_ratio": 0.1,
    "gradient_clip_norm": 1.0,
    "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.1_8B_Instruct_4T1L_500samples",
    "activation_batch_size": 16,
    "force_recache": false,
    "output_dir": "./ntml_4T1L_500samples_pytorch",
    "probe_name": "ntml_binary_4T1L_500samples_layer_9",
    "save_checkpoints": true,
    "checkpoint_every": 5,
    "verbose": true,
    "log_every": 10,
    "eval_every": 1,
    "ignore_system_tokens": true,
    "ignore_user_tokens": true,
    "min_tokens_per_statement": 1,
    "token_overlap_strategy": "majority",
    "probe_method": "pytorch",
    "sklearn_C": 1.0,
    "sklearn_C_sweep": false,
    "sklearn_C_values": [
      0.0001,
      0.001,
      0.01,
      0.1,
      1.0,
      10.0,
      100.0,
      1000.0,
      10000.0
    ],
    "sklearn_solver": "liblinear",
    "sklearn_max_iter": 1000,
    "pytorch_bias": true,
    "pytorch_normalize_weights": true
  }
}