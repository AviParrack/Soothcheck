{
  "model_type": "pytorch_interpretability_probe",
  "training_history": {
    "train_loss": [
      0.4252770096063614,
      0.39807958125251613,
      0.38844822925519723,
      0.3832869469166891,
      0.38043951246564245,
      0.3781081118267965,
      0.37677040825423586,
      0.37555026460319896
    ],
    "train_accuracy": [
      0.8271138066357474,
      0.8292186942561541,
      0.8317873706742775,
      0.8333927934356047,
      0.8340349625401355,
      0.8347841598287549,
      0.8348911880128433,
      0.8353549768105601
    ],
    "val_loss": [
      0.4030730334195224,
      0.39707987091758035,
      0.3919296091253107,
      0.38951492743058636,
      0.3883736263621937,
      0.38840196349404077,
      0.386911019411954,
      0.3866928859190507
    ],
    "val_accuracy": [
      0.8324771689497716,
      0.8351883561643836,
      0.8356164383561644,
      0.836615296803653,
      0.8370433789954338,
      0.8369006849315068,
      0.8371860730593608,
      0.8380422374429224
    ],
    "val_f1": [
      0.005084745762711864,
      0.04308202154101077,
      0.04477611940298507,
      0.05761316872427984,
      0.06239737274220033,
      0.06388206388206388,
      0.06552006552006552,
      0.07948094079480941
    ],
    "val_auroc": [
      0.7259335339913365,
      0.7382271272388066,
      0.7462603927358054,
      0.7522598067021444,
      0.7551293608838122,
      0.7551437130259314,
      0.7590756171384685,
      0.7601776722340836
    ],
    "learning_rate": [
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001,
      0.001
    ]
  },
  "metadata": {
    "layer": 11,
    "num_assistant_tokens": 35038,
    "hidden_size": 8192,
    "label_distribution": [
      29014,
      6024
    ],
    "training_history": {
      "train_loss": [
        0.4252770096063614,
        0.39807958125251613,
        0.38844822925519723,
        0.3832869469166891,
        0.38043951246564245,
        0.3781081118267965,
        0.37677040825423586,
        0.37555026460319896
      ],
      "train_accuracy": [
        0.8271138066357474,
        0.8292186942561541,
        0.8317873706742775,
        0.8333927934356047,
        0.8340349625401355,
        0.8347841598287549,
        0.8348911880128433,
        0.8353549768105601
      ],
      "val_loss": [
        0.4030730334195224,
        0.39707987091758035,
        0.3919296091253107,
        0.38951492743058636,
        0.3883736263621937,
        0.38840196349404077,
        0.386911019411954,
        0.3866928859190507
      ],
      "val_accuracy": [
        0.8324771689497716,
        0.8351883561643836,
        0.8356164383561644,
        0.836615296803653,
        0.8370433789954338,
        0.8369006849315068,
        0.8371860730593608,
        0.8380422374429224
      ],
      "val_f1": [
        0.005084745762711864,
        0.04308202154101077,
        0.04477611940298507,
        0.05761316872427984,
        0.06239737274220033,
        0.06388206388206388,
        0.06552006552006552,
        0.07948094079480941
      ],
      "val_auroc": [
        0.7259335339913365,
        0.7382271272388066,
        0.7462603927358054,
        0.7522598067021444,
        0.7551293608838122,
        0.7551437130259314,
        0.7590756171384685,
        0.7601776722340836
      ],
      "learning_rate": [
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001,
        0.001
      ]
    },
    "final_metrics": {
      "loss": 0.3866928859190507,
      "accuracy": 0.8380422374429224,
      "precision": 0.875,
      "recall": 0.041631265930331354,
      "f1": 0.07948094079480941,
      "auroc": 0.7601776722340836
    },
    "best_val_f1": 0.07948094079480941,
    "training_time": 8.430904865264893,
    "num_parameters": 8193
  },
  "config": {
    "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
    "max_length": 312,
    "model_name": "meta-llama/Llama-3.3-70B-Instruct",
    "hook_point": "blocks.11.hook_resid_pre",
    "hook_layer": 11,
    "device": "cuda",
    "dtype": "bfloat16",
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_epochs": 8,
    "weight_decay": 0.001,
    "train_ratio": 0.8,
    "handle_class_imbalance": true,
    "optimizer_type": "AdamW",
    "scheduler_type": "cosine",
    "warmup_ratio": 0.1,
    "gradient_clip_norm": 1.0,
    "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
    "activation_batch_size": 4,
    "force_recache": false,
    "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
    "probe_name": "ntml_binary_4T1L_500samples_layer_11",
    "save_checkpoints": true,
    "checkpoint_every": 5,
    "verbose": true,
    "log_every": 10,
    "eval_every": 1,
    "ignore_system_tokens": true,
    "ignore_user_tokens": true,
    "min_tokens_per_statement": 1,
    "token_overlap_strategy": "majority",
    "probe_method": "pytorch",
    "sklearn_C": 1.0,
    "sklearn_C_sweep": false,
    "sklearn_C_values": [
      0.0001,
      0.001,
      0.01,
      0.1,
      1.0,
      10.0,
      100.0,
      1000.0,
      10000.0
    ],
    "sklearn_solver": "liblinear",
    "sklearn_max_iter": 1000,
    "pytorch_bias": true,
    "pytorch_normalize_weights": true
  }
}