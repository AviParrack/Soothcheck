{
  "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
  "max_length": 312,
  "model_name": "meta-llama/Llama-3.3-70B-Instruct",
  "hook_point": "blocks.41.hook_resid_pre",
  "hook_layer": 41,
  "device": "cuda",
  "dtype": "bfloat16",
  "batch_size": 32,
  "learning_rate": 0.001,
  "num_epochs": 8,
  "weight_decay": 0.001,
  "train_ratio": 0.8,
  "handle_class_imbalance": true,
  "optimizer_type": "AdamW",
  "scheduler_type": "cosine",
  "warmup_ratio": 0.1,
  "gradient_clip_norm": 1.0,
  "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
  "activation_batch_size": 4,
  "force_recache": false,
  "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
  "probe_name": "ntml_binary_4T1L_500samples_layer_41",
  "save_checkpoints": true,
  "checkpoint_every": 5,
  "verbose": true,
  "log_every": 10,
  "eval_every": 1,
  "ignore_system_tokens": true,
  "ignore_user_tokens": true,
  "min_tokens_per_statement": 1,
  "token_overlap_strategy": "majority",
  "probe_method": "pytorch",
  "sklearn_C": 1.0,
  "sklearn_C_sweep": false,
  "sklearn_C_values": [
    0.0001,
    0.001,
    0.01,
    0.1,
    1.0,
    10.0,
    100.0,
    1000.0,
    10000.0
  ],
  "sklearn_solver": "liblinear",
  "sklearn_max_iter": 1000,
  "pytorch_bias": true,
  "pytorch_normalize_weights": true
}