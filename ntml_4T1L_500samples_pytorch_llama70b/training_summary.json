{
  "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
  "model_name": "meta-llama/Llama-3.3-70B-Instruct",
  "layers_attempted": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41,
    42,
    43,
    44,
    45,
    46,
    47,
    48,
    49,
    50,
    51,
    52,
    53,
    54,
    55,
    56,
    57,
    58,
    59,
    60,
    61,
    62,
    63,
    64,
    65,
    66,
    67,
    68,
    69,
    70,
    71,
    72,
    73,
    74,
    75,
    76,
    77,
    78,
    79
  ],
  "successful_layers": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19,
    20,
    21,
    22,
    23,
    24,
    25,
    26,
    27,
    28,
    29,
    30,
    31,
    32,
    33,
    34,
    35,
    36,
    37,
    38,
    39,
    40,
    41,
    42,
    43,
    44,
    45,
    46,
    47,
    48,
    49,
    50,
    51,
    52,
    53,
    54,
    55,
    56,
    57,
    58,
    59,
    60,
    61,
    62,
    63,
    64,
    65,
    66,
    67,
    68,
    69,
    70,
    71,
    72,
    73,
    74,
    75,
    76,
    77,
    78,
    79
  ],
  "failed_layers": [],
  "total_time": 1291.1215057373047,
  "results": {
    "0": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.0.hook_resid_pre",
        "hook_layer": 0,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_0",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.5394390379185001,
            0.49244855303470403,
            0.484764322094177,
            0.481178012544706,
            0.47911013948590786,
            0.4778710512197725,
            0.4773229027175468,
            0.47687587536633286
          ],
          "train_accuracy": [
            0.8295041027470568,
            0.8296111309311452,
            0.8296111309311452,
            0.829646806992508,
            0.829646806992508,
            0.829646806992508,
            0.829646806992508,
            0.829646806992508
          ],
          "val_loss": [
            0.5050298777493564,
            0.4945715817538175,
            0.49106081182306466,
            0.4889617226340554,
            0.48723900534889913,
            0.48677468733354046,
            0.48631342107599435,
            0.48623872236772014
          ],
          "val_accuracy": [
            0.821917808219178,
            0.821917808219178,
            0.821917808219178,
            0.821917808219178,
            0.821917808219178,
            0.821917808219178,
            0.821917808219178,
            0.821917808219178
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6025622055335166,
            0.6047902920489474,
            0.6049351980597908,
            0.6054924110870776,
            0.6076924490326863,
            0.6075000066119458,
            0.6075216520343149,
            0.6078317174897936
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.48623872236772014,
          "accuracy": 0.821917808219178,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6078317174897936
        },
        "best_val_f1": 0.0,
        "training_time": 8.598270416259766,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_0.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_0_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_0_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_0_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "1": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.1.hook_resid_pre",
        "hook_layer": 1,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_1",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4759235509998722,
            0.44342062037148977,
            0.4387059750622266,
            0.43676567836303143,
            0.4353709356289476,
            0.4344651070019426,
            0.4338884873477291,
            0.43352806870931904
          ],
          "train_accuracy": [
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538,
            0.8264359614698538
          ],
          "val_loss": [
            0.4390686728737571,
            0.43227698586203833,
            0.4302438909357244,
            0.42931324351917616,
            0.4285634821111506,
            0.42806230024857955,
            0.4280283841219815,
            0.4277831337668679
          ],
          "val_accuracy": [
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758,
            0.8346175799086758
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.603162402782361,
            0.6093097040547775,
            0.6103965914691435,
            0.6104114904415716,
            0.6105315673084681,
            0.6102817513697835,
            0.6105096613935614,
            0.6105979488687918
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.4277831337668679,
          "accuracy": 0.8346175799086758,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6105979488687918
        },
        "best_val_f1": 0.0,
        "training_time": 8.066400289535522,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_1.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_1_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_1_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_1_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "2": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.2.hook_resid_pre",
        "hook_layer": 2,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_2",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4643074107020413,
            0.4360835413750448,
            0.43230751946092194,
            0.4303187946682651,
            0.4290098582296611,
            0.42832628076207147,
            0.427815320931341,
            0.4274602010505929
          ],
          "train_accuracy": [
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987,
            0.8272565108811987
          ],
          "val_loss": [
            0.43182823874733667,
            0.42765520269220525,
            0.4264828768643466,
            0.4252547524192116,
            0.42511055686257104,
            0.42492568276145243,
            0.4247901916503906,
            0.4247552351518111
          ],
          "val_accuracy": [
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562,
            0.8313356164383562
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.627676969393866,
            0.6330982154215045,
            0.6349347519114676,
            0.6365058350367075,
            0.6367914733126431,
            0.6369607942225266,
            0.6378124813035445,
            0.6380118617574639
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.4247552351518111,
          "accuracy": 0.8313356164383562,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6380118617574639
        },
        "best_val_f1": 0.0,
        "training_time": 8.59725546836853,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_2.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_2_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_2_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_2_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "3": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.3.hook_resid_pre",
        "hook_layer": 3,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_3",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.45352835592613916,
            0.42792981873228125,
            0.4240972533754018,
            0.4221507132257501,
            0.42064130020468204,
            0.4197061739215568,
            0.4190803278390675,
            0.41859083830221605
          ],
          "train_accuracy": [
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683,
            0.8293970745629683
          ],
          "val_loss": [
            0.44342845569957384,
            0.4402050365101207,
            0.4390681873668324,
            0.4384861686012962,
            0.4378272663463246,
            0.4375652313232422,
            0.4374938271262429,
            0.4373206398703835
          ],
          "val_accuracy": [
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398,
            0.8227739726027398
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6161729903152636,
            0.6249754935227496,
            0.6297561417002218,
            0.6328826375728003,
            0.6347516230130203,
            0.6362249440470346,
            0.636632687144307,
            0.6380361193357921
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.4373206398703835,
          "accuracy": 0.8227739726027398,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6380361193357921
        },
        "best_val_f1": 0.0,
        "training_time": 8.452784538269043,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_3.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_3_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_3_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_3_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "4": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.4.hook_resid_pre",
        "hook_layer": 4,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_4",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4492677096702737,
            0.42713837475265,
            0.4227756689128266,
            0.4204582847552757,
            0.4188848007895631,
            0.417852814849381,
            0.41709183619174783,
            0.41669215170079715
          ],
          "train_accuracy": [
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385,
            0.8275062433107385
          ],
          "val_loss": [
            0.42907128767533737,
            0.4252071033824574,
            0.4243131464177912,
            0.4233312260020863,
            0.4230540015480735,
            0.42285315773703835,
            0.4225846030495384,
            0.42241783142089845
          ],
          "val_accuracy": [
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676,
            0.8303367579908676
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6208215423764065,
            0.6371603073427135,
            0.6410218924086593,
            0.6450634944746849,
            0.6466572700346058,
            0.6477293504024041,
            0.6492603982400971,
            0.6505658286252612
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.42241783142089845,
          "accuracy": 0.8303367579908676,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6505658286252612
        },
        "best_val_f1": 0.0,
        "training_time": 8.32291293144226,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_4.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_4_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_4_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_4_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "5": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.5.hook_resid_pre",
        "hook_layer": 5,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_5",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4466138419155116,
            0.423472114791881,
            0.41849574521524174,
            0.41578418843141973,
            0.4140363824149789,
            0.4129279794418104,
            0.4120832028454297,
            0.4116683048472557
          ],
          "train_accuracy": [
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605,
            0.8285408490902605
          ],
          "val_loss": [
            0.4329375527121804,
            0.4293162085793235,
            0.4277518705888228,
            0.42718570015647195,
            0.42647571563720704,
            0.4261205499822443,
            0.4260262749411843,
            0.425697153264826
          ],
          "val_accuracy": [
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864,
            0.8261986301369864
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6377632149876209,
            0.6547952985017484,
            0.6603353270317716,
            0.6652751899401891,
            0.6672474766811018,
            0.6687931601680039,
            0.6704023697502347,
            0.6712815255338036
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.425697153264826,
          "accuracy": 0.8261986301369864,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6712815255338036
        },
        "best_val_f1": 0.0,
        "training_time": 8.356191873550415,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_5.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_5_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_5_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_5_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "6": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.6.hook_resid_pre",
        "hook_layer": 6,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_6",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.44396793651798544,
            0.422467837935169,
            0.417151282231013,
            0.4139292740930705,
            0.41215952261261746,
            0.41088233343814606,
            0.4100695031792878,
            0.4093933790649998
          ],
          "train_accuracy": [
            0.8268997502675705,
            0.8268997502675705,
            0.8268997502675705,
            0.8269354263289332,
            0.8269711023902961,
            0.8270424545130217,
            0.8269711023902961,
            0.8270067784516589
          ],
          "val_loss": [
            0.42363000349564983,
            0.42100479819557884,
            0.4177598693154075,
            0.4168027574365789,
            0.4163781252774325,
            0.4157890276475386,
            0.4155517664822665,
            0.4154969735579057
          ],
          "val_accuracy": [
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256,
            0.8327625570776256
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6287374674551507,
            0.650676146292168,
            0.6615916829049773,
            0.6678535692313451,
            0.6680953163488013,
            0.6706967112450203,
            0.673037864309324,
            0.6747208833251069
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.4154969735579057,
          "accuracy": 0.8327625570776256,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6747208833251069
        },
        "best_val_f1": 0.0,
        "training_time": 8.331340551376343,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_6.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_6_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_6_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_6_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "7": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.7.hook_resid_pre",
        "hook_layer": 7,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_7",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4407227845632867,
            0.41762594300317984,
            0.4113890929785493,
            0.4082352456436854,
            0.4060428734851754,
            0.4045153926360553,
            0.4036119457793562,
            0.40293922251490155
          ],
          "train_accuracy": [
            0.8282911166607206,
            0.8282911166607206,
            0.8283624687834463,
            0.8283267927220834,
            0.8284694969675348,
            0.8284694969675348,
            0.8285051730288976,
            0.8285408490902605
          ],
          "val_loss": [
            0.4280027519572865,
            0.42394716956398704,
            0.42333017696033826,
            0.4205036510120739,
            0.4201833811673251,
            0.4196766289797696,
            0.41931454051624645,
            0.419267259944569
          ],
          "val_accuracy": [
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748,
            0.8271974885844748
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
          ],
          "val_auroc": [
            0.6620592501574392,
            0.6781805190674239,
            0.6852220894460204,
            0.6882490117400342,
            0.6891083217820887,
            0.6907092096242154,
            0.691751634968228,
            0.6923629452119872
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.419267259944569,
          "accuracy": 0.8271974885844748,
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0,
          "auroc": 0.6923629452119872
        },
        "best_val_f1": 0.0,
        "training_time": 8.55807089805603,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_7.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_7_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_7_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_7_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "8": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.8.hook_resid_pre",
        "hook_layer": 8,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_8",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4375182747092421,
            0.4173338484682449,
            0.41059410435968335,
            0.40718558900160334,
            0.40479460178308835,
            0.4030885129622673,
            0.40201520579590644,
            0.40132370206727286
          ],
          "train_accuracy": [
            0.8267570460221192,
            0.8267570460221192,
            0.8267570460221192,
            0.826792722083482,
            0.8268997502675705,
            0.8269354263289332,
            0.8270067784516589,
            0.8271138066357474
          ],
          "val_loss": [
            0.41536625948819245,
            0.4112749446522106,
            0.40908075245943937,
            0.40736539147116924,
            0.40870531689036976,
            0.4065727103840221,
            0.40616408694874157,
            0.40597484328530054
          ],
          "val_accuracy": [
            0.8333333333333334,
            0.8333333333333334,
            0.8333333333333334,
            0.8334760273972602,
            0.8334760273972602,
            0.8334760273972602,
            0.8334760273972602,
            0.8334760273972602
          ],
          "val_f1": [
            0.0,
            0.0,
            0.0,
            0.0034158838599487617,
            0.0034158838599487617,
            0.0034158838599487617,
            0.0034158838599487617,
            0.0034158838599487617
          ],
          "val_auroc": [
            0.6672846248123474,
            0.6839714005911053,
            0.6954673132857947,
            0.6994232618690186,
            0.7001773169215613,
            0.7026362239632201,
            0.7042826544614373,
            0.7057151171655095
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.40597484328530054,
          "accuracy": 0.8334760273972602,
          "precision": 0.6666666666666666,
          "recall": 0.0017123287671232876,
          "f1": 0.0034158838599487617,
          "auroc": 0.7057151171655095
        },
        "best_val_f1": 0.0034158838599487617,
        "training_time": 8.349170446395874,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_8.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_8_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_8_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_8_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "9": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.9.hook_resid_pre",
        "hook_layer": 9,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_9",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4320168128092539,
            0.4108277879417215,
            0.40325337910352776,
            0.3989941458043442,
            0.3963626880011602,
            0.39472742848200343,
            0.39352199680184663,
            0.3926941128149969
          ],
          "train_accuracy": [
            0.827791651801641,
            0.827791651801641,
            0.8279700321084552,
            0.828219764537995,
            0.8284694969675348,
            0.828433820906172,
            0.828826257581163,
            0.8288619336425259
          ],
          "val_loss": [
            0.41530795097351075,
            0.4089077819477428,
            0.40511787154457785,
            0.4037409002130682,
            0.4024818810549649,
            0.4018963466991078,
            0.40155341625213625,
            0.40102428089488634
          ],
          "val_accuracy": [
            0.829195205479452,
            0.829195205479452,
            0.829337899543379,
            0.829337899543379,
            0.8299086757990868,
            0.8299086757990868,
            0.8299086757990868,
            0.8299086757990868
          ],
          "val_f1": [
            0.0,
            0.0,
            0.001669449081803005,
            0.001669449081803005,
            0.008319467554076539,
            0.008319467554076539,
            0.008319467554076539,
            0.008319467554076539
          ],
          "val_auroc": [
            0.7024484862704573,
            0.7217978261779039,
            0.7324377024129761,
            0.7347828068421498,
            0.7398037484579343,
            0.739568979236941,
            0.742429267685361,
            0.743495792771667
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.40102428089488634,
          "accuracy": 0.8299086757990868,
          "precision": 1.0,
          "recall": 0.004177109440267335,
          "f1": 0.008319467554076539,
          "auroc": 0.743495792771667
        },
        "best_val_f1": 0.008319467554076539,
        "training_time": 8.578200101852417,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_9.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_9_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_9_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_9_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "10": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.10.hook_resid_pre",
        "hook_layer": 10,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_10",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.42911652397347366,
            0.40626302485664684,
            0.3977179195238575,
            0.3930441591565467,
            0.39011797710368623,
            0.38818947855196045,
            0.3869207706727666,
            0.38575658586607675
          ],
          "train_accuracy": [
            0.8287905815198002,
            0.8288619336425259,
            0.8292543703175169,
            0.8299322154834107,
            0.8298965394220478,
            0.8301105957902247,
            0.830467356403853,
            0.8305030324652158
          ],
          "val_loss": [
            0.41756851889870383,
            0.410604849728671,
            0.4060505390167236,
            0.4049843831495805,
            0.40362973646684125,
            0.4021340240131725,
            0.4013689908114347,
            0.4010011510415511
          ],
          "val_accuracy": [
            0.8251997716894978,
            0.8253424657534246,
            0.8263413242009132,
            0.8266267123287672,
            0.8261986301369864,
            0.8266267123287672,
            0.8264840182648402,
            0.8274828767123288
          ],
          "val_f1": [
            0.0,
            0.0016313213703099511,
            0.012976480129764802,
            0.016194331983805668,
            0.011363636363636364,
            0.016194331983805668,
            0.014586709886547812,
            0.02891566265060241
          ],
          "val_auroc": [
            0.7148645396252916,
            0.7344513651907244,
            0.743216394287267,
            0.7471887693344673,
            0.7515612615442165,
            0.7543066059209436,
            0.7575715591441488,
            0.7572700420302998
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.4010011510415511,
          "accuracy": 0.8274828767123288,
          "precision": 0.9,
          "recall": 0.014693877551020407,
          "f1": 0.02891566265060241,
          "auroc": 0.7572700420302998
        },
        "best_val_f1": 0.02891566265060241,
        "training_time": 8.527951002120972,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_10.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_10_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_10_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_10_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "11": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.11.hook_resid_pre",
        "hook_layer": 11,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_11",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4252770096063614,
            0.39807958125251613,
            0.38844822925519723,
            0.3832869469166891,
            0.38043951246564245,
            0.3781081118267965,
            0.37677040825423586,
            0.37555026460319896
          ],
          "train_accuracy": [
            0.8271138066357474,
            0.8292186942561541,
            0.8317873706742775,
            0.8333927934356047,
            0.8340349625401355,
            0.8347841598287549,
            0.8348911880128433,
            0.8353549768105601
          ],
          "val_loss": [
            0.4030730334195224,
            0.39707987091758035,
            0.3919296091253107,
            0.38951492743058636,
            0.3883736263621937,
            0.38840196349404077,
            0.386911019411954,
            0.3866928859190507
          ],
          "val_accuracy": [
            0.8324771689497716,
            0.8351883561643836,
            0.8356164383561644,
            0.836615296803653,
            0.8370433789954338,
            0.8369006849315068,
            0.8371860730593608,
            0.8380422374429224
          ],
          "val_f1": [
            0.005084745762711864,
            0.04308202154101077,
            0.04477611940298507,
            0.05761316872427984,
            0.06239737274220033,
            0.06388206388206388,
            0.06552006552006552,
            0.07948094079480941
          ],
          "val_auroc": [
            0.7259335339913365,
            0.7382271272388066,
            0.7462603927358054,
            0.7522598067021444,
            0.7551293608838122,
            0.7551437130259314,
            0.7590756171384685,
            0.7601776722340836
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.3866928859190507,
          "accuracy": 0.8380422374429224,
          "precision": 0.875,
          "recall": 0.041631265930331354,
          "f1": 0.07948094079480941,
          "auroc": 0.7601776722340836
        },
        "best_val_f1": 0.07948094079480941,
        "training_time": 8.430904865264893,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_11.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_11_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_11_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_11_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "12": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.12.hook_resid_pre",
        "hook_layer": 12,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_12",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4200017248454704,
            0.39404092875381586,
            0.38374558567456457,
            0.3777716180233106,
            0.3743020688698172,
            0.3718057165271071,
            0.3702958593629811,
            0.3690519769033885
          ],
          "train_accuracy": [
            0.8279343560470924,
            0.8305743845879415,
            0.8344987513378523,
            0.8354976810560114,
            0.8373528362468784,
            0.8376382447377809,
            0.8378523011059579,
            0.8380663574741348
          ],
          "val_loss": [
            0.4037926890633323,
            0.3943934830752286,
            0.3920978687026284,
            0.38911163752729244,
            0.3871777881275524,
            0.3863672343167392,
            0.3860734159296209,
            0.38649260347539727
          ],
          "val_accuracy": [
            0.8310502283105022,
            0.8344748858447488,
            0.836615296803653,
            0.8359018264840182,
            0.8356164383561644,
            0.8361872146118722,
            0.8361872146118722,
            0.836472602739726
          ],
          "val_f1": [
            0.019867549668874173,
            0.059967585089141004,
            0.10054988216810684,
            0.08585055643879173,
            0.07692307692307693,
            0.08744038155802862,
            0.09606299212598425,
            0.09047619047619047
          ],
          "val_auroc": [
            0.7274476230702479,
            0.7439339551199571,
            0.7571724801874566,
            0.7558212653096925,
            0.7642842510133572,
            0.7651318083678791,
            0.7655652617005066,
            0.7637533318218332
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.38649260347539727,
          "accuracy": 0.836472602739726,
          "precision": 0.890625,
          "recall": 0.047658862876254184,
          "f1": 0.09047619047619047,
          "auroc": 0.7637533318218332
        },
        "best_val_f1": 0.10054988216810684,
        "training_time": 8.292735576629639,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_12.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_12_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_12_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_12_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "13": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.13.hook_resid_pre",
        "hook_layer": 13,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_13",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.4123747666200546,
            0.38027455164417284,
            0.36786645365087955,
            0.3611949298479786,
            0.3572262488475673,
            0.35404167508017526,
            0.3522915492114955,
            0.35078820177953535
          ],
          "train_accuracy": [
            0.8303960042811274,
            0.8369960756332501,
            0.8399571887263646,
            0.8412772029967892,
            0.8421691045308598,
            0.8435247948626472,
            0.8442026400285408,
            0.8444523724580806
          ],
          "val_loss": [
            0.4039511978626251,
            0.39190062176097523,
            0.38671393394470216,
            0.38269127932461827,
            0.38066639412533154,
            0.3802166841246865,
            0.3783352277495644,
            0.3774465344168923
          ],
          "val_accuracy": [
            0.8281963470319634,
            0.8301940639269406,
            0.8303367579908676,
            0.8311929223744292,
            0.831763698630137,
            0.8334760273972602,
            0.8333333333333334,
            0.8330479452054794
          ],
          "val_f1": [
            0.05642633228840126,
            0.080370942812983,
            0.09167303284950344,
            0.10310841546626232,
            0.11018867924528301,
            0.14505494505494507,
            0.13864306784660768,
            0.12816691505216096
          ],
          "val_auroc": [
            0.7465419632739144,
            0.7734237985439076,
            0.7866353046192034,
            0.7934046670953699,
            0.7993636060096412,
            0.8015313871550886,
            0.8047286746321546,
            0.8050674167850846
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.3774465344168923,
          "accuracy": 0.8330479452054794,
          "precision": 0.7818181818181819,
          "recall": 0.0698051948051948,
          "f1": 0.12816691505216096,
          "auroc": 0.8050674167850846
        },
        "best_val_f1": 0.14505494505494507,
        "training_time": 8.361016273498535,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_13.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_13_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_13_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_13_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "14": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.14.hook_resid_pre",
        "hook_layer": 14,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_14",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.3985378742898436,
            0.3556648992920575,
            0.34028357318411134,
            0.3316376720933609,
            0.32694137048775745,
            0.32353017183199323,
            0.3216641115101233,
            0.3201332344720353
          ],
          "train_accuracy": [
            0.8332500891901534,
            0.8436674991080985,
            0.8498394577238673,
            0.8525865144488048,
            0.8546914020692116,
            0.8558687120941848,
            0.8572244024259722,
            0.8571887263646093
          ],
          "val_loss": [
            0.37491321997209026,
            0.3594813368537209,
            0.34937529130415484,
            0.3458565820347179,
            0.34109065207568084,
            0.3397630290551619,
            0.33854787999933417,
            0.339284119551832
          ],
          "val_accuracy": [
            0.8370433789954338,
            0.8397545662100456,
            0.8417522831050228,
            0.843607305936073,
            0.848744292237443,
            0.8496004566210046,
            0.848744292237443,
            0.8450342465753424
          ],
          "val_f1": [
            0.12153846153846154,
            0.15500376222723852,
            0.1742367833209233,
            0.19765739385065886,
            0.24822695035460993,
            0.2577464788732394,
            0.24393723252496433,
            0.20381231671554254
          ],
          "val_auroc": [
            0.812847135644765,
            0.838640007558434,
            0.8538438970262819,
            0.8599307096190307,
            0.8654075906852247,
            0.8686341327229756,
            0.871088208487752,
            0.8717010525687664
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.339284119551832,
          "accuracy": 0.8450342465753424,
          "precision": 0.9328859060402684,
          "recall": 0.11440329218106995,
          "f1": 0.20381231671554254,
          "auroc": 0.8717010525687664
        },
        "best_val_f1": 0.2577464788732394,
        "training_time": 8.008383750915527,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_14.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_14_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_14_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_14_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "15": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.15.hook_resid_pre",
        "hook_layer": 15,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_15",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.39545429140737615,
            0.3501230871908741,
            0.33321766276337783,
            0.3245336692695204,
            0.31938779663685796,
            0.315923517289227,
            0.3136481760095244,
            0.3121420092472475
          ],
          "train_accuracy": [
            0.8341776667855869,
            0.8472707813057438,
            0.8535140920442383,
            0.8574027827327863,
            0.8582590082054942,
            0.8597574027827328,
            0.8607206564395291,
            0.8616839100963254
          ],
          "val_loss": [
            0.3627728042277423,
            0.3454835138537667,
            0.33913415562022814,
            0.3336112239144065,
            0.3306840549815785,
            0.32949389544400304,
            0.3277176770296964,
            0.32691696557131683
          ],
          "val_accuracy": [
            0.8441780821917808,
            0.8514554794520548,
            0.8567351598173516,
            0.8545947488584474,
            0.858304794520548,
            0.858304794520548,
            0.860587899543379,
            0.8620148401826484
          ],
          "val_f1": [
            0.15348837209302327,
            0.23173431734317343,
            0.2849002849002849,
            0.2578295702840495,
            0.3011963406052076,
            0.3021784961349262,
            0.3191637630662021,
            0.3335630599586492
          ],
          "val_auroc": [
            0.8158266428190495,
            0.8406243673790719,
            0.8468866161900166,
            0.8584123436814094,
            0.862313605839522,
            0.8640205486161248,
            0.8671456506517583,
            0.8693410584133595
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.32691696557131683,
          "accuracy": 0.8620148401826484,
          "precision": 0.9029850746268657,
          "recall": 0.20456466610312765,
          "f1": 0.3335630599586492,
          "auroc": 0.8693410584133595
        },
        "best_val_f1": 0.3335630599586492,
        "training_time": 8.024639129638672,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_15.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_15_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_15_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_15_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "16": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.16.hook_resid_pre",
        "hook_layer": 16,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_16",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.3651319064506113,
            0.3052194675762359,
            0.28511359147965637,
            0.27523312272002165,
            0.26979818230826563,
            0.2665303512625226,
            0.2642655448826481,
            0.2624920418817703
          ],
          "train_accuracy": [
            0.844595076703532,
            0.8668569389939351,
            0.8746343203710311,
            0.8798787013913664,
            0.8829825187299322,
            0.885265786657153,
            0.8864430966821263,
            0.8868712094184802
          ],
          "val_loss": [
            0.3330090566114946,
            0.30540725968100807,
            0.2945250316099687,
            0.2895465027202259,
            0.286031081459739,
            0.2841439973224293,
            0.2831054774197665,
            0.2814874887466431
          ],
          "val_accuracy": [
            0.8477454337899544,
            0.8645833333333334,
            0.8687214611872146,
            0.8710045662100456,
            0.874857305936073,
            0.8742865296803652,
            0.8715753424657534,
            0.8777111872146118
          ],
          "val_f1": [
            0.2805124747134187,
            0.4152803450400493,
            0.4397076735688185,
            0.44945188794153473,
            0.47828673408685307,
            0.4752829064919595,
            0.45454545454545453,
            0.5002915451895044
          ],
          "val_auroc": [
            0.8837836371527779,
            0.9133475366141383,
            0.9253609942574785,
            0.9285299534811254,
            0.9313586460559118,
            0.9339363119880697,
            0.9356183782941596,
            0.9367375996038105
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.2814874887466431,
          "accuracy": 0.8777111872146118,
          "precision": 0.9186295503211992,
          "recall": 0.34375,
          "f1": 0.5002915451895044,
          "auroc": 0.9367375996038105
        },
        "best_val_f1": 0.5002915451895044,
        "training_time": 8.659043550491333,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_16.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_16_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_16_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_16_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "17": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.17.hook_resid_pre",
        "hook_layer": 17,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_17",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.3117829178158007,
            0.23330107549009801,
            0.21426210171419735,
            0.20543058092395464,
            0.20062497251382158,
            0.19762535723240954,
            0.19569514540436606,
            0.193874389647621
          ],
          "train_accuracy": [
            0.8681412772029968,
            0.9035676061362825,
            0.9128077060292543,
            0.916767748840528,
            0.9194077773813771,
            0.9201926507313593,
            0.922083481983589,
            0.9227256510881199
          ],
          "val_loss": [
            0.25396950244903566,
            0.2261007850820368,
            0.2151062380183827,
            0.21026230237700722,
            0.20747961781241678,
            0.20564419356259434,
            0.20443330678072844,
            0.20338325066999954
          ],
          "val_accuracy": [
            0.896546803652968,
            0.9101027397260274,
            0.9078196347031964,
            0.911101598173516,
            0.9146689497716894,
            0.9128139269406392,
            0.9125285388127854,
            0.9149543378995434
          ],
          "val_f1": [
            0.5835726593911545,
            0.658351409978308,
            0.6419068736141907,
            0.6593767085839256,
            0.677801724137931,
            0.66811515480717,
            0.6655755591925805,
            0.6788793103448276
          ],
          "val_auroc": [
            0.9512014541389101,
            0.9661758743135879,
            0.9719702356834458,
            0.9734447122007219,
            0.9742018738876979,
            0.9752723118474987,
            0.975454122057349,
            0.9760460406863541
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.20338325066999954,
          "accuracy": 0.9149543378995434,
          "precision": 0.9707241910631741,
          "recall": 0.5219552609776305,
          "f1": 0.6788793103448276,
          "auroc": 0.9760460406863541
        },
        "best_val_f1": 0.6788793103448276,
        "training_time": 8.609800815582275,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_17.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_17_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_17_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_17_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "18": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.18.hook_resid_pre",
        "hook_layer": 18,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_18",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.3022881962324931,
            0.22054212616935168,
            0.1997714248490116,
            0.1906504245415398,
            0.185781045064126,
            0.18272679712470263,
            0.1807687976078628,
            0.17927567267866984
          ],
          "train_accuracy": [
            0.8720299678915447,
            0.9091330717088834,
            0.9196218337495541,
            0.9257224402425972,
            0.9272565108811988,
            0.9292543703175169,
            0.930467356403853,
            0.9311452015697467
          ],
          "val_loss": [
            0.2471849571574818,
            0.21844320080497048,
            0.2078338839791038,
            0.20236919142983176,
            0.19909300587394022,
            0.19742837819186124,
            0.19589989998123863,
            0.19441360953179274
          ],
          "val_accuracy": [
            0.8908390410958904,
            0.90625,
            0.9239440639269406,
            0.916095890410959,
            0.9155251141552512,
            0.9185216894977168,
            0.9185216894977168,
            0.9202340182648402
          ],
          "val_f1": [
            0.574763757643135,
            0.6554798112218144,
            0.7423876268728854,
            0.7045226130653266,
            0.6997971602434077,
            0.7149276085871193,
            0.71407110665999,
            0.7220288413724515
          ],
          "val_auroc": [
            0.9593735468460388,
            0.9711854626078535,
            0.9753615207538676,
            0.9769616997039854,
            0.978129013204236,
            0.9786474797927855,
            0.9790098787740695,
            0.9797901473853053
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.19441360953179274,
          "accuracy": 0.9202340182648402,
          "precision": 0.9552631578947368,
          "recall": 0.580335731414868,
          "f1": 0.7220288413724515,
          "auroc": 0.9797901473853053
        },
        "best_val_f1": 0.7423876268728854,
        "training_time": 8.693711519241333,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_18.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_18_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_18_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_18_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "19": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.19.hook_resid_pre",
        "hook_layer": 19,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_19",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.2931443816858884,
            0.20696082381216901,
            0.18614486839673292,
            0.17740303728746498,
            0.17261377676096681,
            0.16940269270512068,
            0.1674341808102991,
            0.16614968096624771
          ],
          "train_accuracy": [
            0.8749910809846593,
            0.9178737067427756,
            0.9284694969675348,
            0.9331073849447021,
            0.9352479486264716,
            0.9378166250445951,
            0.939885836603639,
            0.9405993578308954
          ],
          "val_loss": [
            0.2237474801865491,
            0.19459713155573063,
            0.18466663143851542,
            0.17963776588439942,
            0.17674368023872375,
            0.17535336992957376,
            0.17407924912192604,
            0.1730127220804041
          ],
          "val_accuracy": [
            0.9129566210045662,
            0.9218036529680366,
            0.930079908675799,
            0.932505707762557,
            0.9357876712328768,
            0.9375,
            0.9333618721461188,
            0.9345034246575342
          ],
          "val_f1": [
            0.6640969162995595,
            0.71005291005291,
            0.7482014388489209,
            0.7587965323814381,
            0.7727272727272727,
            0.7812187812187812,
            0.762582613116421,
            0.7659357470678225
          ],
          "val_auroc": [
            0.9683339266591582,
            0.9792079446424121,
            0.9819585435456921,
            0.983266985658632,
            0.9836090615566407,
            0.9843695908302023,
            0.9845928813594527,
            0.9845639603316009
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.1730127220804041,
          "accuracy": 0.9345034246575342,
          "precision": 0.976592977893368,
          "recall": 0.6300335570469798,
          "f1": 0.7659357470678225,
          "auroc": 0.9845639603316009
        },
        "best_val_f1": 0.7812187812187812,
        "training_time": 8.630013704299927,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_19.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_19_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_19_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_19_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "20": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.20.hook_resid_pre",
        "hook_layer": 20,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_20",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.23341760699335298,
            0.1497797513099974,
            0.13254511487334286,
            0.12473384476347602,
            0.12057322746814658,
            0.11822576827654556,
            0.11670215875250564,
            0.11546138996368946
          ],
          "train_accuracy": [
            0.905529789511238,
            0.9479486264716376,
            0.9574027827327863,
            0.9610417409917945,
            0.9636104174099179,
            0.9651801641098823,
            0.9658223332144131,
            0.9663574741348555
          ],
          "val_loss": [
            0.16543817953629927,
            0.1416723595424132,
            0.13226881460710005,
            0.12900624708695846,
            0.12630814855748956,
            0.12450125217437744,
            0.1234925768592141,
            0.12279311526905407
          ],
          "val_accuracy": [
            0.9407819634703196,
            0.9487728310502284,
            0.9563356164383562,
            0.9607591324200914,
            0.9606164383561644,
            0.9594748858447488,
            0.9586187214611872,
            0.96175799086758
          ],
          "val_f1": [
            0.790509843513377,
            0.823065549531789,
            0.8533077660594439,
            0.8705882352941177,
            0.8696883852691218,
            0.8646329837940896,
            0.861376673040153,
            0.8733459357277883
          ],
          "val_auroc": [
            0.9856126601752806,
            0.9900480023610352,
            0.9921689162979376,
            0.9920836648060364,
            0.9923606773658384,
            0.9928821944186936,
            0.993057372719961,
            0.9932675428503803
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.12279311526905407,
          "accuracy": 0.96175799086758,
          "precision": 0.9798515376458112,
          "recall": 0.7877237851662404,
          "f1": 0.8733459357277883,
          "auroc": 0.9932675428503803
        },
        "best_val_f1": 0.8733459357277883,
        "training_time": 8.61574649810791,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_20.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_20_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_20_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_20_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "21": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.21.hook_resid_pre",
        "hook_layer": 21,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_21",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.22842725665738048,
            0.14441252454741088,
            0.12671506215210102,
            0.11948288238892273,
            0.1154649177540655,
            0.11303334727407047,
            0.1113854037878448,
            0.11012156222645006
          ],
          "train_accuracy": [
            0.9072065643952908,
            0.9500178380306814,
            0.9584017124509454,
            0.9622190510167677,
            0.9644666428826257,
            0.9662147698894042,
            0.9674277559757403,
            0.9676418123439172
          ],
          "val_loss": [
            0.1671745473688299,
            0.14183464050292968,
            0.13290018168362705,
            0.12892068949612703,
            0.12615186951377175,
            0.12490096742456609,
            0.12348290790211071,
            0.12285504341125489
          ],
          "val_accuracy": [
            0.9442066210045662,
            0.9530536529680366,
            0.9546232876712328,
            0.9537671232876712,
            0.9599029680365296,
            0.963755707762557,
            0.9594748858447488,
            0.9620433789954338
          ],
          "val_f1": [
            0.814075130765573,
            0.8466200466200466,
            0.8509840674789129,
            0.8470254957507082,
            0.8706856879889554,
            0.884963768115942,
            0.8688827331486612,
            0.8792007266121707
          ],
          "val_auroc": [
            0.9840698265462045,
            0.9896567414668813,
            0.9915951696469211,
            0.9919912816791437,
            0.9925065058205689,
            0.9929452497048261,
            0.9930465806898134,
            0.9932277482084267
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.12285504341125489,
          "accuracy": 0.9620433789954338,
          "precision": 0.9728643216080402,
          "recall": 0.8019884009942005,
          "f1": 0.8792007266121707,
          "auroc": 0.9932277482084267
        },
        "best_val_f1": 0.884963768115942,
        "training_time": 8.659993410110474,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_21.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_21_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_21_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_21_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "22": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.22.hook_resid_pre",
        "hook_layer": 22,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_22",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.2296308756521031,
            0.14520462182218627,
            0.12790669963512247,
            0.11987383457827785,
            0.11556699897532594,
            0.11295935397618982,
            0.11129735144850327,
            0.11004310552898335
          ],
          "train_accuracy": [
            0.9061719586157688,
            0.9495540492329647,
            0.9587227970032108,
            0.9635390652871922,
            0.9654655726007849,
            0.9667142347484837,
            0.9676418123439172,
            0.9682126293257224
          ],
          "val_loss": [
            0.16526913724162362,
            0.1412052804773504,
            0.1316626028581099,
            0.12755084037780762,
            0.12475861202586781,
            0.1232557329264554,
            0.12213354977694425,
            0.12157607078552246
          ],
          "val_accuracy": [
            0.9356449771689498,
            0.9477739726027398,
            0.956763698630137,
            0.9570490867579908,
            0.9571917808219178,
            0.9599029680365296,
            0.9604737442922374,
            0.96175799086758
          ],
          "val_f1": [
            0.7820202996616723,
            0.8299256505576208,
            0.8640646029609691,
            0.8641083521444696,
            0.8647430117222723,
            0.874497543546226,
            0.8772707133362871,
            0.8812056737588653
          ],
          "val_auroc": [
            0.9860254202230496,
            0.990847326697566,
            0.9921911539987673,
            0.9928203980897546,
            0.9932738984710718,
            0.9938182959192001,
            0.9937684150984811,
            0.9938713426594287
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.12157607078552246,
          "accuracy": 0.96175799086758,
          "precision": 0.9688109161793372,
          "recall": 0.808130081300813,
          "f1": 0.8812056737588653,
          "auroc": 0.9938713426594287
        },
        "best_val_f1": 0.8812056737588653,
        "training_time": 8.620869874954224,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_22.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_22_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_22_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_22_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "23": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.23.hook_resid_pre",
        "hook_layer": 23,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_23",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.2411576072647147,
            0.15413785367761845,
            0.1350460308837836,
            0.12696831045697812,
            0.12249924659252712,
            0.11956410652630406,
            0.11785766427919744,
            0.11658816219022557
          ],
          "train_accuracy": [
            0.9018908312522298,
            0.9463432037103103,
            0.9555833036032823,
            0.9604352479486264,
            0.9626114876917589,
            0.9635390652871922,
            0.9653585444166964,
            0.9663931501962183
          ],
          "val_loss": [
            0.1797378128225153,
            0.1531522501598705,
            0.14326052096757022,
            0.13878241018815474,
            0.13591050668196245,
            0.13485337495803834,
            0.13337339921431107,
            0.13202504894950173
          ],
          "val_accuracy": [
            0.9333618721461188,
            0.947203196347032,
            0.9537671232876712,
            0.9524828767123288,
            0.9551940639269406,
            0.9539098173515982,
            0.9549086757990868,
            0.95662100456621
          ],
          "val_f1": [
            0.7707412862052038,
            0.8251417769376181,
            0.8502772643253235,
            0.8459046737621472,
            0.8560953253895509,
            0.8514942528735632,
            0.8551787351054079,
            0.8619436875567665
          ],
          "val_auroc": [
            0.9801473396843372,
            0.9874090507850316,
            0.9893174105374121,
            0.9907240869868914,
            0.9909241059076,
            0.9913656128211275,
            0.9916549004991225,
            0.9918869281375835
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.13202504894950173,
          "accuracy": 0.95662100456621,
          "precision": 0.9595551061678463,
          "recall": 0.7823577906018137,
          "f1": 0.8619436875567665,
          "auroc": 0.9918869281375835
        },
        "best_val_f1": 0.8619436875567665,
        "training_time": 8.632803916931152,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_23.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_23_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_23_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_23_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "24": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.24.hook_resid_pre",
        "hook_layer": 24,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_24",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.2508665920494626,
            0.16276149313947927,
            0.1424933239800609,
            0.13380649946119688,
            0.1291941376360448,
            0.12630994156955583,
            0.12418738818944317,
            0.12275596940252062
          ],
          "train_accuracy": [
            0.8977167320727791,
            0.9409917945058865,
            0.9525865144488048,
            0.9559757402782733,
            0.9594363182304674,
            0.961148769175883,
            0.9629682483053871,
            0.9627898679985729
          ],
          "val_loss": [
            0.19129808816042812,
            0.16209595853632147,
            0.1519833814014088,
            0.14574162418192083,
            0.1437672268260609,
            0.1418337941169739,
            0.14046113816174594,
            0.13945506702769886
          ],
          "val_accuracy": [
            0.9170947488584474,
            0.9467751141552512,
            0.942208904109589,
            0.9506278538812786,
            0.9474885844748858,
            0.9492009132420092,
            0.9490582191780822,
            0.9500570776255708
          ],
          "val_f1": [
            0.6934036939313984,
            0.8269141531322506,
            0.8044422984065669,
            0.8398148148148148,
            0.825426944971537,
            0.8328638497652582,
            0.8316831683168316,
            0.8364485981308412
          ],
          "val_auroc": [
            0.9781414628343548,
            0.9864388729649813,
            0.9890267597176748,
            0.9899101589495508,
            0.9904710990517408,
            0.9904486529507064,
            0.9910475460817747,
            0.9909509641202261
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.13945506702769886,
          "accuracy": 0.9500570776255708,
          "precision": 0.9728260869565217,
          "recall": 0.7336065573770492,
          "f1": 0.8364485981308412,
          "auroc": 0.9909509641202261
        },
        "best_val_f1": 0.8398148148148148,
        "training_time": 8.496567964553833,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_24.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_24_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_24_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_24_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "25": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.25.hook_resid_pre",
        "hook_layer": 25,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_25",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.2171388856011983,
            0.13229840104234272,
            0.11473549750195519,
            0.10745550193675033,
            0.1033656005683827,
            0.10093747964766744,
            0.09923529997467995,
            0.09826951176268325
          ],
          "train_accuracy": [
            0.9138779878701392,
            0.9575454869782376,
            0.9668926150552979,
            0.9698537281484124,
            0.971780235462005,
            0.972814841241527,
            0.9735640385301463,
            0.9742062076346771
          ],
          "val_loss": [
            0.15338672724637117,
            0.1288521116430109,
            0.12150089524009011,
            0.11786694093184037,
            0.11486372947692872,
            0.11322128989479759,
            0.11244438378648325,
            0.11149748672138561
          ],
          "val_accuracy": [
            0.9474885844748858,
            0.9609018264840182,
            0.9597602739726028,
            0.9624714611872146,
            0.9677511415525114,
            0.9668949771689498,
            0.9660388127853882,
            0.966466894977169
          ],
          "val_f1": [
            0.8232468780019212,
            0.8740808823529411,
            0.8690807799442897,
            0.879080459770115,
            0.8982898289828983,
            0.8950226244343892,
            0.8918181818181818,
            0.8934240362811792
          ],
          "val_auroc": [
            0.9859723119775482,
            0.9919544257863295,
            0.9926419591503377,
            0.9927257679618628,
            0.9935158936349322,
            0.9939864847716737,
            0.9939152221894189,
            0.9941500159086187
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.11149748672138561,
          "accuracy": 0.966466894977169,
          "precision": 0.9810756972111554,
          "recall": 0.8201498751040799,
          "f1": 0.8934240362811792,
          "auroc": 0.9941500159086187
        },
        "best_val_f1": 0.8982898289828983,
        "training_time": 8.03633427619934,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_25.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_25_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_25_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_25_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "26": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.26.hook_resid_pre",
        "hook_layer": 26,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_26",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.21836512255137913,
            0.13423275488288436,
            0.11665829595977857,
            0.10878446218493866,
            0.10479322020559823,
            0.10189326855111612,
            0.10006275396692017,
            0.09877248960610939
          ],
          "train_accuracy": [
            0.9124509454156261,
            0.9545130217623974,
            0.9635747413485551,
            0.9681412772029968,
            0.9704245451302176,
            0.9717445594006422,
            0.9725294327506243,
            0.973421334284695
          ],
          "val_loss": [
            0.1589509530500932,
            0.13470892039212315,
            0.1255449901927601,
            0.12308941104195335,
            0.11895904541015626,
            0.1175031219016422,
            0.11639863361011851,
            0.11545391082763672
          ],
          "val_accuracy": [
            0.9486301369863014,
            0.954337899543379,
            0.959046803652968,
            0.9630422374429224,
            0.9619006849315068,
            0.9631849315068494,
            0.963755707762557,
            0.9631849315068494
          ],
          "val_f1": [
            0.8301886792452831,
            0.8504672897196262,
            0.8678028558268079,
            0.8842199374161824,
            0.8782489740082079,
            0.8828337874659401,
            0.8845454545454545,
            0.8828337874659401
          ],
          "val_auroc": [
            0.9838787326830783,
            0.9902040763723765,
            0.9918660855756103,
            0.9924609950862149,
            0.9927713017198605,
            0.9928569331766763,
            0.9932306042244374,
            0.9931378129468176
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.11545391082763672,
          "accuracy": 0.9631849315068494,
          "precision": 0.972972972972973,
          "recall": 0.8079800498753117,
          "f1": 0.8828337874659401,
          "auroc": 0.9931378129468176
        },
        "best_val_f1": 0.8845454545454545,
        "training_time": 8.15871810913086,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_26.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_26_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_26_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_26_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "27": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.27.hook_resid_pre",
        "hook_layer": 27,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_27",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.21371327337200782,
            0.12984318679122075,
            0.11237061661604332,
            0.10485244097111568,
            0.10089967962456485,
            0.09814671806344703,
            0.09643129940616758,
            0.095177085440793
          ],
          "train_accuracy": [
            0.9158401712450945,
            0.9558687120941848,
            0.9647163753121656,
            0.9700677845165894,
            0.9724937566892615,
            0.9726721369960757,
            0.9745272921869426,
            0.9748127006778452
          ],
          "val_loss": [
            0.14850201390006326,
            0.12401442744515159,
            0.1165623513135043,
            0.11269164302132346,
            0.11036974733526056,
            0.10883142839778553,
            0.10841394784775647,
            0.10690772533416748
          ],
          "val_accuracy": [
            0.9501997716894978,
            0.9551940639269406,
            0.963898401826484,
            0.9658961187214612,
            0.9660388127853882,
            0.9671803652968036,
            0.963898401826484,
            0.9656107305936074
          ],
          "val_f1": [
            0.8351440717997166,
            0.8514664143803217,
            0.88515660463005,
            0.8916099773242631,
            0.8918181818181818,
            0.8959276018099548,
            0.8834638415476739,
            0.8902050113895217
          ],
          "val_auroc": [
            0.9875157182681725,
            0.9928358526949047,
            0.993351793376122,
            0.9940791344173749,
            0.9942859281641854,
            0.9946057998700071,
            0.9945420270681714,
            0.9946299845894392
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.10690772533416748,
          "accuracy": 0.9656107305936074,
          "precision": 0.977,
          "recall": 0.8175732217573222,
          "f1": 0.8902050113895217,
          "auroc": 0.9946299845894392
        },
        "best_val_f1": 0.8959276018099548,
        "training_time": 8.588951826095581,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_27.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_27_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_27_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_27_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "28": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.28.hook_resid_pre",
        "hook_layer": 28,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_28",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.17454515587215283,
            0.09310296195725055,
            0.07888929414898838,
            0.07237781411606699,
            0.06902883093821131,
            0.06692215371621799,
            0.06562003857332822,
            0.06463931242352751
          ],
          "train_accuracy": [
            0.9362825544059936,
            0.9739921512665002,
            0.980164109882269,
            0.9831608990367463,
            0.9843025330003567,
            0.9854441669639672,
            0.9858722797003211,
            0.9869425615412059
          ],
          "val_loss": [
            0.109186974438754,
            0.08835070133209229,
            0.08120115887035023,
            0.07828408588062633,
            0.07553523237054999,
            0.07458908530798826,
            0.07362739877267317,
            0.07278350483287464
          ],
          "val_accuracy": [
            0.963755707762557,
            0.9731735159817352,
            0.976170091324201,
            0.9746004566210046,
            0.978595890410959,
            0.9810216894977168,
            0.9788812785388128,
            0.980593607305936
          ],
          "val_f1": [
            0.8827331486611265,
            0.915695067264574,
            0.926007975188303,
            0.9203222918531782,
            0.9336870026525199,
            0.9418960244648318,
            0.9345711759504863,
            0.9402985074626866
          ],
          "val_auroc": [
            0.9952992150789768,
            0.9975475545359711,
            0.9980019969212447,
            0.9981480445057835,
            0.9983756623708724,
            0.9983671519437238,
            0.9985071412580893,
            0.9984997126649002
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.07278350483287464,
          "accuracy": 0.980593607305936,
          "precision": 0.9861878453038674,
          "recall": 0.8984899328859061,
          "f1": 0.9402985074626866,
          "auroc": 0.9984997126649002
        },
        "best_val_f1": 0.9418960244648318,
        "training_time": 8.245948314666748,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_28.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_28_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_28_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_28_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "29": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.29.hook_resid_pre",
        "hook_layer": 29,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_29",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.14862116288444768,
            0.07876789712742584,
            0.0660364507914406,
            0.06052257000260293,
            0.057770275459816195,
            0.055768092583915956,
            0.05436907291038123,
            0.05337924086680151
          ],
          "train_accuracy": [
            0.9474134855511952,
            0.9769532643596147,
            0.981805208704959,
            0.9850160542276133,
            0.9866571530503032,
            0.9877631109525509,
            0.9880841955048163,
            0.9887263646093472
          ],
          "val_loss": [
            0.08848190307617188,
            0.07242628010836515,
            0.06525565169074318,
            0.06316353624517268,
            0.060878177122636275,
            0.05940574299205433,
            0.058813047409057614,
            0.0585489576513117
          ],
          "val_accuracy": [
            0.9726027397260274,
            0.976027397260274,
            0.9801655251141552,
            0.9838755707762558,
            0.9821632420091324,
            0.9838755707762558,
            0.9828767123287672,
            0.9838755707762558
          ],
          "val_f1": [
            0.9146666666666666,
            0.9254658385093167,
            0.9393807239424335,
            0.9511034184335785,
            0.9454862625381596,
            0.9509335649153279,
            0.9478260869565217,
            0.9510186389250108
          ],
          "val_auroc": [
            0.9961882281491162,
            0.9978769550078105,
            0.9983608271837343,
            0.9985271357360129,
            0.9986448986130054,
            0.998715556339201,
            0.998766118748772,
            0.9988825131274996
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.0585489576513117,
          "accuracy": 0.9838755707762558,
          "precision": 0.9856244384546271,
          "recall": 0.9187604690117253,
          "f1": 0.9510186389250108,
          "auroc": 0.9988825131274996
        },
        "best_val_f1": 0.9511034184335785,
        "training_time": 8.334843635559082,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_29.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_29_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_29_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_29_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "30": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.30.hook_resid_pre",
        "hook_layer": 30,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_30",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.13891686478706256,
            0.06998750062225616,
            0.05823437970761022,
            0.05341919191760015,
            0.05055434985690193,
            0.048900987025877654,
            0.04750993173807587,
            0.04663747850992636
          ],
          "train_accuracy": [
            0.9524438102033536,
            0.980164109882269,
            0.9857295754548698,
            0.987513378523011,
            0.9886906885479843,
            0.9900107028184089,
            0.9899036746343204,
            0.9909026043524795
          ],
          "val_loss": [
            0.08582307208668102,
            0.06976586255160246,
            0.06382001096552069,
            0.06033189513466575,
            0.05880405686118386,
            0.057112442363392225,
            0.05648093115199696,
            0.05595329458063299
          ],
          "val_accuracy": [
            0.9731735159817352,
            0.9775970319634704,
            0.9823059360730594,
            0.9825913242009132,
            0.9818778538812786,
            0.983019406392694,
            0.9821632420091324,
            0.9827340182648402
          ],
          "val_f1": [
            0.9180470793374019,
            0.9321227842628621,
            0.9472340425531914,
            0.9479522184300341,
            0.9457496796240923,
            0.9492969748615253,
            0.9466040153780436,
            0.9483568075117371
          ],
          "val_auroc": [
            0.9958360735965713,
            0.9977538686714426,
            0.9981698791963177,
            0.998629832999973,
            0.9987381698112647,
            0.9988071628818128,
            0.998916419600712,
            0.9989466350275059
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.05595329458063299,
          "accuracy": 0.9827340182648402,
          "precision": 0.9901960784313726,
          "recall": 0.9099099099099099,
          "f1": 0.9483568075117371,
          "auroc": 0.9989466350275059
        },
        "best_val_f1": 0.9492969748615253,
        "training_time": 8.196162223815918,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_30.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_30_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_30_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_30_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "31": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.31.hook_resid_pre",
        "hook_layer": 31,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_31",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.10571916375870574,
            0.04994888314828447,
            0.04082878285670253,
            0.03693452687534295,
            0.03473103394918994,
            0.0333025750159775,
            0.032474704567325985,
            0.03183316048787541
          ],
          "train_accuracy": [
            0.9648590795576168,
            0.9858722797003211,
            0.9896896182661434,
            0.9909739564752051,
            0.9923653228683553,
            0.9928647877274349,
            0.9931501962183374,
            0.9936853371387799
          ],
          "val_loss": [
            0.05834477164528586,
            0.04654340310530229,
            0.04219706708734686,
            0.03985846692865545,
            0.03888817266984419,
            0.03795828385786577,
            0.037457786906849255,
            0.0369738752191717
          ],
          "val_accuracy": [
            0.9837328767123288,
            0.9888698630136986,
            0.988156392694064,
            0.9895833333333334,
            0.990154109589041,
            0.9900114155251142,
            0.990296803652968,
            0.990154109589041
          ],
          "val_f1": [
            0.950477845351868,
            0.9665809768637532,
            0.9643623872906827,
            0.9688167449807774,
            0.9705756929637527,
            0.9701365187713311,
            0.9709897610921502,
            0.970550576184379
          ],
          "val_auroc": [
            0.9979314147269106,
            0.9989749565790714,
            0.9992610704473525,
            0.9994036595223373,
            0.9994571394227482,
            0.9994671444108465,
            0.9994966555268202,
            0.999516665503017
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.0369738752191717,
          "accuracy": 0.990154109589041,
          "precision": 0.990418118466899,
          "recall": 0.9514644351464435,
          "f1": 0.970550576184379,
          "auroc": 0.999516665503017
        },
        "best_val_f1": 0.9709897610921502,
        "training_time": 8.184996366500854,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_31.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_31_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_31_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_31_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "32": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.32.hook_resid_pre",
        "hook_layer": 32,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_32",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.10641639363488446,
            0.04941243837804419,
            0.04029665770834167,
            0.036308732330288786,
            0.03405450452884583,
            0.03263561568780032,
            0.031562663468034706,
            0.03102783055457214
          ],
          "train_accuracy": [
            0.9637174455940064,
            0.9862290403139493,
            0.9902961113093115,
            0.9913663931501963,
            0.9926864074206208,
            0.9932572244024259,
            0.9941848019978594,
            0.9940777738137709
          ],
          "val_loss": [
            0.058785802667791195,
            0.04731309197165749,
            0.04268308552828702,
            0.040374313701282846,
            0.03900805047967217,
            0.03812767375599254,
            0.037728801640597255,
            0.037037541649558324
          ],
          "val_accuracy": [
            0.980736301369863,
            0.9841609589041096,
            0.9861586757990868,
            0.9877283105022832,
            0.9884417808219178,
            0.9887271689497716,
            0.9884417808219178,
            0.9885844748858448
          ],
          "val_f1": [
            0.9402390438247012,
            0.9510366122629025,
            0.9573626373626374,
            0.9624454148471616,
            0.9646750981247274,
            0.9655473179241169,
            0.9645824223874071,
            0.9650655021834061
          ],
          "val_auroc": [
            0.9980222995201133,
            0.9990101642314132,
            0.9993158241151121,
            0.9994311674674513,
            0.9994862840693601,
            0.9995323484081742,
            0.9995273112617745,
            0.9995821358551965
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.037037541649558324,
          "accuracy": 0.9885844748858448,
          "precision": 0.9901433691756273,
          "recall": 0.9412265758091993,
          "f1": 0.9650655021834061,
          "auroc": 0.9995821358551965
        },
        "best_val_f1": 0.9655473179241169,
        "training_time": 8.158555269241333,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_32.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_32_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_32_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_32_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "33": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.33.hook_resid_pre",
        "hook_layer": 33,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_33",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08772693736878433,
            0.038349318977224225,
            0.030703259385339746,
            0.02754653669196313,
            0.02573580437310074,
            0.02470778939994605,
            0.02393242637903247,
            0.02335029844190398
          ],
          "train_accuracy": [
            0.9702104887620406,
            0.9899036746343204,
            0.9925793792365323,
            0.9940777738137709,
            0.9948626471637532,
            0.9953264359614699,
            0.9956118444523725,
            0.9959329290046379
          ],
          "val_loss": [
            0.048638595234264025,
            0.037887677279385655,
            0.034452382001009856,
            0.03278556303544478,
            0.031441020965576175,
            0.030962007695978337,
            0.030434404719959608,
            0.030313886295665393
          ],
          "val_accuracy": [
            0.9864440639269406,
            0.9894406392694064,
            0.990439497716895,
            0.9908675799086758,
            0.9914383561643836,
            0.9915810502283106,
            0.9917237442922374,
            0.9918664383561644
          ],
          "val_f1": [
            0.9601342845153168,
            0.969140950792327,
            0.9720949604331528,
            0.9733998337489609,
            0.9750623441396509,
            0.9754677754677755,
            0.9759136212624585,
            0.9763387297633873
          ],
          "val_auroc": [
            0.9987616559994215,
            0.9993389471971361,
            0.9994777965358574,
            0.9994921334716459,
            0.9995410061788662,
            0.9995668550384653,
            0.999576813205688,
            0.9995857826187183
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030313886295665393,
          "accuracy": 0.9918664383561644,
          "precision": 0.9924050632911392,
          "recall": 0.9607843137254902,
          "f1": 0.9763387297633873,
          "auroc": 0.9995857826187183
        },
        "best_val_f1": 0.9763387297633873,
        "training_time": 8.166990518569946,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_33.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_33_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_33_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_33_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "34": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.34.hook_resid_pre",
        "hook_layer": 34,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_34",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08351518121041936,
            0.03522873091932437,
            0.028069908943316436,
            0.0249551921321683,
            0.023413933757224788,
            0.022312900210947614,
            0.021560750450390354,
            0.021067763899333913
          ],
          "train_accuracy": [
            0.9729932215483411,
            0.9903674634320371,
            0.9931501962183374,
            0.9947556189796647,
            0.9952907599001071,
            0.9958615768819122,
            0.996111309311452,
            0.9964323938637174
          ],
          "val_loss": [
            0.04488648934797807,
            0.03429462801326405,
            0.030825393850153142,
            0.029425161535089665,
            0.028357419100674717,
            0.027481122450395065,
            0.027093267440795897,
            0.026695893027565695
          ],
          "val_accuracy": [
            0.9875856164383562,
            0.9898687214611872,
            0.9922945205479452,
            0.9917237442922374,
            0.9921518264840182,
            0.992865296803653,
            0.9924372146118722,
            0.992579908675799
          ],
          "val_f1": [
            0.9647344953384678,
            0.9713594191206132,
            0.9782608695652174,
            0.9766317485898469,
            0.9778493757551349,
            0.9798711755233495,
            0.9786548530004028,
            0.9790660225442834
          ],
          "val_auroc": [
            0.9991140553605773,
            0.999553949802511,
            0.999697883817238,
            0.9996803157058778,
            0.9997077053598095,
            0.9997477523538156,
            0.9997602021965118,
            0.9997731361997575
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.026695893027565695,
          "accuracy": 0.992579908675799,
          "precision": 0.9910350448247759,
          "recall": 0.9673826571201273,
          "f1": 0.9790660225442834,
          "auroc": 0.9997731361997575
        },
        "best_val_f1": 0.9798711755233495,
        "training_time": 8.212211608886719,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_34.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_34_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_34_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_34_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "35": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.35.hook_resid_pre",
        "hook_layer": 35,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_35",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.07328483768096661,
            0.029132081965435312,
            0.02319460014969995,
            0.020493984660431404,
            0.01899807500444591,
            0.01806791166224215,
            0.017472337842089673,
            0.01706893545720029
          ],
          "train_accuracy": [
            0.9763467713164466,
            0.9927220834819835,
            0.9949696753478416,
            0.9961826614341777,
            0.9966107741705316,
            0.9968605066000713,
            0.9975383517659651,
            0.9975026757046022
          ],
          "val_loss": [
            0.033335330269553445,
            0.025912878730080344,
            0.022475996884432706,
            0.021035302769054066,
            0.020137596130371093,
            0.019651425968516958,
            0.019329127398404207,
            0.019089182940396396
          ],
          "val_accuracy": [
            0.990439497716895,
            0.9940068493150684,
            0.9947203196347032,
            0.995291095890411,
            0.9954337899543378,
            0.9954337899543378,
            0.9954337899543378,
            0.995291095890411
          ],
          "val_f1": [
            0.9717418810628426,
            0.9824707846410684,
            0.98456403838131,
            0.9862442684451855,
            0.9866666666666667,
            0.9866555462885738,
            0.9866666666666667,
            0.986232790988736
          ],
          "val_auroc": [
            0.9995885263992238,
            0.9997875369835121,
            0.9998770775110637,
            0.999904409436803,
            0.9999208512983804,
            0.99993444608436,
            0.9999275419260352,
            0.9999353713839293
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.019089182940396396,
          "accuracy": 0.995291095890411,
          "precision": 0.9974683544303797,
          "recall": 0.9752475247524752,
          "f1": 0.986232790988736,
          "auroc": 0.9999353713839293
        },
        "best_val_f1": 0.9866666666666667,
        "training_time": 8.075620174407959,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_35.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_35_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_35_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_35_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "36": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.36.hook_resid_pre",
        "hook_layer": 36,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_36",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08136329183686677,
            0.03295219623266834,
            0.02594975409093717,
            0.023033851394578645,
            0.021503466449903332,
            0.020508868292348298,
            0.019832716323435307,
            0.019339832821733332
          ],
          "train_accuracy": [
            0.9745629682483054,
            0.9914734213342847,
            0.9943988583660364,
            0.995718872636461,
            0.9960399571887264,
            0.9965037459864431,
            0.996931858722797,
            0.9968961826614342
          ],
          "val_loss": [
            0.04284792379899458,
            0.03317008018493652,
            0.0297103535045277,
            0.02810736136002974,
            0.026992247321388937,
            0.026269886710427025,
            0.025939260829578748,
            0.025409026579423385
          ],
          "val_accuracy": [
            0.98787100456621,
            0.9917237442922374,
            0.9922945205479452,
            0.992579908675799,
            0.992722602739726,
            0.992865296803653,
            0.992579908675799,
            0.9934360730593608
          ],
          "val_f1": [
            0.9628334062090075,
            0.9748917748917749,
            0.9766233766233766,
            0.9775086505190311,
            0.9779125162407969,
            0.9783549783549783,
            0.9774501300954033,
            0.9800865800865801
          ],
          "val_auroc": [
            0.9991444899557378,
            0.9995201224933176,
            0.9996307229720993,
            0.9996412424363956,
            0.9996873381445273,
            0.9997307309347494,
            0.9997146595309634,
            0.9997519890188481
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.025409026579423385,
          "accuracy": 0.9934360730593608,
          "precision": 0.9956024626209323,
          "recall": 0.9650468883205456,
          "f1": 0.9800865800865801,
          "auroc": 0.9997519890188481
        },
        "best_val_f1": 0.9800865800865801,
        "training_time": 8.637011766433716,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_36.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_36_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_36_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_36_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "37": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.37.hook_resid_pre",
        "hook_layer": 37,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_37",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08213839563647429,
            0.03251362322366129,
            0.025709172544924365,
            0.02266102693719815,
            0.021146234626707422,
            0.02016278590632764,
            0.019508823413257253,
            0.019048032080797164
          ],
          "train_accuracy": [
            0.9744202640028541,
            0.9921869425615412,
            0.9948269711023903,
            0.9961469853728149,
            0.9966107741705316,
            0.996931858722797,
            0.9971459150909739,
            0.9976097038886906
          ],
          "val_loss": [
            0.03984906023198908,
            0.030691862106323242,
            0.02699673826044256,
            0.025510683926669032,
            0.024723534150557086,
            0.024024274132468482,
            0.02359560402956876,
            0.023244489323009144
          ],
          "val_accuracy": [
            0.9895833333333334,
            0.9918664383561644,
            0.9935787671232876,
            0.9942922374429224,
            0.9944349315068494,
            0.9944349315068494,
            0.9942922374429224,
            0.9942922374429224
          ],
          "val_f1": [
            0.9683571738188123,
            0.9753353526611857,
            0.980611805256355,
            0.9828030954428203,
            0.9832402234636871,
            0.983225806451613,
            0.9827586206896551,
            0.9827734711455641
          ],
          "val_auroc": [
            0.9995829690132589,
            0.9997403378242011,
            0.9998466327075977,
            0.9998643121440558,
            0.999858055224157,
            0.9998738430336691,
            0.9998851200404634,
            0.9998940688910163
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.023244489323009144,
          "accuracy": 0.9942922374429224,
          "precision": 0.9982502187226596,
          "recall": 0.9677692960135709,
          "f1": 0.9827734711455641,
          "auroc": 0.9998940688910163
        },
        "best_val_f1": 0.9832402234636871,
        "training_time": 8.422390222549438,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_37.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_37_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_37_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_37_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "38": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.38.hook_resid_pre",
        "hook_layer": 38,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_38",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08545713631869996,
            0.03363212579903809,
            0.02698077604208635,
            0.02378629614943511,
            0.02209707910671286,
            0.02105797944775438,
            0.02037533842979773,
            0.019776893473447184
          ],
          "train_accuracy": [
            0.9725651088119872,
            0.9927577595433464,
            0.994470210488762,
            0.9959686050660007,
            0.9963967178023546,
            0.9970032108455227,
            0.9969675347841598,
            0.9973242953977881
          ],
          "val_loss": [
            0.04305134253068404,
            0.032767113772305574,
            0.02907516956329346,
            0.027269783886996184,
            0.02590387517755682,
            0.025261176716197622,
            0.02453799139369618,
            0.02440657317638397
          ],
          "val_accuracy": [
            0.9882990867579908,
            0.990582191780822,
            0.9920091324200914,
            0.9915810502283106,
            0.9924372146118722,
            0.9924372146118722,
            0.9934360730593608,
            0.992865296803653
          ],
          "val_f1": [
            0.965076660988075,
            0.9719864176570459,
            0.9763513513513513,
            0.9750317393144308,
            0.9775898520084566,
            0.9776465626318009,
            0.9806397306397306,
            0.9788672865595942
          ],
          "val_auroc": [
            0.9993753056348506,
            0.9997361606033724,
            0.9998018161601452,
            0.9998168517838336,
            0.9998519349057732,
            0.9998527940842697,
            0.9998781398499158,
            0.9998739155556414
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.02440657317638397,
          "accuracy": 0.992865296803653,
          "precision": 0.9957007738607051,
          "recall": 0.9625935162094763,
          "f1": 0.9788672865595942,
          "auroc": 0.9998739155556414
        },
        "best_val_f1": 0.9806397306397306,
        "training_time": 8.00469446182251,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_38.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_38_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_38_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_38_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "39": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.39.hook_resid_pre",
        "hook_layer": 39,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_39",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08598586277330303,
            0.03409908743379595,
            0.02691967531052082,
            0.023791325128675527,
            0.02215429361203694,
            0.021004780097843304,
            0.020203383403434735,
            0.01966702651453617
          ],
          "train_accuracy": [
            0.9720656439529076,
            0.992436674991081,
            0.9950410274705672,
            0.9959329290046379,
            0.9967891544773457,
            0.9972172672136996,
            0.9974313235818766,
            0.9975026757046022
          ],
          "val_loss": [
            0.04578409628434615,
            0.03499784469604492,
            0.031114729967984287,
            0.029536620053378017,
            0.02809182947332209,
            0.027387601679021663,
            0.026858308098532936,
            0.026384843479503286
          ],
          "val_accuracy": [
            0.9867294520547946,
            0.9892979452054794,
            0.9912956621004566,
            0.9912956621004566,
            0.9922945205479452,
            0.9918664383561644,
            0.9922945205479452,
            0.9924372146118722
          ],
          "val_f1": [
            0.9615861214374225,
            0.9691484985602633,
            0.9750918742343814,
            0.975071516142215,
            0.9779951100244498,
            0.9767441860465116,
            0.9779591836734693,
            0.9783761729906161
          ],
          "val_auroc": [
            0.9994330262225373,
            0.9997574890922357,
            0.9997637609260571,
            0.999809824061124,
            0.9998282214403336,
            0.999846131010246,
            0.9998542147071716,
            0.9998569325018276
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.026384843479503286,
          "accuracy": 0.9924372146118722,
          "precision": 0.9941956882255389,
          "recall": 0.9630522088353414,
          "f1": 0.9783761729906161,
          "auroc": 0.9998569325018276
        },
        "best_val_f1": 0.9783761729906161,
        "training_time": 8.117604970932007,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_39.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_39_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_39_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_39_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "40": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.40.hook_resid_pre",
        "hook_layer": 40,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_40",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09078542591332028,
            0.03623983254188408,
            0.028082971125160724,
            0.02483729829960694,
            0.023013930850700564,
            0.02182062946208944,
            0.021075224844083938,
            0.020468691678624175
          ],
          "train_accuracy": [
            0.9708883339279344,
            0.992436674991081,
            0.994898323225116,
            0.9960042811273635,
            0.9966464502318944,
            0.9970032108455227,
            0.9973242953977881,
            0.997752408134142
          ],
          "val_loss": [
            0.0485807939009233,
            0.036924643950028854,
            0.032716590707952325,
            0.03083652583035556,
            0.02971515655517578,
            0.029029863530939275,
            0.028513708981600674,
            0.028004689650102096
          ],
          "val_accuracy": [
            0.9864440639269406,
            0.990582191780822,
            0.9914383561643836,
            0.9921518264840182,
            0.9920091324200914,
            0.9924372146118722,
            0.992722602739726,
            0.992722602739726
          ],
          "val_f1": [
            0.9596260093497663,
            0.9722921914357683,
            0.9747687132043734,
            0.9769392033542977,
            0.9764903442485307,
            0.9778149853495186,
            0.9786342689568496,
            0.9786342689568496
          ],
          "val_auroc": [
            0.9989431933807127,
            0.9995653159132402,
            0.9997159335591014,
            0.9997669434919201,
            0.9997751022433445,
            0.9997648151219832,
            0.9997853184190411,
            0.9997931224421427
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.028004689650102096,
          "accuracy": 0.992722602739726,
          "precision": 0.9982905982905983,
          "recall": 0.9597370583401807,
          "f1": 0.9786342689568496,
          "auroc": 0.9997931224421427
        },
        "best_val_f1": 0.9786342689568496,
        "training_time": 7.94964599609375,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_40.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_40_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_40_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_40_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "41": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.41.hook_resid_pre",
        "hook_layer": 41,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_41",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09028021440539322,
            0.036643228111958734,
            0.02818024029623564,
            0.024893567246729382,
            0.023075541913016067,
            0.02184886155866903,
            0.02106900247809005,
            0.02054392612968746
          ],
          "train_accuracy": [
            0.9698537281484124,
            0.9916874777024617,
            0.9952194077773814,
            0.99671780235462,
            0.9971459150909739,
            0.9971102390296112,
            0.9976453799500535,
            0.9976097038886906
          ],
          "val_loss": [
            0.05244871269572865,
            0.04052981029857289,
            0.03636476343328303,
            0.03443597121672197,
            0.033455790172923695,
            0.032850460572676224,
            0.03233297196301547,
            0.03196521238847212
          ],
          "val_accuracy": [
            0.9858732876712328,
            0.9898687214611872,
            0.9914383561643836,
            0.9917237442922374,
            0.9911529680365296,
            0.9914383561643836,
            0.9911529680365296,
            0.9918664383561644
          ],
          "val_f1": [
            0.9571614019904803,
            0.9695670810115731,
            0.9743589743589743,
            0.9752136752136752,
            0.973458904109589,
            0.9743370402053037,
            0.9734816082121471,
            0.9756929637526652
          ],
          "val_auroc": [
            0.9987232631452181,
            0.9993004092818178,
            0.9994145708475873,
            0.9994894060948015,
            0.9995330539868243,
            0.9995421292911064,
            0.9995569666933452,
            0.9995485396250834
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03196521238847212,
          "accuracy": 0.9918664383561644,
          "precision": 0.9939183318853171,
          "recall": 0.9581239530988275,
          "f1": 0.9756929637526652,
          "auroc": 0.9995485396250834
        },
        "best_val_f1": 0.9756929637526652,
        "training_time": 8.065852880477905,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_41.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_41_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_41_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_41_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "42": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.42.hook_resid_pre",
        "hook_layer": 42,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_42",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09281944719113444,
            0.0374342617429963,
            0.0290907702353447,
            0.025465807560661205,
            0.023556470872034833,
            0.022393836061465958,
            0.02163222267985616,
            0.021095932780267442
          ],
          "train_accuracy": [
            0.9697466999643239,
            0.9916874777024617,
            0.9949696753478416,
            0.9961469853728149,
            0.9971102390296112,
            0.9972886193364252,
            0.9975383517659651,
            0.9975740278273278
          ],
          "val_loss": [
            0.04679459658536044,
            0.03685997832905163,
            0.032718511061234905,
            0.03063008351759477,
            0.02961844964460893,
            0.028699926896528765,
            0.028049746426669034,
            0.027740309455178
          ],
          "val_accuracy": [
            0.9860159817351598,
            0.990439497716895,
            0.9918664383561644,
            0.9918664383561644,
            0.9917237442922374,
            0.9918664383561644,
            0.992579908675799,
            0.9921518264840182
          ],
          "val_f1": [
            0.9567901234567902,
            0.9709327548806942,
            0.9752066115702479,
            0.9751850239442751,
            0.9748263888888888,
            0.9752496743378203,
            0.9774501300954033,
            0.9761181068171949
          ],
          "val_auroc": [
            0.9991979326377923,
            0.9994460325448355,
            0.9995921032001658,
            0.9996670469886544,
            0.9996856911828522,
            0.9997115288063076,
            0.9997231997782663,
            0.9997193828566194
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.027740309455178,
          "accuracy": 0.9921518264840182,
          "precision": 0.9885664028144239,
          "recall": 0.9639794168096055,
          "f1": 0.9761181068171949,
          "auroc": 0.9997193828566194
        },
        "best_val_f1": 0.9774501300954033,
        "training_time": 7.932027578353882,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_42.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_42_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_42_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_42_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "43": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.43.hook_resid_pre",
        "hook_layer": 43,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_43",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09297067821706266,
            0.03736018339920466,
            0.02899587397637977,
            0.02531731502497441,
            0.02348728477529603,
            0.02224525157149592,
            0.021469398403803915,
            0.020861379923426532
          ],
          "train_accuracy": [
            0.9695683196575098,
            0.9917588298251873,
            0.9945415626114877,
            0.9962540135569034,
            0.9968605066000713,
            0.9971459150909739,
            0.9972886193364252,
            0.9976453799500535
          ],
          "val_loss": [
            0.047149014405228874,
            0.03643288178877397,
            0.03310961289839311,
            0.030940615047108044,
            0.030025867982344193,
            0.02956153696233576,
            0.028807158903642133,
            0.028668568351052023
          ],
          "val_accuracy": [
            0.988013698630137,
            0.9907248858447488,
            0.992579908675799,
            0.9921518264840182,
            0.992722602739726,
            0.9922945205479452,
            0.992722602739726,
            0.992722602739726
          ],
          "val_f1": [
            0.9636363636363636,
            0.9721149721149721,
            0.9777587681779298,
            0.9764453961456103,
            0.9781771501925546,
            0.9768637532133676,
            0.9781771501925546,
            0.9781584582441113
          ],
          "val_auroc": [
            0.9991117829049805,
            0.9995591774007644,
            0.9996617278743742,
            0.9997262191229189,
            0.9997083811180023,
            0.9997390018227985,
            0.9997577064514359,
            0.9997599452293808
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.028668568351052023,
          "accuracy": 0.992722602739726,
          "precision": 0.9973799126637555,
          "recall": 0.9596638655462185,
          "f1": 0.9781584582441113,
          "auroc": 0.9997599452293808
        },
        "best_val_f1": 0.9781771501925546,
        "training_time": 7.968213319778442,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_43.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_43_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_43_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_43_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "44": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.44.hook_resid_pre",
        "hook_layer": 44,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_44",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09604558787100255,
            0.038848626686761915,
            0.030117170198408028,
            0.02623117328557658,
            0.024223656929417015,
            0.022849172435607336,
            0.022082786110854926,
            0.021434376266100296
          ],
          "train_accuracy": [
            0.9683553335711738,
            0.9910809846592936,
            0.9942918301819479,
            0.9955761683910096,
            0.9965750981091688,
            0.9966107741705316,
            0.9968248305387085,
            0.9975740278273278
          ],
          "val_loss": [
            0.05058777549050071,
            0.03850477500395341,
            0.03423851186578924,
            0.03190081336281516,
            0.030647910724986682,
            0.029859087683937767,
            0.029466121846979314,
            0.029233525016091087
          ],
          "val_accuracy": [
            0.98787100456621,
            0.9912956621004566,
            0.9917237442922374,
            0.9921518264840182,
            0.992865296803653,
            0.9934360730593608,
            0.9932933789954338,
            0.99300799086758
          ],
          "val_f1": [
            0.9648324369052544,
            0.9747829681686647,
            0.9760923330585326,
            0.9773569370111157,
            0.9794576828266228,
            0.9811320754716981,
            0.980729807298073,
            0.9798436857260386
          ],
          "val_auroc": [
            0.9990942058206181,
            0.9995166666549784,
            0.9996573466738572,
            0.9997339983491488,
            0.999772639770087,
            0.9997688527705759,
            0.9997655566784086,
            0.9997670995300615
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.029233525016091087,
          "accuracy": 0.99300799086758,
          "precision": 0.995819397993311,
          "recall": 0.9643724696356275,
          "f1": 0.9798436857260386,
          "auroc": 0.9997670995300615
        },
        "best_val_f1": 0.9811320754716981,
        "training_time": 7.964285612106323,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_44.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_44_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_44_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_44_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "45": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.45.hook_resid_pre",
        "hook_layer": 45,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_45",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09823867893824566,
            0.03973424852268609,
            0.03007202293961968,
            0.02630908797882055,
            0.024375995436096438,
            0.02283333070133919,
            0.021936906746176144,
            0.021307466241220634
          ],
          "train_accuracy": [
            0.9673207277916518,
            0.9911880128433821,
            0.9947912950410275,
            0.9961826614341777,
            0.9965037459864431,
            0.9971102390296112,
            0.9974669996432394,
            0.9977167320727791
          ],
          "val_loss": [
            0.04958757053722035,
            0.03752507729963823,
            0.03399633927778764,
            0.03244481086730957,
            0.030910301208496093,
            0.030171940543434837,
            0.029431473125110973,
            0.029127892580899324
          ],
          "val_accuracy": [
            0.9864440639269406,
            0.990582191780822,
            0.9911529680365296,
            0.9914383561643836,
            0.9920091324200914,
            0.9912956621004566,
            0.9924372146118722,
            0.9921518264840182
          ],
          "val_f1": [
            0.9585333915320821,
            0.9715025906735751,
            0.9732758620689655,
            0.9740932642487047,
            0.9758828596037898,
            0.9736728528269314,
            0.9772238934250107,
            0.9763440860215054
          ],
          "val_auroc": [
            0.9990507737089768,
            0.9995435505689412,
            0.9995744397599866,
            0.9995921321604915,
            0.9996486898342367,
            0.9996949511109667,
            0.9997089455097267,
            0.9997055375473345
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.029127892580899324,
          "accuracy": 0.9921518264840182,
          "precision": 0.9947414548641542,
          "recall": 0.9586148648648649,
          "f1": 0.9763440860215054,
          "auroc": 0.9997055375473345
        },
        "best_val_f1": 0.9772238934250107,
        "training_time": 7.967492580413818,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_45.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_45_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_45_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_45_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "46": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.46.hook_resid_pre",
        "hook_layer": 46,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_46",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09431886884753835,
            0.03699741566757837,
            0.02838460041941505,
            0.024538550893754854,
            0.022747457590906725,
            0.02151050718424663,
            0.020602751069289705,
            0.01997894594939128
          ],
          "train_accuracy": [
            0.9687834463075277,
            0.9921869425615412,
            0.9954334641455583,
            0.9963967178023546,
            0.9970032108455227,
            0.9975383517659651,
            0.9978594363182305,
            0.9978951123795933
          ],
          "val_loss": [
            0.051517642628062854,
            0.04106289419260892,
            0.03733925819396973,
            0.03583097891374068,
            0.034251317110928624,
            0.03325731537558816,
            0.032785194570367986,
            0.032578468322753906
          ],
          "val_accuracy": [
            0.985587899543379,
            0.98787100456621,
            0.9888698630136986,
            0.9891552511415526,
            0.990296803652968,
            0.9908675799086758,
            0.9907248858447488,
            0.9910102739726028
          ],
          "val_f1": [
            0.9569296375266525,
            0.9639372083156555,
            0.9669491525423729,
            0.9677966101694915,
            0.9712351945854484,
            0.9729501267962807,
            0.9724925941599661,
            0.9733615221987315
          ],
          "val_auroc": [
            0.9984895710043487,
            0.9989398625439401,
            0.999091750859602,
            0.9991195492871853,
            0.999247579674019,
            0.9992835456808408,
            0.9992705062122321,
            0.9992667806497724
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.032578468322753906,
          "accuracy": 0.9910102739726028,
          "precision": 0.9896818572656921,
          "recall": 0.9575707154742097,
          "f1": 0.9733615221987315,
          "auroc": 0.9992667806497724
        },
        "best_val_f1": 0.9733615221987315,
        "training_time": 8.076337575912476,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_46.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_46_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_46_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_46_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "47": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.47.hook_resid_pre",
        "hook_layer": 47,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_47",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09555518751343091,
            0.03783369303965881,
            0.028537390096597885,
            0.024942260842608737,
            0.022783189277338994,
            0.021472847951920577,
            0.020694026848956194,
            0.020017001837423946
          ],
          "train_accuracy": [
            0.9681056011416339,
            0.9917588298251873,
            0.9949696753478416,
            0.9963253656796289,
            0.9970745629682483,
            0.9976453799500535,
            0.9978237602568676,
            0.9981448448091331
          ],
          "val_loss": [
            0.05202050642533736,
            0.03996662226590243,
            0.03594116080891002,
            0.03429725603623824,
            0.03341053615916859,
            0.033264415914362126,
            0.031607320091941137,
            0.03194413185119629
          ],
          "val_accuracy": [
            0.9851598173515982,
            0.9897260273972602,
            0.9908675799086758,
            0.9898687214611872,
            0.990296803652968,
            0.990154109589041,
            0.9908675799086758,
            0.990296803652968
          ],
          "val_f1": [
            0.9560439560439561,
            0.97,
            0.9733333333333334,
            0.9702804520719966,
            0.9715481171548117,
            0.9710934227063259,
            0.9732888146911519,
            0.9715719063545151
          ],
          "val_auroc": [
            0.998590015816651,
            0.9991190243896935,
            0.9993768984354325,
            0.9994561086524361,
            0.9994781154090746,
            0.9995132415783246,
            0.9995432892652734,
            0.9994946910110298
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03194413185119629,
          "accuracy": 0.990296803652968,
          "precision": 0.9965694682675815,
          "recall": 0.9477977161500816,
          "f1": 0.9715719063545151,
          "auroc": 0.9994946910110298
        },
        "best_val_f1": 0.9733333333333334,
        "training_time": 7.973113059997559,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_47.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_47_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_47_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_47_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "48": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.48.hook_resid_pre",
        "hook_layer": 48,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_48",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09599078460235029,
            0.038308892696755664,
            0.029330791093272978,
            0.025494435644755353,
            0.023596093780467432,
            0.022195756164290113,
            0.02133450863806352,
            0.020649492070844322
          ],
          "train_accuracy": [
            0.9683910096325365,
            0.9910096325365679,
            0.9945772386728505,
            0.9958259008205494,
            0.9963967178023546,
            0.9970745629682483,
            0.9971459150909739,
            0.9976810560114163
          ],
          "val_loss": [
            0.05348408438942649,
            0.04155950979752974,
            0.03751217235218395,
            0.0352638228373094,
            0.03394360596483404,
            0.03348084363070401,
            0.03276035568930886,
            0.03203296661376953
          ],
          "val_accuracy": [
            0.9840182648401826,
            0.9888698630136986,
            0.990296803652968,
            0.990582191780822,
            0.9912956621004566,
            0.9914383561643836,
            0.9917237442922374,
            0.9912956621004566
          ],
          "val_f1": [
            0.9524214103653356,
            0.9671993271656855,
            0.9715004191114837,
            0.9722921914357683,
            0.9744876620660812,
            0.9748743718592965,
            0.9757322175732217,
            0.9744876620660812
          ],
          "val_auroc": [
            0.9984243381297252,
            0.9990787400725138,
            0.9992437958890666,
            0.9993478697931811,
            0.9994047341841742,
            0.9994101295571024,
            0.9994616695669163,
            0.9994781396526969
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03203296661376953,
          "accuracy": 0.9912956621004566,
          "precision": 0.9914893617021276,
          "recall": 0.9580592105263158,
          "f1": 0.9744876620660812,
          "auroc": 0.9994781396526969
        },
        "best_val_f1": 0.9757322175732217,
        "training_time": 8.066125631332397,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_48.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_48_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_48_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_48_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "49": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.49.hook_resid_pre",
        "hook_layer": 49,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_49",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09501251651901224,
            0.036981898767142196,
            0.028166180514819818,
            0.024330070792999307,
            0.02240833292872598,
            0.021021351241612952,
            0.020234397051167,
            0.01960522399101083
          ],
          "train_accuracy": [
            0.9685693899393507,
            0.9920442383160899,
            0.9948269711023903,
            0.9963253656796289,
            0.9970388869068855,
            0.9973599714591509,
            0.9976453799500535,
            0.9975383517659651
          ],
          "val_loss": [
            0.05210804505781694,
            0.04036052877252752,
            0.03593532388860529,
            0.03469633189114657,
            0.033251931450583715,
            0.03266827409917658,
            0.031919730793346056,
            0.03197700760581277
          ],
          "val_accuracy": [
            0.985445205479452,
            0.9885844748858448,
            0.9894406392694064,
            0.9895833333333334,
            0.990154109589041,
            0.990582191780822,
            0.9910102739726028,
            0.9908675799086758
          ],
          "val_f1": [
            0.9578512396694215,
            0.967373572593801,
            0.9697712418300654,
            0.9701675521046179,
            0.9718482252141983,
            0.9731051344743277,
            0.9744006501422187,
            0.9739413680781759
          ],
          "val_auroc": [
            0.9989546139181176,
            0.9993911731330094,
            0.9995849222702853,
            0.9995688458039591,
            0.9996006522610441,
            0.9996165901371433,
            0.9996334981448312,
            0.9996375865565261
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03197700760581277,
          "accuracy": 0.9908675799086758,
          "precision": 0.9950083194675541,
          "recall": 0.9537480063795853,
          "f1": 0.9739413680781759,
          "auroc": 0.9996375865565261
        },
        "best_val_f1": 0.9744006501422187,
        "training_time": 8.021436214447021,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_49.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_49_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_49_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_49_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "50": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.50.hook_resid_pre",
        "hook_layer": 50,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_50",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.093757058576719,
            0.03615893308843005,
            0.027191501920915222,
            0.02387262327111747,
            0.02175483841993357,
            0.020556463462355883,
            0.019777582806309677,
            0.01917037593740885
          ],
          "train_accuracy": [
            0.9685693899393507,
            0.9925080271138066,
            0.9956118444523725,
            0.9965394220478059,
            0.9973599714591509,
            0.997752408134142,
            0.9978237602568676,
            0.9977167320727791
          ],
          "val_loss": [
            0.05266489115628329,
            0.041516815532337534,
            0.03773480762134899,
            0.03577918572859331,
            0.03476530421863903,
            0.034511696208607064,
            0.03358590927991,
            0.03267131718722257
          ],
          "val_accuracy": [
            0.9821632420091324,
            0.9867294520547946,
            0.988156392694064,
            0.9890125570776256,
            0.9888698630136986,
            0.9887271689497716,
            0.9887271689497716,
            0.990154109589041
          ],
          "val_f1": [
            0.9464209172738963,
            0.9606099110546379,
            0.9649936735554618,
            0.9675789473684211,
            0.9671717171717171,
            0.9666807254323071,
            0.9666525960320811,
            0.9710934227063259
          ],
          "val_auroc": [
            0.9987685251545658,
            0.9992848677012341,
            0.9994218637794998,
            0.999514235034757,
            0.9994759243758946,
            0.9994685460267803,
            0.9995873800149184,
            0.9995862448842855
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03267131718722257,
          "accuracy": 0.990154109589041,
          "precision": 0.9905982905982906,
          "recall": 0.952341824157765,
          "f1": 0.9710934227063259,
          "auroc": 0.9995862448842855
        },
        "best_val_f1": 0.9710934227063259,
        "training_time": 8.822291135787964,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_50.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_50_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_50_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_50_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "51": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.51.hook_resid_pre",
        "hook_layer": 51,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_51",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09606237729084274,
            0.0367885792678962,
            0.02796599560217362,
            0.024194575408707505,
            0.022091949754075645,
            0.02080469207889209,
            0.019983045097661616,
            0.019409341536691948
          ],
          "train_accuracy": [
            0.9672136996075633,
            0.9925793792365323,
            0.9953621120228326,
            0.9968248305387085,
            0.9975026757046022,
            0.9979307884409562,
            0.9978594363182305,
            0.9983232251159472
          ],
          "val_loss": [
            0.04848812276666815,
            0.039324738762595436,
            0.03432950106534091,
            0.0326325850053267,
            0.03149721405722878,
            0.031177997589111328,
            0.030670252713290127,
            0.030254450711337002
          ],
          "val_accuracy": [
            0.9853025114155252,
            0.9888698630136986,
            0.9911529680365296,
            0.9910102739726028,
            0.9914383561643836,
            0.9911529680365296,
            0.9912956621004566,
            0.9912956621004566
          ],
          "val_f1": [
            0.9569577935645633,
            0.9677685950413223,
            0.9743589743589743,
            0.9738914214670534,
            0.9751655629139073,
            0.9743164871582436,
            0.9747412008281573,
            0.974762101779065
          ],
          "val_auroc": [
            0.9988902646697222,
            0.9992218504506458,
            0.9994650133566566,
            0.9995059054050389,
            0.9995258217394842,
            0.9995111316771983,
            0.9995229967275061,
            0.9995314717634404
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030254450711337002,
          "accuracy": 0.9912956621004566,
          "precision": 0.9874266554903605,
          "recall": 0.9624183006535948,
          "f1": 0.974762101779065,
          "auroc": 0.9995314717634404
        },
        "best_val_f1": 0.9751655629139073,
        "training_time": 8.877136468887329,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_51.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_51_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_51_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_51_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "52": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.52.hook_resid_pre",
        "hook_layer": 52,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_52",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09592619771350465,
            0.03713113750165252,
            0.028162022525249006,
            0.02432053441343378,
            0.022247882521621985,
            0.020965895443287207,
            0.020096958827516533,
            0.01947313813985959
          ],
          "train_accuracy": [
            0.9676418123439172,
            0.9915804495183732,
            0.9954334641455583,
            0.9964680699250803,
            0.9969675347841598,
            0.997752408134142,
            0.9980378166250446,
            0.9981448448091331
          ],
          "val_loss": [
            0.049377424066716975,
            0.038161516189575195,
            0.03471742543307218,
            0.03262676352804357,
            0.03143668608231978,
            0.030612945556640625,
            0.030224505337801848,
            0.030147201364690606
          ],
          "val_accuracy": [
            0.9861586757990868,
            0.9894406392694064,
            0.9900114155251142,
            0.990154109589041,
            0.9900114155251142,
            0.9908675799086758,
            0.990582191780822,
            0.990582191780822
          ],
          "val_f1": [
            0.9586000853606488,
            0.9686706181202371,
            0.9702633814783348,
            0.9707006369426752,
            0.9702886247877759,
            0.9728583545377438,
            0.9719864176570459,
            0.9720101781170484
          ],
          "val_auroc": [
            0.9989884409039437,
            0.9993686280427355,
            0.9994364673263756,
            0.9995106239189684,
            0.9995610906029886,
            0.9995884416792499,
            0.9995868623520117,
            0.9995897338560811
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030147201364690606,
          "accuracy": 0.990582191780822,
          "precision": 0.9887834339948232,
          "recall": 0.9557964970809008,
          "f1": 0.9720101781170484,
          "auroc": 0.9995897338560811
        },
        "best_val_f1": 0.9728583545377438,
        "training_time": 8.634343147277832,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_52.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_52_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_52_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_52_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "53": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.53.hook_resid_pre",
        "hook_layer": 53,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_53",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0903614510241981,
            0.033941973876803436,
            0.025410262163469068,
            0.021990649377689037,
            0.020218516268329396,
            0.018919921684244723,
            0.018233097998263764,
            0.017611313301891293
          ],
          "train_accuracy": [
            0.9698537281484124,
            0.9929361398501605,
            0.9961469853728149,
            0.9970032108455227,
            0.9977167320727791,
            0.9978951123795933,
            0.9981448448091331,
            0.9983945772386729
          ],
          "val_loss": [
            0.04518268325112083,
            0.03491144613786177,
            0.031394880468195135,
            0.030676624991677025,
            0.02969732718034224,
            0.028674221038818358,
            0.028411032936789773,
            0.027981597726995294
          ],
          "val_accuracy": [
            0.985587899543379,
            0.990582191780822,
            0.9900114155251142,
            0.990582191780822,
            0.990439497716895,
            0.9914383561643836,
            0.9910102739726028,
            0.9911529680365296
          ],
          "val_f1": [
            0.9571489181162495,
            0.9724540901502504,
            0.9706129303106633,
            0.9722921914357683,
            0.9718369062631358,
            0.9748953974895398,
            0.9735849056603774,
            0.974036850921273
          ],
          "val_auroc": [
            0.9988825570279771,
            0.9995566481032756,
            0.9996208370984243,
            0.999628514187545,
            0.9996371864548851,
            0.9996587249549184,
            0.9996666863806734,
            0.9996588671232355
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.027981597726995294,
          "accuracy": 0.9911529680365296,
          "precision": 0.9906303236797275,
          "recall": 0.9579901153212521,
          "f1": 0.974036850921273,
          "auroc": 0.9996588671232355
        },
        "best_val_f1": 0.9748953974895398,
        "training_time": 8.717433214187622,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_53.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_53_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_53_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_53_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "54": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.54.hook_resid_pre",
        "hook_layer": 54,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_54",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09063066561923247,
            0.03324721458465813,
            0.024878896500694154,
            0.021386059307276387,
            0.01964615875659468,
            0.01852246542880099,
            0.017710237125929906,
            0.017161188970349694
          ],
          "train_accuracy": [
            0.9704958972529433,
            0.9935069568319658,
            0.9963253656796289,
            0.9976097038886906,
            0.9981805208704959,
            0.9982875490545844,
            0.9986443096682126,
            0.9988940420977525
          ],
          "val_loss": [
            0.047345152768221765,
            0.03703961805863814,
            0.03429985046386719,
            0.03278680281205611,
            0.031743036616932264,
            0.03127258907664906,
            0.031467797539450906,
            0.030611909519542346
          ],
          "val_accuracy": [
            0.9848744292237442,
            0.9887271689497716,
            0.9900114155251142,
            0.9898687214611872,
            0.9907248858447488,
            0.990154109589041,
            0.9894406392694064,
            0.9911529680365296
          ],
          "val_f1": [
            0.9542709232096636,
            0.9661089661089661,
            0.9700342465753424,
            0.9695409695409696,
            0.9721627408993576,
            0.9704749679075738,
            0.968103448275862,
            0.9734816082121471
          ],
          "val_auroc": [
            0.9989677917700144,
            0.9993978483403874,
            0.9994288616869956,
            0.9994425568330446,
            0.9995184960555805,
            0.9995032792266372,
            0.9994778453839749,
            0.9995053081371631
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030611909519542346,
          "accuracy": 0.9911529680365296,
          "precision": 0.986990459670425,
          "recall": 0.960337552742616,
          "f1": 0.9734816082121471,
          "auroc": 0.9995053081371631
        },
        "best_val_f1": 0.9734816082121471,
        "training_time": 8.605661392211914,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_54.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_54_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_54_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_54_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "55": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.55.hook_resid_pre",
        "hook_layer": 55,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_55",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0916643412188376,
            0.0332438215681407,
            0.025104638831222166,
            0.021660031938976417,
            0.01979439589088638,
            0.018596094169709237,
            0.01785159241790845,
            0.017294392411779935
          ],
          "train_accuracy": [
            0.9693542632893328,
            0.9932929004637888,
            0.9961826614341777,
            0.9970745629682483,
            0.9976453799500535,
            0.997966464502319,
            0.9981448448091331,
            0.9984302533000357
          ],
          "val_loss": [
            0.045530598813837225,
            0.03670777841047807,
            0.033232719247991385,
            0.031938669898293234,
            0.030573090639981357,
            0.029947965795343572,
            0.02948984666304155,
            0.02910972075028853
          ],
          "val_accuracy": [
            0.9873002283105022,
            0.9892979452054794,
            0.9912956621004566,
            0.990296803652968,
            0.9912956621004566,
            0.9914383561643836,
            0.9918664383561644,
            0.9921518264840182
          ],
          "val_f1": [
            0.961488533102553,
            0.9676305567544238,
            0.9737859905457671,
            0.9706390328151986,
            0.9737408523461042,
            0.9742046431642304,
            0.9755888650963598,
            0.9764049764049764
          ],
          "val_auroc": [
            0.9989073492491461,
            0.9991130596599347,
            0.9993654664064819,
            0.9993669891130829,
            0.9994096248979062,
            0.9994445746398871,
            0.9994803219900876,
            0.9995033801186145
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.02910972075028853,
          "accuracy": 0.9921518264840182,
          "precision": 0.992153443766347,
          "recall": 0.9611486486486487,
          "f1": 0.9764049764049764,
          "auroc": 0.9995033801186145
        },
        "best_val_f1": 0.9764049764049764,
        "training_time": 8.575122833251953,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_55.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_55_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_55_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_55_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "56": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.56.hook_resid_pre",
        "hook_layer": 56,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_56",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0895599628794411,
            0.032279845315444214,
            0.023837433562329098,
            0.020725978861592675,
            0.01876340689032326,
            0.017754189463834103,
            0.01692869275017348,
            0.016319572472664183
          ],
          "train_accuracy": [
            0.9703888690688548,
            0.9936139850160542,
            0.9961469853728149,
            0.9973599714591509,
            0.9978594363182305,
            0.9982518729932216,
            0.9983945772386729,
            0.9985372814841241
          ],
          "val_loss": [
            0.04980659918351607,
            0.03944588141007857,
            0.035686707496643065,
            0.034311894259669566,
            0.03372625762766058,
            0.032974069768732246,
            0.03283265720714222,
            0.03191508813337846
          ],
          "val_accuracy": [
            0.9853025114155252,
            0.9873002283105022,
            0.9890125570776256,
            0.9890125570776256,
            0.9892979452054794,
            0.9891552511415526,
            0.9895833333333334,
            0.990296803652968
          ],
          "val_f1": [
            0.9579076420106253,
            0.963298969072165,
            0.9685328974254189,
            0.9685071574642127,
            0.969224456298728,
            0.9689795918367347,
            0.9700451374640952,
            0.9721539721539721
          ],
          "val_auroc": [
            0.998750899050622,
            0.9992629420485923,
            0.9993449997751938,
            0.9993449997751938,
            0.999373535541018,
            0.9993381790311677,
            0.9993998441251193,
            0.9994119544257373
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03191508813337846,
          "accuracy": 0.990296803652968,
          "precision": 0.9933054393305439,
          "recall": 0.9518845228548516,
          "f1": 0.9721539721539721,
          "auroc": 0.9994119544257373
        },
        "best_val_f1": 0.9721539721539721,
        "training_time": 8.237802505493164,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_56.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_56_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_56_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_56_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "57": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.57.hook_resid_pre",
        "hook_layer": 57,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_57",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08834782427338432,
            0.03135264751003825,
            0.023552397580723784,
            0.020128017438141858,
            0.018218597668312388,
            0.017208789930291915,
            0.0165082275783473,
            0.015973239402461065
          ],
          "train_accuracy": [
            0.9702818408847663,
            0.9936853371387799,
            0.9967534784159828,
            0.9976810560114163,
            0.9978237602568676,
            0.9984302533000357,
            0.9984659293613986,
            0.9988226899750268
          ],
          "val_loss": [
            0.0468076153235002,
            0.03841242356733842,
            0.034795895489779384,
            0.03306177746165882,
            0.03256910064003684,
            0.03207011656327681,
            0.0315903750332919,
            0.030909274924885145
          ],
          "val_accuracy": [
            0.9865867579908676,
            0.988013698630137,
            0.9897260273972602,
            0.9885844748858448,
            0.9892979452054794,
            0.9884417808219178,
            0.9884417808219178,
            0.9898687214611872
          ],
          "val_f1": [
            0.9607023411371237,
            0.9650291423813488,
            0.9702725020644096,
            0.9667774086378738,
            0.9690210656753407,
            0.9664596273291925,
            0.9664318276004973,
            0.9706732755059893
          ],
          "val_auroc": [
            0.9990073083493036,
            0.9993184127064532,
            0.9993981938780967,
            0.9994862767942321,
            0.9994588388251483,
            0.9994784675261084,
            0.9995106895513399,
            0.9995243381821151
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030909274924885145,
          "accuracy": 0.9898687214611872,
          "precision": 0.9865659109991604,
          "recall": 0.9552845528455285,
          "f1": 0.9706732755059893,
          "auroc": 0.9995243381821151
        },
        "best_val_f1": 0.9706732755059893,
        "training_time": 8.533679485321045,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_57.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_57_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_57_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_57_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "58": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.58.hook_resid_pre",
        "hook_layer": 58,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_58",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09067667848069101,
            0.032687565943302764,
            0.024109360051753858,
            0.020650514983040488,
            0.018760650307067656,
            0.017560793167686082,
            0.01679446592025425,
            0.016165829431605803
          ],
          "train_accuracy": [
            0.9696396717802355,
            0.9931858722797003,
            0.9964323938637174,
            0.9974669996432394,
            0.9979307884409562,
            0.9982518729932216,
            0.9986799857295755,
            0.9987156617909383
          ],
          "val_loss": [
            0.046122195503928445,
            0.034713944521817294,
            0.031464853069999,
            0.029494029825383968,
            0.029220767454667524,
            0.028963784738020464,
            0.02845776297829368,
            0.028143033114346593
          ],
          "val_accuracy": [
            0.985445205479452,
            0.9911529680365296,
            0.9920091324200914,
            0.9931506849315068,
            0.992865296803653,
            0.9924372146118722,
            0.992865296803653,
            0.992722602739726
          ],
          "val_f1": [
            0.9558441558441558,
            0.9735720375106565,
            0.9762107051826678,
            0.979557069846678,
            0.9787414965986394,
            0.9774946921443737,
            0.9787234042553191,
            0.9783071033602723
          ],
          "val_auroc": [
            0.9990346985943351,
            0.9994793087488942,
            0.9995137143914196,
            0.9996116049224542,
            0.9995731684933569,
            0.9995332924976265,
            0.9995407782441174,
            0.9995974971694521
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.028143033114346593,
          "accuracy": 0.992722602739726,
          "precision": 0.9948096885813149,
          "recall": 0.9623430962343096,
          "f1": 0.9783071033602723,
          "auroc": 0.9995974971694521
        },
        "best_val_f1": 0.979557069846678,
        "training_time": 8.553365468978882,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_58.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_58_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_58_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_58_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "59": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.59.hook_resid_pre",
        "hook_layer": 59,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_59",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09034901100410718,
            0.03234262106999687,
            0.023603845223971562,
            0.020166266600061294,
            0.01847742035714952,
            0.017307638071613497,
            0.016547097100506294,
            0.0160236418157918
          ],
          "train_accuracy": [
            0.9699607563325009,
            0.9929718159115234,
            0.9965394220478059,
            0.9972172672136996,
            0.9979307884409562,
            0.9980734926864074,
            0.9982875490545844,
            0.9984302533000357
          ],
          "val_loss": [
            0.046215911345048384,
            0.03631831082430753,
            0.03307138356295499,
            0.03165669441223144,
            0.03124713897705078,
            0.030857541344382546,
            0.03076735409823331,
            0.02992266308177601
          ],
          "val_accuracy": [
            0.9851598173515982,
            0.9894406392694064,
            0.9884417808219178,
            0.9890125570776256,
            0.9888698630136986,
            0.9892979452054794,
            0.9890125570776256,
            0.990296803652968
          ],
          "val_f1": [
            0.9539823008849557,
            0.967741935483871,
            0.9644268774703557,
            0.9662132514260641,
            0.9656992084432717,
            0.9671772428884027,
            0.9661240651121865,
            0.9702537182852143
          ],
          "val_auroc": [
            0.9990963033967696,
            0.9994169249757242,
            0.9995470514184296,
            0.9995697171855074,
            0.9995689103135402,
            0.9995312807390713,
            0.999558420977967,
            0.9995448508585192
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.02992266308177601,
          "accuracy": 0.990296803652968,
          "precision": 0.9910634495084897,
          "recall": 0.9502999143101971,
          "f1": 0.9702537182852143,
          "auroc": 0.9995448508585192
        },
        "best_val_f1": 0.9702537182852143,
        "training_time": 8.358946800231934,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_59.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_59_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_59_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_59_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "60": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.60.hook_resid_pre",
        "hook_layer": 60,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_60",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09066004790025486,
            0.031695346092830784,
            0.023426306812458386,
            0.01993283797395692,
            0.018171415772697288,
            0.017026085324147417,
            0.01635048066618848,
            0.015731890053279934
          ],
          "train_accuracy": [
            0.9701391366393151,
            0.9935426328933286,
            0.9965394220478059,
            0.9973599714591509,
            0.9980021405636817,
            0.998572957545487,
            0.9987156617909383,
            0.9988940420977525
          ],
          "val_loss": [
            0.044532489776611325,
            0.0370294527574019,
            0.03371824784712358,
            0.03268037709322843,
            0.032973159443248405,
            0.03195074688304554,
            0.030960330096158114,
            0.031018057736483487
          ],
          "val_accuracy": [
            0.9871575342465754,
            0.9887271689497716,
            0.9894406392694064,
            0.9890125570776256,
            0.990439497716895,
            0.9885844748858448,
            0.9898687214611872,
            0.9891552511415526
          ],
          "val_f1": [
            0.9615713065755764,
            0.9664543524416136,
            0.9685106382978723,
            0.9673036093418259,
            0.9718605627887442,
            0.9658994032395567,
            0.9698769622401358,
            0.9676595744680851
          ],
          "val_auroc": [
            0.9989868330037925,
            0.9992712193921143,
            0.9993634956132805,
            0.9994053870022968,
            0.9993845132861203,
            0.9994007803890718,
            0.9994295717217289,
            0.9994158238603852
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.031018057736483487,
          "accuracy": 0.9891552511415526,
          "precision": 0.9844155844155844,
          "recall": 0.9514644351464435,
          "f1": 0.9676595744680851,
          "auroc": 0.9994158238603852
        },
        "best_val_f1": 0.9718605627887442,
        "training_time": 8.322839260101318,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_60.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_60_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_60_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_60_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "61": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.61.hook_resid_pre",
        "hook_layer": 61,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_61",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09192847270416478,
            0.03247376714012326,
            0.023605306762521535,
            0.020159293092642677,
            0.018424309698703217,
            0.017246911297956285,
            0.016422860699676013,
            0.015868012040649374
          ],
          "train_accuracy": [
            0.9688904744916161,
            0.9927577595433464,
            0.9967891544773457,
            0.9975740278273278,
            0.9980021405636817,
            0.9983945772386729,
            0.9986443096682126,
            0.9986799857295755
          ],
          "val_loss": [
            0.04483029192144221,
            0.03412897370078347,
            0.030437863956798206,
            0.028909587860107423,
            0.028039143302223898,
            0.027505644884976473,
            0.026995650204745206,
            0.026426436684348367
          ],
          "val_accuracy": [
            0.98787100456621,
            0.9914383561643836,
            0.9911529680365296,
            0.9922945205479452,
            0.9915810502283106,
            0.9920091324200914,
            0.992865296803653,
            0.9931506849315068
          ],
          "val_f1": [
            0.9621043245653144,
            0.9731663685152058,
            0.9722222222222222,
            0.9758064516129032,
            0.9735069600359227,
            0.974910394265233,
            0.9776186213070726,
            0.9785714285714285
          ],
          "val_auroc": [
            0.9987596277124171,
            0.9991393089695881,
            0.9993307657429035,
            0.9994423173140066,
            0.9993978921263232,
            0.9993970652615779,
            0.9994093178937139,
            0.9994746402085986
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.026426436684348367,
          "accuracy": 0.9931506849315068,
          "precision": 0.9891696750902527,
          "recall": 0.9681978798586572,
          "f1": 0.9785714285714285,
          "auroc": 0.9994746402085986
        },
        "best_val_f1": 0.9785714285714285,
        "training_time": 8.454217672348022,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_61.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_61_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_61_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_61_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "62": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.62.hook_resid_pre",
        "hook_layer": 62,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_62",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09052567095517024,
            0.031140362218736787,
            0.022748233158285964,
            0.019556275824059364,
            0.017740074503416255,
            0.016627948142728475,
            0.01580169400546836,
            0.015456427396891733
          ],
          "train_accuracy": [
            0.9691402069211559,
            0.9939350695683197,
            0.9968248305387085,
            0.997752408134142,
            0.9983232251159472,
            0.9984302533000357,
            0.9988583660363896,
            0.9988583660363896
          ],
          "val_loss": [
            0.0497509089383212,
            0.03922371864318848,
            0.03681709116155451,
            0.035473257303237915,
            0.034651630575006656,
            0.03404551852833141,
            0.03429431915283203,
            0.033814252506602895
          ],
          "val_accuracy": [
            0.9853025114155252,
            0.9877283105022832,
            0.9875856164383562,
            0.9873002283105022,
            0.9884417808219178,
            0.9884417808219178,
            0.9890125570776256,
            0.9877283105022832
          ],
          "val_f1": [
            0.9566315789473684,
            0.9641068447412354,
            0.9636135508155583,
            0.9626207475850483,
            0.9661229611041405,
            0.9660661918726435,
            0.9678228165482657,
            0.9638958858102435
          ],
          "val_auroc": [
            0.9980421240620332,
            0.9987934210367415,
            0.998867726694414,
            0.9989718682758175,
            0.9990098025217038,
            0.9989762015885498,
            0.998971157896681,
            0.9990229445357282
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.033814252506602895,
          "accuracy": 0.9877283105022832,
          "precision": 0.9837189374464439,
          "recall": 0.9448559670781893,
          "f1": 0.9638958858102435,
          "auroc": 0.9990229445357282
        },
        "best_val_f1": 0.9678228165482657,
        "training_time": 8.44134521484375,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_62.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_62_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_62_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_62_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "63": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.63.hook_resid_pre",
        "hook_layer": 63,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_63",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09064341316076174,
            0.031845470832992495,
            0.022891051221541107,
            0.01955052271493834,
            0.017756432195972293,
            0.01669283733399134,
            0.01599862985631885,
            0.01530967803871829
          ],
          "train_accuracy": [
            0.9691758829825188,
            0.9932929004637888,
            0.9965394220478059,
            0.9978594363182305,
            0.9983945772386729,
            0.9986086336068498,
            0.9987156617909383,
            0.998965394220478
          ],
          "val_loss": [
            0.04901227084073154,
            0.03764364502646706,
            0.03381468599492853,
            0.03258479508486661,
            0.03153161569075151,
            0.03067951635880904,
            0.030063390731811523,
            0.03022044355219061
          ],
          "val_accuracy": [
            0.9848744292237442,
            0.9882990867579908,
            0.9891552511415526,
            0.990296803652968,
            0.990439497716895,
            0.9910102739726028,
            0.9912956621004566,
            0.990582191780822
          ],
          "val_f1": [
            0.9542709232096636,
            0.9647160068846816,
            0.9674378748928878,
            0.9710144927536232,
            0.9714529186195143,
            0.973225669358266,
            0.9740976645435244,
            0.9718909710391823
          ],
          "val_auroc": [
            0.9978648347701409,
            0.998900027135831,
            0.9990865229931182,
            0.9991336688003443,
            0.9990564360504914,
            0.9991076126442896,
            0.9991553342781689,
            0.9991229440289295
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03022044355219061,
          "accuracy": 0.990582191780822,
          "precision": 0.98959236773634,
          "recall": 0.9548117154811715,
          "f1": 0.9718909710391823,
          "auroc": 0.9991229440289295
        },
        "best_val_f1": 0.9740976645435244,
        "training_time": 8.346702575683594,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_63.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_63_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_63_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_63_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "64": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.64.hook_resid_pre",
        "hook_layer": 64,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_64",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09137521385636231,
            0.031543403492866245,
            0.02279666845673976,
            0.019278180908271405,
            0.017595903044268828,
            0.016378548084524328,
            0.015761224538104857,
            0.015309223920089878
          ],
          "train_accuracy": [
            0.9702818408847663,
            0.9935069568319658,
            0.99671780235462,
            0.9976453799500535,
            0.9982518729932216,
            0.9986799857295755,
            0.9986799857295755,
            0.998787013913664
          ],
          "val_loss": [
            0.04569927995855158,
            0.03655901822176846,
            0.033990027687766336,
            0.0327253905209628,
            0.03210492134094238,
            0.03158176162026145,
            0.030900335311889647,
            0.03112626075744629
          ],
          "val_accuracy": [
            0.9837328767123288,
            0.9898687214611872,
            0.9888698630136986,
            0.9897260273972602,
            0.990154109589041,
            0.9898687214611872,
            0.9907248858447488,
            0.990154109589041
          ],
          "val_f1": [
            0.9507346585998271,
            0.9698769622401358,
            0.9666666666666667,
            0.9693877551020408,
            0.9707006369426752,
            0.9698513800424629,
            0.9724925941599661,
            0.9707750952986023
          ],
          "val_auroc": [
            0.9989266533335527,
            0.9992267556557882,
            0.999407160268369,
            0.999373982408584,
            0.9993734103765187,
            0.9993743399286246,
            0.9993779866330407,
            0.999322571026719
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03112626075744629,
          "accuracy": 0.990154109589041,
          "precision": 0.9913494809688581,
          "recall": 0.9510373443983402,
          "f1": 0.9707750952986023,
          "auroc": 0.999322571026719
        },
        "best_val_f1": 0.9724925941599661,
        "training_time": 8.327501058578491,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_64.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_64_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_64_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_64_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "65": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.65.hook_resid_pre",
        "hook_layer": 65,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_65",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09085697598211025,
            0.031234239879251377,
            0.022140031791032723,
            0.01900046746316685,
            0.017153581493793556,
            0.016086692390240492,
            0.01541872765043895,
            0.014872532531397935
          ],
          "train_accuracy": [
            0.9688547984302534,
            0.9933285765251516,
            0.9971459150909739,
            0.9977880841955048,
            0.9982875490545844,
            0.9984659293613986,
            0.9987156617909383,
            0.9990367463432037
          ],
          "val_loss": [
            0.04990114298733798,
            0.040049992908130994,
            0.036916617913679645,
            0.03628752448342063,
            0.034691275520758194,
            0.03453695990822532,
            0.034707134420221504,
            0.03458016568964178
          ],
          "val_accuracy": [
            0.9834474885844748,
            0.985730593607306,
            0.98787100456621,
            0.9870148401826484,
            0.9887271689497716,
            0.988156392694064,
            0.9875856164383562,
            0.98787100456621
          ],
          "val_f1": [
            0.9507640067911715,
            0.9582289055973267,
            0.964509394572025,
            0.9617807643847123,
            0.9670970428987922,
            0.9653733833959116,
            0.9636135508155583,
            0.9644797325532805
          ],
          "val_auroc": [
            0.9983582482694551,
            0.9989933242321593,
            0.9991152554182198,
            0.9991478978553706,
            0.9991835142238888,
            0.9991687153749419,
            0.999144994731893,
            0.9991601476202885
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03458016568964178,
          "accuracy": 0.98787100456621,
          "precision": 0.9838022165387894,
          "recall": 0.9459016393442623,
          "f1": 0.9644797325532805,
          "auroc": 0.9991601476202885
        },
        "best_val_f1": 0.9670970428987922,
        "training_time": 8.364035367965698,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_65.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_65_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_65_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_65_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "66": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.66.hook_resid_pre",
        "hook_layer": 66,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_66",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09185005724004823,
            0.031143320537253057,
            0.022355537019567946,
            0.01908084590596117,
            0.017343277983435487,
            0.016287272162395252,
            0.015587769397725798,
            0.014988725987947695
          ],
          "train_accuracy": [
            0.9679985729575454,
            0.9934356047092401,
            0.9965750981091688,
            0.9976453799500535,
            0.9983232251159472,
            0.9987513378523011,
            0.9988583660363896,
            0.998965394220478
          ],
          "val_loss": [
            0.047705338217995386,
            0.0379166993227872,
            0.03498163277452642,
            0.03324392058632591,
            0.032401264797557484,
            0.03143222982233221,
            0.031825587966225366,
            0.031822195920077234
          ],
          "val_accuracy": [
            0.9853025114155252,
            0.9885844748858448,
            0.98787100456621,
            0.9898687214611872,
            0.9895833333333334,
            0.990439497716895,
            0.9895833333333334,
            0.9895833333333334
          ],
          "val_f1": [
            0.9567771716323962,
            0.9667497921862012,
            0.9640591966173362,
            0.9700800674252001,
            0.9692113032475749,
            0.9718605627887442,
            0.9692372524230931,
            0.9692890197728229
          ],
          "val_auroc": [
            0.9984315539046345,
            0.9988742621824694,
            0.9990232997252964,
            0.999099807558292,
            0.9990959004730415,
            0.9991532280693529,
            0.9991041408710243,
            0.9991143703305891
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.031822195920077234,
          "accuracy": 0.9895833333333334,
          "precision": 0.9913941480206541,
          "recall": 0.9481481481481482,
          "f1": 0.9692890197728229,
          "auroc": 0.9991143703305891
        },
        "best_val_f1": 0.9718605627887442,
        "training_time": 8.5116446018219,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_66.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_66_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_66_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_66_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "67": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.67.hook_resid_pre",
        "hook_layer": 67,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_67",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08595079207393132,
            0.02723104981003865,
            0.01973424669138271,
            0.01669171208528521,
            0.015271393458899026,
            0.014319540777554115,
            0.013639345634345934,
            0.013253154569054576
          ],
          "train_accuracy": [
            0.970567249375669,
            0.9946129147342133,
            0.9975026757046022,
            0.9985016054227613,
            0.9987513378523011,
            0.9986799857295755,
            0.999179450588655,
            0.9990010702818409
          ],
          "val_loss": [
            0.045382944020358,
            0.03718782771717418,
            0.03534643650054932,
            0.034521832791241734,
            0.033788958462801846,
            0.03294236009771174,
            0.03313544446771795,
            0.0338655948638916
          ],
          "val_accuracy": [
            0.9858732876712328,
            0.9884417808219178,
            0.9888698630136986,
            0.988013698630137,
            0.988156392694064,
            0.9887271689497716,
            0.988156392694064,
            0.9874429223744292
          ],
          "val_f1": [
            0.9569377990430622,
            0.9647366129734436,
            0.9659982563208369,
            0.9636048526863085,
            0.964053702901689,
            0.9658452226545612,
            0.9639600521059488,
            0.9617058311575283
          ],
          "val_auroc": [
            0.9987094011376988,
            0.9991146627037214,
            0.9991843147633284,
            0.9991700644463315,
            0.9992283017112012,
            0.999252730826053,
            0.9992296831194816,
            0.9991721002059025
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.0338655948638916,
          "accuracy": 0.9874429223744292,
          "precision": 0.9883720930232558,
          "recall": 0.9364406779661016,
          "f1": 0.9617058311575283,
          "auroc": 0.9991721002059025
        },
        "best_val_f1": 0.9659982563208369,
        "training_time": 8.55476450920105,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_67.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_67_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_67_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_67_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "68": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.68.hook_resid_pre",
        "hook_layer": 68,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_68",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0860976404999489,
            0.027270808158927178,
            0.01913539864352509,
            0.01632633521359788,
            0.014810536805217125,
            0.014001548273242228,
            0.01328214387022401,
            0.012814155707484511
          ],
          "train_accuracy": [
            0.9711380663574741,
            0.9942918301819479,
            0.9974669996432394,
            0.9983232251159472,
            0.9988940420977525,
            0.998787013913664,
            0.999179450588655,
            0.9994291830181948
          ],
          "val_loss": [
            0.04448057954961603,
            0.036732118779962714,
            0.03464125719937411,
            0.032616923072121363,
            0.032436370849609375,
            0.03251641880382191,
            0.031749296188354495,
            0.03171067237854004
          ],
          "val_accuracy": [
            0.9873002283105022,
            0.9895833333333334,
            0.9892979452054794,
            0.990296803652968,
            0.9910102739726028,
            0.9897260273972602,
            0.990439497716895,
            0.990439497716895
          ],
          "val_f1": [
            0.961982058949167,
            0.9692631578947368,
            0.9681798896902842,
            0.9712837837837838,
            0.9734736842105263,
            0.9695173581710415,
            0.9717418810628426,
            0.9716941275876637
          ],
          "val_auroc": [
            0.9985584776816858,
            0.9989890872773906,
            0.9990242463583251,
            0.9990849367799788,
            0.9990592628060713,
            0.9990635418017225,
            0.999100198531135,
            0.999091070007079
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.03171067237854004,
          "accuracy": 0.990439497716895,
          "precision": 0.9930915371329879,
          "recall": 0.9511993382961125,
          "f1": 0.9716941275876637,
          "auroc": 0.999091070007079
        },
        "best_val_f1": 0.9734736842105263,
        "training_time": 8.244091510772705,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_68.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_68_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_68_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_68_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "69": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.69.hook_resid_pre",
        "hook_layer": 69,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_69",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0859707954539556,
            0.027614019632543604,
            0.019376014683557225,
            0.016364814955996326,
            0.014880631649526492,
            0.013916563154432123,
            0.013407303608547827,
            0.012918911749905306
          ],
          "train_accuracy": [
            0.9708169818052087,
            0.9946129147342133,
            0.9973956475205137,
            0.9983945772386729,
            0.998787013913664,
            0.9990010702818409,
            0.9988940420977525,
            0.9990724224045665
          ],
          "val_loss": [
            0.04369594400579279,
            0.03528810847889293,
            0.03268904685974121,
            0.03142556710676713,
            0.030950416218150745,
            0.031149877201427114,
            0.030504989624023437,
            0.030629942362958736
          ],
          "val_accuracy": [
            0.985445205479452,
            0.9874429223744292,
            0.9894406392694064,
            0.9891552511415526,
            0.9890125570776256,
            0.9891552511415526,
            0.9894406392694064,
            0.9897260273972602
          ],
          "val_f1": [
            0.9561101549053356,
            0.9624252775405636,
            0.9686706181202371,
            0.9677966101694915,
            0.9672200936568752,
            0.9676595744680851,
            0.9685641461342396,
            0.9694137638062872
          ],
          "val_auroc": [
            0.9989293813866482,
            0.9992180899414083,
            0.9992573714771117,
            0.9993133244113923,
            0.9993281354822312,
            0.9993211234776795,
            0.9993236993160862,
            0.9993044520791023
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030629942362958736,
          "accuracy": 0.9897260273972602,
          "precision": 0.9921739130434782,
          "recall": 0.9476744186046512,
          "f1": 0.9694137638062872,
          "auroc": 0.9993044520791023
        },
        "best_val_f1": 0.9694137638062872,
        "training_time": 8.319566011428833,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_69.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_69_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_69_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_69_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "70": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.70.hook_resid_pre",
        "hook_layer": 70,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_70",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08555513705854138,
            0.026678833174923238,
            0.01869087864232322,
            0.01591800591062125,
            0.01430746619951099,
            0.013444462288213579,
            0.012797002197927945,
            0.01242115385149984
          ],
          "train_accuracy": [
            0.9712807706029254,
            0.9942204780592223,
            0.9975740278273278,
            0.9984302533000357,
            0.9988583660363896,
            0.998965394220478,
            0.9992508027113807,
            0.999179450588655
          ],
          "val_loss": [
            0.041398533907803625,
            0.03298770731145685,
            0.03193972327492454,
            0.03109071037986062,
            0.031167744506489146,
            0.029227564551613548,
            0.030369645898992364,
            0.029177670045332477
          ],
          "val_accuracy": [
            0.9873002283105022,
            0.9898687214611872,
            0.988013698630137,
            0.9882990867579908,
            0.9884417808219178,
            0.9897260273972602,
            0.988156392694064,
            0.9888698630136986
          ],
          "val_f1": [
            0.9617204301075268,
            0.9696969696969697,
            0.9638242894056848,
            0.9646551724137931,
            0.9651912333476579,
            0.9692044482463644,
            0.9642087106511428,
            0.9665809768637532
          ],
          "val_auroc": [
            0.9988670480694088,
            0.9992317290862258,
            0.9994030860915686,
            0.9994031578791702,
            0.9992996401574675,
            0.9993256990568975,
            0.9993690587683458,
            0.9993605160437393
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.029177670045332477,
          "accuracy": 0.9888698630136986,
          "precision": 0.9938325991189427,
          "recall": 0.9407839866555463,
          "f1": 0.9665809768637532,
          "auroc": 0.9993605160437393
        },
        "best_val_f1": 0.9696969696969697,
        "training_time": 8.285295248031616,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_70.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_70_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_70_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_70_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "71": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.71.hook_resid_pre",
        "hook_layer": 71,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_71",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08428503995650707,
            0.025526694511701288,
            0.01731261038582891,
            0.014629931429392534,
            0.013187663627524762,
            0.012359868010535803,
            0.011835743340378686,
            0.011428787864449107
          ],
          "train_accuracy": [
            0.9717088833392793,
            0.9943275062433108,
            0.9978951123795933,
            0.9983945772386729,
            0.9989297181591152,
            0.9990724224045665,
            0.9991080984659294,
            0.9993221548341064
          ],
          "val_loss": [
            0.04128507700833407,
            0.03265553604472767,
            0.030914358659224078,
            0.03033022013577548,
            0.03112209059975364,
            0.029740671678022905,
            0.030080296776511452,
            0.030334507335316053
          ],
          "val_accuracy": [
            0.9892979452054794,
            0.990154109589041,
            0.9910102739726028,
            0.9911529680365296,
            0.9895833333333334,
            0.9907248858447488,
            0.990154109589041,
            0.9900114155251142
          ],
          "val_f1": [
            0.9686061113436585,
            0.970873786407767,
            0.973651191969887,
            0.9739932885906041,
            0.9691592733417829,
            0.9726315789473684,
            0.9709473684210527,
            0.9704641350210971
          ],
          "val_auroc": [
            0.9987732125442876,
            0.9991756688221575,
            0.9991374717523066,
            0.9991860538728058,
            0.9992403975625006,
            0.9992503558302457,
            0.9992819377650944,
            0.9992425314770172
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030334507335316053,
          "accuracy": 0.9900114155251142,
          "precision": 0.9939498703543648,
          "recall": 0.9480626545754328,
          "f1": 0.9704641350210971,
          "auroc": 0.9992425314770172
        },
        "best_val_f1": 0.9739932885906041,
        "training_time": 8.25805139541626,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_71.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_71_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_71_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_71_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "72": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.72.hook_resid_pre",
        "hook_layer": 72,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_72",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0826563465230371,
            0.024945930295547293,
            0.016884520210827526,
            0.014391093131061218,
            0.012896739910452384,
            0.012068604263710921,
            0.011465372233842946,
            0.011058852807980149
          ],
          "train_accuracy": [
            0.9714948269711023,
            0.9947556189796647,
            0.9981091687477702,
            0.9985372814841241,
            0.9988583660363896,
            0.9990724224045665,
            0.9992151266500179,
            0.9992151266500179
          ],
          "val_loss": [
            0.04038846276023171,
            0.03324623107910156,
            0.03470577326687899,
            0.031250377134843306,
            0.029395318031311034,
            0.029180925542658026,
            0.029891135475852273,
            0.02899808016690341
          ],
          "val_accuracy": [
            0.988156392694064,
            0.9885844748858448,
            0.985587899543379,
            0.9884417808219178,
            0.9892979452054794,
            0.9900114155251142,
            0.9890125570776256,
            0.9897260273972602
          ],
          "val_f1": [
            0.9641158668396023,
            0.9654874892148404,
            0.9559144478393714,
            0.9648284845853234,
            0.9676305567544238,
            0.9698535745047373,
            0.9667386609071275,
            0.9689387402933564
          ],
          "val_auroc": [
            0.9991142091013225,
            0.9994067247503673,
            0.9994679035486596,
            0.99949856526317,
            0.9995060860610688,
            0.999509267937103,
            0.99950840015273,
            0.9995078939451791
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.02899808016690341,
          "accuracy": 0.9897260273972602,
          "precision": 0.9938053097345133,
          "recall": 0.9452861952861953,
          "f1": 0.9689387402933564,
          "auroc": 0.9995078939451791
        },
        "best_val_f1": 0.9698535745047373,
        "training_time": 8.239155292510986,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_72.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_72_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_72_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_72_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "73": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.73.hook_resid_pre",
        "hook_layer": 73,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_73",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08230823371984643,
            0.024135970271332827,
            0.016147762311613995,
            0.01352924190368078,
            0.012230990322723508,
            0.011228132104186436,
            0.010765639396881915,
            0.010334359130026883
          ],
          "train_accuracy": [
            0.9722797003210846,
            0.9946485907955762,
            0.9981448448091331,
            0.9988226899750268,
            0.9991437745272922,
            0.9992864787727435,
            0.9995005351409204,
            0.9994291830181948
          ],
          "val_loss": [
            0.039181726629083806,
            0.030942006544633346,
            0.030912811105901546,
            0.028901381926103073,
            0.027460588108409536,
            0.0274614464152943,
            0.027392830631949684,
            0.026744239980524238
          ],
          "val_accuracy": [
            0.9885844748858448,
            0.9894406392694064,
            0.988013698630137,
            0.9898687214611872,
            0.9900114155251142,
            0.9911529680365296,
            0.990296803652968,
            0.990439497716895
          ],
          "val_f1": [
            0.9666388657214345,
            0.9690117252931323,
            0.9644670050761421,
            0.9701304164913757,
            0.9705882352941176,
            0.9741019214703425,
            0.9714285714285714,
            0.9719077568134172
          ],
          "val_auroc": [
            0.9990570611723316,
            0.9995570152704867,
            0.9995626909236516,
            0.9995890117652033,
            0.999600504962862,
            0.9995621233583352,
            0.9995951130923555,
            0.9995857482646335
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.026744239980524238,
          "accuracy": 0.990439497716895,
          "precision": 0.9922945205479452,
          "recall": 0.952341824157765,
          "f1": 0.9719077568134172,
          "auroc": 0.9995857482646335
        },
        "best_val_f1": 0.9741019214703425,
        "training_time": 8.480395078659058,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_73.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_73_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_73_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_73_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "74": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.74.hook_resid_pre",
        "hook_layer": 74,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_74",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08135244191398835,
            0.02346531317896767,
            0.015431293287446305,
            0.01283846184670857,
            0.011241168773001629,
            0.010650922274259535,
            0.01010906903421906,
            0.009706841320858325
          ],
          "train_accuracy": [
            0.9716018551551908,
            0.9952550838387442,
            0.9980021405636817,
            0.9988226899750268,
            0.9990367463432037,
            0.9992508027113807,
            0.9995005351409204,
            0.9995362112022833
          ],
          "val_loss": [
            0.03782868818803267,
            0.030898033488880504,
            0.026342743093317206,
            0.027164389870383523,
            0.026102148402820935,
            0.025284142927689986,
            0.025246585499156603,
            0.025102004137906163
          ],
          "val_accuracy": [
            0.98787100456621,
            0.98787100456621,
            0.990296803652968,
            0.9897260273972602,
            0.9895833333333334,
            0.990582191780822,
            0.9908675799086758,
            0.9898687214611872
          ],
          "val_f1": [
            0.9627682873412177,
            0.9625715543813298,
            0.970357454228422,
            0.968476357267951,
            0.9681639773222852,
            0.971304347826087,
            0.9721980886185926,
            0.9690901175446234
          ],
          "val_auroc": [
            0.9988553745494015,
            0.9996039353243491,
            0.9996199445831101,
            0.9996365386549767,
            0.9995999878358874,
            0.9996172398224975,
            0.9996059090685798,
            0.9996213335142354
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.025102004137906163,
          "accuracy": 0.9898687214611872,
          "precision": 0.9893333333333333,
          "recall": 0.9496587030716723,
          "f1": 0.9690901175446234,
          "auroc": 0.9996213335142354
        },
        "best_val_f1": 0.9721980886185926,
        "training_time": 8.539554119110107,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_74.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_74_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_74_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_74_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "75": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.75.hook_resid_pre",
        "hook_layer": 75,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_75",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.08114544271606289,
            0.023263223386331373,
            0.014740301232325705,
            0.012264492523911746,
            0.010965054657004059,
            0.010098738213639588,
            0.009614987805438947,
            0.009250627297453039
          ],
          "train_accuracy": [
            0.9714234748483768,
            0.994898323225116,
            0.9980021405636817,
            0.9984659293613986,
            0.9993221548341064,
            0.999179450588655,
            0.9994291830181948,
            0.9996075633250089
          ],
          "val_loss": [
            0.043144689906727186,
            0.0326137976212935,
            0.03172748739069158,
            0.029760174317793413,
            0.031281536275690254,
            0.02950310707092285,
            0.02976675033569336,
            0.030005429007790307
          ],
          "val_accuracy": [
            0.983304794520548,
            0.9897260273972602,
            0.9867294520547946,
            0.9887271689497716,
            0.9870148401826484,
            0.988013698630137,
            0.9877283105022832,
            0.9875856164383562
          ],
          "val_f1": [
            0.9495036685369012,
            0.9697732997481109,
            0.9602053915275995,
            0.9664828171404327,
            0.9610944848225738,
            0.9643160577740016,
            0.9633418584825234,
            0.9629314017895185
          ],
          "val_auroc": [
            0.9986977690034415,
            0.9993917869066151,
            0.9994130951010459,
            0.9994530658416058,
            0.9994100919327032,
            0.9994132381090621,
            0.999440910160219,
            0.9994332592313462
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030005429007790307,
          "accuracy": 0.9875856164383562,
          "precision": 0.989492119089317,
          "recall": 0.9377593360995851,
          "f1": 0.9629314017895185,
          "auroc": 0.9994332592313462
        },
        "best_val_f1": 0.9697732997481109,
        "training_time": 8.288570404052734,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_75.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_75_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_75_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_75_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "76": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.76.hook_resid_pre",
        "hook_layer": 76,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_76",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.07460544650447151,
            0.019516481722377615,
            0.012448686515789087,
            0.010142962863991998,
            0.009026279188248703,
            0.008389702816036654,
            0.008062923553407184,
            0.007834969263855521
          ],
          "train_accuracy": [
            0.9744916161255798,
            0.9961469853728149,
            0.9988940420977525,
            0.9993935069568319,
            0.9996432393863718,
            0.9997145915090974,
            0.9998929718159115,
            0.999785943631823
          ],
          "val_loss": [
            0.03296468908136541,
            0.02715910564769398,
            0.024841182882135566,
            0.023802900314331056,
            0.02401184168728915,
            0.023822927474975587,
            0.023842503807761452,
            0.024074567448009145
          ],
          "val_accuracy": [
            0.9891552511415526,
            0.9918664383561644,
            0.9921518264840182,
            0.992579908675799,
            0.9921518264840182,
            0.9911529680365296,
            0.9921518264840182,
            0.9915810502283106
          ],
          "val_f1": [
            0.9684908789386402,
            0.9765913757700205,
            0.9773755656108597,
            0.9786535303776683,
            0.9774312679524005,
            0.9745484400656814,
            0.9773941635840526,
            0.9756701030927835
          ],
          "val_auroc": [
            0.9991395855283102,
            0.9993427565449438,
            0.9994477915958161,
            0.9995077713969845,
            0.9994474396016778,
            0.9994844693850283,
            0.9994409629095329,
            0.9994824278190261
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.024074567448009145,
          "accuracy": 0.9915810502283106,
          "precision": 0.9891304347826086,
          "recall": 0.9625711960943857,
          "f1": 0.9756701030927835,
          "auroc": 0.9994824278190261
        },
        "best_val_f1": 0.9786535303776683,
        "training_time": 8.290568828582764,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_76.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_76_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_76_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_76_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "77": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.77.hook_resid_pre",
        "hook_layer": 77,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_77",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.07404105256887825,
            0.018898195309615503,
            0.011604628679167148,
            0.009348912580793544,
            0.00814866250355358,
            0.0075948737709481086,
            0.007149569992163138,
            0.006946655896122325
          ],
          "train_accuracy": [
            0.9741705315733143,
            0.9964680699250803,
            0.9986799857295755,
            0.9994648590795576,
            0.9996789154477346,
            0.9998216196931858,
            0.9998929718159115,
            0.9999286478772743
          ],
          "val_loss": [
            0.0375281420621005,
            0.030515228618275037,
            0.027699726278131657,
            0.026056020910089666,
            0.027220444245771927,
            0.02652416554364291,
            0.025438737869262696,
            0.025311149250377307
          ],
          "val_accuracy": [
            0.9867294520547946,
            0.9888698630136986,
            0.9900114155251142,
            0.990582191780822,
            0.990154109589041,
            0.990439497716895,
            0.9908675799086758,
            0.9910102739726028
          ],
          "val_f1": [
            0.959931064196467,
            0.9665523156089194,
            0.9702633814783348,
            0.9718909710391823,
            0.9705002137665669,
            0.9714041826717883,
            0.9727659574468085,
            0.9732711073398388
          ],
          "val_auroc": [
            0.9987963372816993,
            0.999130077842168,
            0.9991546292019616,
            0.9993320881534521,
            0.9993080393068706,
            0.9992928203353026,
            0.999297342954212,
            0.9992885848668003
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.025311149250377307,
          "accuracy": 0.9910102739726028,
          "precision": 0.9905008635578584,
          "recall": 0.9566305254378649,
          "f1": 0.9732711073398388,
          "auroc": 0.9992885848668003
        },
        "best_val_f1": 0.9732711073398388,
        "training_time": 8.32576847076416,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_77.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_77_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_77_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_77_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "78": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.78.hook_resid_pre",
        "hook_layer": 78,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_78",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.0796321361074777,
            0.02028279834465213,
            0.012001904033838886,
            0.009472041515225214,
            0.008387415086187115,
            0.0075982894352956175,
            0.007271390055842085,
            0.007031633284742429
          ],
          "train_accuracy": [
            0.9706029254370317,
            0.995718872636461,
            0.9984302533000357,
            0.9995005351409204,
            0.9995718872636461,
            0.9998216196931858,
            0.9998216196931858,
            0.9999286478772743
          ],
          "val_loss": [
            0.03821325735612349,
            0.028890837322581898,
            0.03021946820345792,
            0.02785342823375355,
            0.026424781842665238,
            0.0266473726792769,
            0.026312611319802025,
            0.02708301544189453
          ],
          "val_accuracy": [
            0.9884417808219178,
            0.990439497716895,
            0.988156392694064,
            0.9897260273972602,
            0.9907248858447488,
            0.990154109589041,
            0.990154109589041,
            0.9897260273972602
          ],
          "val_f1": [
            0.9668168783285539,
            0.9725522326915199,
            0.9657731958762886,
            0.9704433497536946,
            0.9733933688088416,
            0.9716864997948297,
            0.9717560376586164,
            0.9704433497536946
          ],
          "val_auroc": [
            0.9986785982849531,
            0.9991777325053386,
            0.9992476029284773,
            0.9992650356687813,
            0.9993111278341451,
            0.9993256318740782,
            0.9992929977842289,
            0.99925750472497
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.02708301544189453,
          "accuracy": 0.9897260273972602,
          "precision": 0.9916107382550335,
          "recall": 0.9501607717041801,
          "f1": 0.9704433497536946,
          "auroc": 0.99925750472497
        },
        "best_val_f1": 0.9733933688088416,
        "training_time": 8.358887434005737,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_78.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_78_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_78_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_78_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    },
    "79": {
      "config": {
        "dataset_path": "data/NTML-datasets/4T1L_500samples.jsonl",
        "max_length": 312,
        "model_name": "meta-llama/Llama-3.3-70B-Instruct",
        "hook_point": "blocks.79.hook_resid_pre",
        "hook_layer": 79,
        "device": "cuda",
        "dtype": "bfloat16",
        "batch_size": 32,
        "learning_rate": 0.001,
        "num_epochs": 8,
        "weight_decay": 0.001,
        "train_ratio": 0.8,
        "handle_class_imbalance": true,
        "optimizer_type": "AdamW",
        "scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "gradient_clip_norm": 1.0,
        "cache_dir": "./cache/ntml_binary/meta_llama_Llama_3.3_70B_Instruct_4T1L_500samples",
        "activation_batch_size": 4,
        "force_recache": false,
        "output_dir": "./ntml_4T1L_500samples_pytorch_llama70b",
        "probe_name": "ntml_binary_4T1L_500samples_layer_79",
        "save_checkpoints": true,
        "checkpoint_every": 5,
        "verbose": true,
        "log_every": 10,
        "eval_every": 1,
        "ignore_system_tokens": true,
        "ignore_user_tokens": true,
        "min_tokens_per_statement": 1,
        "token_overlap_strategy": "majority",
        "probe_method": "pytorch",
        "sklearn_C": 1.0,
        "sklearn_C_sweep": false,
        "sklearn_C_values": [
          0.0001,
          0.001,
          0.01,
          0.1,
          1.0,
          10.0,
          100.0,
          1000.0,
          10000.0
        ],
        "sklearn_solver": "liblinear",
        "sklearn_max_iter": 1000,
        "pytorch_bias": true,
        "pytorch_normalize_weights": true
      },
      "training_results": {
        "training_history": {
          "train_loss": [
            0.09197234076907067,
            0.027410150392908075,
            0.015592744616476913,
            0.01124075442535556,
            0.009679327780576466,
            0.008934684068530152,
            0.008414002858340468,
            0.008027777897053692
          ],
          "train_accuracy": [
            0.966464502318944,
            0.9925080271138066,
            0.996931858722797,
            0.998965394220478,
            0.9996075633250089,
            0.9997502675704603,
            0.9998572957545487,
            0.9998572957545487
          ],
          "val_loss": [
            0.0458251953125,
            0.03547028194774281,
            0.03313360647721724,
            0.03009665445847945,
            0.029833949695933948,
            0.03027501106262207,
            0.030457352508198133,
            0.030172894217751243
          ],
          "val_accuracy": [
            0.9841609589041096,
            0.988013698630137,
            0.9871575342465754,
            0.9894406392694064,
            0.9895833333333334,
            0.9890125570776256,
            0.9888698630136986,
            0.9892979452054794
          ],
          "val_f1": [
            0.9524625267665953,
            0.9639484978540772,
            0.961139896373057,
            0.9683490162532079,
            0.9688699360341151,
            0.9669669669669669,
            0.9665809768637532,
            0.9679350149636596
          ],
          "val_auroc": [
            0.9979254006822753,
            0.9985187119176174,
            0.9989840114960113,
            0.9990645524650239,
            0.9991243973719186,
            0.9991105035120349,
            0.9990593422675678,
            0.9990688942962377
          ],
          "learning_rate": [
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001
          ]
        },
        "final_metrics": {
          "loss": 0.030172894217751243,
          "accuracy": 0.9892979452054794,
          "precision": 0.9826388888888888,
          "recall": 0.953664700926706,
          "f1": 0.9679350149636596,
          "auroc": 0.9990688942962377
        },
        "best_val_f1": 0.9688699360341151,
        "training_time": 8.311673879623413,
        "num_parameters": 8193
      },
      "paths": {
        "probe": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_79.pt",
        "config": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_79_config.json",
        "metrics": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_79_metrics.json",
        "log": "ntml_4T1L_500samples_pytorch_llama70b/ntml_binary_4T1L_500samples_layer_79_training.log",
        "checkpoints": "ntml_4T1L_500samples_pytorch_llama70b/checkpoints"
      }
    }
  }
}