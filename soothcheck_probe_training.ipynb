{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260194fe-10b4-405c-9a76-de8cf08e7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'probity'...\n",
      "remote: Enumerating objects: 241, done.\u001b[K\n",
      "remote: Counting objects: 100% (241/241), done.\u001b[K\n",
      "remote: Compressing objects: 100% (167/167), done.\u001b[K\n",
      "remote: Total 241 (delta 127), reused 167 (delta 62), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (241/241), 327.85 KiB | 3.64 MiB/s, done.\n",
      "Resolving deltas: 100% (127/127), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Jordine/probity.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d371b5-5b3d-402c-a9cb-f15b8a279f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/probity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd probity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7f1398-8624-4c50-b02e-3088bce0d0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 392\n",
      "Obtaining file:///probity\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from probity==0.1.0) (2.2.1)\n",
      "Collecting transformers>=4.30.0 (from probity==0.1.0)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from probity==0.1.0) (1.26.3)\n",
      "Collecting matplotlib>=3.7.0 (from probity==0.1.0)\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting transformer_lens>=1.0.0 (from probity==0.1.0)\n",
      "  Downloading transformer_lens-2.15.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting scikit-learn>=1.3.0 (from probity==0.1.0)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting datasets>=2.12.0 (from probity==0.1.0)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from probity==0.1.0) (4.65.0)\n",
      "Collecting tabulate>=0.9.0 (from probity==0.1.0)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting neuronpedia (from probity==0.1.0)\n",
      "  Downloading neuronpedia-1.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.12.0->probity==0.1.0) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.65.0 (from probity==0.1.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0) (2024.2.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.12.0->probity==0.1.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.12.0->probity==0.1.0) (6.0.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->probity==0.1.0)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.0->probity==0.1.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->probity==0.1.0)\n",
      "  Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->probity==0.1.0)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->probity==0.1.0) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.7.0->probity==0.1.0)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->probity==0.1.0) (2.9.0.post0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn>=1.3.0->probity==0.1.0)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn>=1.3.0->probity==0.1.0)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->probity==0.1.0)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->probity==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->probity==0.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->probity==0.1.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->probity==0.1.0) (3.1.3)\n",
      "Collecting accelerate>=0.23.0 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting einops>=0.6.0 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting rich>=12.6.0 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentencepiece (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typeguard<5.0,>=4.2 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading typeguard-4.4.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting wandb>=0.13.5 (from transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.30.0->probity==0.1.0)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers>=4.30.0->probity==0.1.0)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.30.0->probity==0.1.0)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from neuronpedia->probity==0.1.0)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer_lens>=1.0.0->probity==0.1.0) (5.9.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading aiohttp-3.12.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading wadler_lindig-0.1.6-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.12.0->probity==0.1.0) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->probity==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.12.0->probity==0.1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.12.0->probity==0.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.12.0->probity==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.12.0->probity==0.1.0) (2024.2.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.6.0->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12.6.0->transformer_lens>=1.0.0->probity==0.1.0) (2.15.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=2.0.0->probity==0.1.0)\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0) (8.1.7)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0) (3.10.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=2.0.0 (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->probity==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->probity==0.1.0) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading frozenlist-1.6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.12.0->probity==0.1.0)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens>=1.0.0->probity==0.1.0)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformer_lens-2.15.4-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading neuronpedia-1.0.21-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.1/512.1 kB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.4.3-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.6/341.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wadler_lindig-0.1.6-py3-none-any.whl (20 kB)\n",
      "Downloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: probity, transformers-stream-generator\n",
      "  Building editable for probity (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for probity: filename=probity-0.1.0-0.editable-py3-none-any.whl size=3639 sha256=c507b165dbebfa3eeeffb66b1ea694dbab1301ce6b71067365e9476db3a2160b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mcmseq2d/wheels/45/fb/72/388ba3ec924db7885385dc14d3e052a5b05eb79417a8da02d3\n",
      "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12424 sha256=cc05de95b7b606ec4544fe7204213e4101379a6e78656b97ae6f9d96c51cf8c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\n",
      "Successfully built probity transformers-stream-generator\n",
      "Installing collected packages: sentencepiece, better-abc, xxhash, wadler-lindig, tzdata, typing-extensions, tqdm, threadpoolctl, tabulate, smmap, setproctitle, sentry-sdk, scipy, safetensors, requests, regex, python-dotenv, pyparsing, pyarrow, protobuf, propcache, mdurl, kiwisolver, joblib, hf-xet, frozenlist, fonttools, fancy-einsum, einops, dill, cycler, contourpy, beartype, async-timeout, annotated-types, aiohappyeyeballs, typing-inspection, typeguard, scikit-learn, pydantic-core, pandas, neuronpedia, multiprocess, multidict, matplotlib, markdown-it-py, jaxtyping, huggingface-hub, gitdb, aiosignal, yarl, tokenizers, rich, pydantic, gitpython, accelerate, wandb, transformers, aiohttp, transformers-stream-generator, datasets, transformer_lens, probity\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.11 aiosignal-1.3.2 annotated-types-0.7.0 async-timeout-5.0.1 beartype-0.14.1 better-abc-0.0.3 contourpy-1.3.2 cycler-0.12.1 datasets-3.6.0 dill-0.3.8 einops-0.8.1 fancy-einsum-0.0.3 fonttools-4.58.2 frozenlist-1.6.2 gitdb-4.0.12 gitpython-3.1.44 hf-xet-1.1.3 huggingface-hub-0.32.4 jaxtyping-0.3.2 joblib-1.5.1 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.10.3 mdurl-0.1.2 multidict-6.4.4 multiprocess-0.70.16 neuronpedia-1.0.21 pandas-2.3.0 probity-0.1.0 propcache-0.3.1 protobuf-6.31.1 pyarrow-20.0.0 pydantic-2.11.5 pydantic-core-2.33.2 pyparsing-3.2.3 python-dotenv-1.1.0 regex-2024.11.6 requests-2.32.3 rich-14.0.0 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.15.3 sentencepiece-0.2.0 sentry-sdk-2.29.1 setproctitle-1.3.6 smmap-5.0.2 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.21.1 tqdm-4.67.1 transformer_lens-2.15.4 transformers-4.52.4 transformers-stream-generator-0.0.5 typeguard-4.4.3 typing-extensions-4.14.0 typing-inspection-0.4.1 tzdata-2025.2 wadler-lindig-0.1.6 wandb-0.20.1 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip cache purge\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb890f0-e382-4331-8a72-3a7033bbc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e71431-f949-41f3-aa34-7034130e12ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/two_truths_one_lie.json\n",
      "Dataset size: 10\n",
      "Loading model meta-llama/Llama-3.1-8B-Instruct\n",
      "Loading checkpoint shards: 100%|█████████████████| 4/4 [00:00<00:00, 111.79it/s]\n",
      "Loaded pretrained model meta-llama/Llama-3.1-8B-Instruct into HookedTransformer\n",
      "Training on layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "Model dtype: torch.bfloat16\n",
      "Collecting activations...\n",
      "Loading cached activations from cache/Llama-3.1-8B-Instruct_activations.pt\n",
      "Layers:   0%|                                            | 0/32 [00:00<?, ?it/s]\n",
      "Training logistic probe on layer 0\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 50.38it/s, Train Loss=0.691406, Val Loss=0.\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 0 to trained_probes/logistic/layer_0_probe.json\n",
      "\n",
      "Training meandiff probe on layer 0\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.69140625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 0 to trained_probes/meandiff/layer_0_probe.json\n",
      "\n",
      "Training linear probe on layer 0\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.609375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.609375, Val Loss=0.507812, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=10.437500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=10.437500, Val Loss=0.500000,\u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.421875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.421875, Val Loss=0.496094, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.949219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.949219, Val Loss=0.496094, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.457031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.457031, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.507812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.507812, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.605469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.605469, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.617188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.617188, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.613281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 266.98it/s, Train Loss=0.617188, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 0 to trained_probes/linear/layer_0_probe.json\n",
      "\n",
      "Training pca probe on layer 0\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.69140625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 0 to trained_probes/pca/layer_0_probe.json\n",
      "Layers:   3%|█▏                                  | 1/32 [00:00<00:07,  4.07it/s]\n",
      "Training logistic probe on layer 1\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.640625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.640625, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.621094]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.621094, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.542969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.542969, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.488281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.488281, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.457031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 347.91it/s, Train Loss=0.488281, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 1 to trained_probes/logistic/layer_1_probe.json\n",
      "\n",
      "Training meandiff probe on layer 1\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.69140625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 1 to trained_probes/meandiff/layer_1_probe.json\n",
      "\n",
      "Training linear probe on layer 1\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.406250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.406250, Val Loss=0.000254, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.656250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.656250, Val Loss=0.000238, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.015625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.015625, Val Loss=0.000243, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.734375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.734375, Val Loss=0.000256, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.070312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.070312, Val Loss=0.000271, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.785156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 426.77it/s, Train Loss=1.070312, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 1 to trained_probes/linear/layer_1_probe.json\n",
      "\n",
      "Training pca probe on layer 1\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.6953125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 1 to trained_probes/pca/layer_1_probe.json\n",
      "\n",
      "Training logistic probe on layer 2\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.007812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.007812, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.750000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.750000, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.609375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.609375, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.582031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.582031, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.589844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 8 epochs\n",
      "Training:  70%|▋| 7/10 [00:00<00:00, 375.56it/s, Train Loss=0.585938, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 2 to trained_probes/logistic/layer_2_probe.json\n",
      "\n",
      "Training meandiff probe on layer 2\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.69140625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 2 to trained_probes/meandiff/layer_2_probe.json\n",
      "\n",
      "Training linear probe on layer 2\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.296875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.296875, Val Loss=0.000043, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=4.312500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=4.312500, Val Loss=0.000018, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.671875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.671875, Val Loss=0.000021, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.218750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.218750, Val Loss=0.000042, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.777344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.777344, Val Loss=0.000066, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.667969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 433.49it/s, Train Loss=0.777344, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 2 to trained_probes/linear/layer_2_probe.json\n",
      "\n",
      "Training pca probe on layer 2\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.6953125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 2 to trained_probes/pca/layer_2_probe.json\n",
      "Layers:   9%|███▍                                | 3/32 [00:00<00:03,  9.66it/s]\n",
      "Training logistic probe on layer 3\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.980469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.980469, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.734375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.734375, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.609375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.609375, Val Loss=0.699219, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.589844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.589844, Val Loss=0.699219, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.589844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.589844, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.597656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.597656, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.597656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.597656, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.593750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.593750, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.597656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 426.65it/s, Train Loss=0.597656, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 3 to trained_probes/logistic/layer_3_probe.json\n",
      "\n",
      "Training meandiff probe on layer 3\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.6875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 3 to trained_probes/meandiff/layer_3_probe.json\n",
      "\n",
      "Training linear probe on layer 3\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.664062, Val Loss=0.515625, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=4.656250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=4.656250, Val Loss=0.515625, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.171875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.171875, Val Loss=0.523438, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.792969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.792969, Val Loss=0.523438, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.478516]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.478516, Val Loss=0.531250, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.462891]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 427.49it/s, Train Loss=0.478516, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 3 to trained_probes/linear/layer_3_probe.json\n",
      "\n",
      "Training pca probe on layer 3\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.703125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 3 to trained_probes/pca/layer_3_probe.json\n",
      "\n",
      "Training logistic probe on layer 4\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.527344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.527344, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.498047]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.498047, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.480469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.480469, Val Loss=0.714844, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.464844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.464844, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.460938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 360.53it/s, Train Loss=0.464844, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 4 to trained_probes/logistic/layer_4_probe.json\n",
      "\n",
      "Training meandiff probe on layer 4\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.6875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 4 to trained_probes/meandiff/layer_4_probe.json\n",
      "\n",
      "Training linear probe on layer 4\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.757812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.757812, Val Loss=0.000809, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=4.687500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=4.687500, Val Loss=0.000523, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.375000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.375000, Val Loss=0.000448, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.101562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.101562, Val Loss=0.000496, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.820312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.820312, Val Loss=0.000576, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.800781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.800781, Val Loss=0.000599, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.828125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Training:  60%|▌| 6/10 [00:00<00:00, 435.14it/s, Train Loss=0.800781, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 4 to trained_probes/linear/layer_4_probe.json\n",
      "\n",
      "Training pca probe on layer 4\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.71484375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 4 to trained_probes/pca/layer_4_probe.json\n",
      "Layers:  16%|█████▋                              | 5/32 [00:00<00:02, 12.56it/s]\n",
      "Training logistic probe on layer 5\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.722656, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.906250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.906250, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.679688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.679688, Val Loss=0.714844, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.578125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.578125, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.585938, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.582031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.582031, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.578125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 386.73it/s, Train Loss=0.582031, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 5 to trained_probes/logistic/layer_5_probe.json\n",
      "\n",
      "Training meandiff probe on layer 5\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.68359375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 5 to trained_probes/meandiff/layer_5_probe.json\n",
      "\n",
      "Training linear probe on layer 5\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.562500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.562500, Val Loss=0.000610, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.117188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.117188, Val Loss=0.000801, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.187500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.187500, Val Loss=0.000479, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.957031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.957031, Val Loss=0.000299, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.789062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.789062, Val Loss=0.000199, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.695312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.695312, Val Loss=0.000165, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.660156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.660156, Val Loss=0.000146, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.644531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.644531, Val Loss=0.000139, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.640625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.640625, Val Loss=0.000135, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.640625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 471.71it/s, Train Loss=0.640625, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 5 to trained_probes/linear/layer_5_probe.json\n",
      "\n",
      "Training pca probe on layer 5\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.7265625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 5 to trained_probes/pca/layer_5_probe.json\n",
      "\n",
      "Training logistic probe on layer 6\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.320312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.320312, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.992188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.992188, Val Loss=1.179688, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.773438]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.773438, Val Loss=1.171875, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.683594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.683594, Val Loss=1.171875, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.664062, Val Loss=1.164062, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.664062, Val Loss=1.156250, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.664062, Val Loss=1.156250, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.664062, Val Loss=1.156250, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 467.77it/s, Train Loss=0.664062, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 6 to trained_probes/logistic/layer_6_probe.json\n",
      "\n",
      "Training meandiff probe on layer 6\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.67578125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 6 to trained_probes/meandiff/layer_6_probe.json\n",
      "\n",
      "Training linear probe on layer 6\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.621094]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.621094, Val Loss=1.125000, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=4.968750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=4.968750, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.367188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.367188, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.546875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.546875, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.566406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.566406, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.683594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 452.32it/s, Train Loss=0.566406, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 6 to trained_probes/linear/layer_6_probe.json\n",
      "\n",
      "Training pca probe on layer 6\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.74609375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 6 to trained_probes/pca/layer_6_probe.json\n",
      "Layers:  22%|███████▉                            | 7/32 [00:00<00:01, 13.77it/s]\n",
      "Training logistic probe on layer 7\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.675781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.675781, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.470703]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.470703, Val Loss=0.722656, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.361328]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.361328, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.324219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.324219, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.310547]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.310547, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.306641]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.306641, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.300781, Val Loss=0.718750, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.298828]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 9 epochs\n",
      "Training:  80%|▊| 8/10 [00:00<00:00, 395.06it/s, Train Loss=0.300781, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 7 to trained_probes/logistic/layer_7_probe.json\n",
      "\n",
      "Training meandiff probe on layer 7\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.65625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 7 to trained_probes/meandiff/layer_7_probe.json\n",
      "\n",
      "Training linear probe on layer 7\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.281250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.281250, Val Loss=0.002090, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.265625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.265625, Val Loss=0.001381, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.156250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.156250, Val Loss=0.000587, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.093750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.093750, Val Loss=0.000254, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.695312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.695312, Val Loss=0.000116, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.562500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.562500, Val Loss=0.000093, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.542969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.542969, Val Loss=0.000089, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.539062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.539062, Val Loss=0.000088, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.539062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.539062, Val Loss=0.000087, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.539062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 476.61it/s, Train Loss=0.539062, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 7 to trained_probes/linear/layer_7_probe.json\n",
      "\n",
      "Training pca probe on layer 7\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.7890625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 7 to trained_probes/pca/layer_7_probe.json\n",
      "\n",
      "Training logistic probe on layer 8\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.451172]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.451172, Val Loss=0.722656, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.365234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.365234, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.320312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.320312, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.294922]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.294922, Val Loss=0.734375, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.279297]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 369.00it/s, Train Loss=0.294922, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 8 to trained_probes/logistic/layer_8_probe.json\n",
      "\n",
      "Training meandiff probe on layer 8\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.64453125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 8 to trained_probes/meandiff/layer_8_probe.json\n",
      "\n",
      "Training linear probe on layer 8\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.390625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.390625, Val Loss=1.070312, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=5.562500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=5.562500, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.585938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.585938, Val Loss=1.195312, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.341797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.341797, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.177734]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.177734, Val Loss=1.250000, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.267578]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 471.74it/s, Train Loss=0.177734, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 8 to trained_probes/linear/layer_8_probe.json\n",
      "\n",
      "Training pca probe on layer 8\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.80859375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 8 to trained_probes/pca/layer_8_probe.json\n",
      "Layers:  28%|██████████▏                         | 9/32 [00:00<00:01, 14.96it/s]\n",
      "Training logistic probe on layer 9\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.757812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.757812, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.710938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.710938, Val Loss=1.195312, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.625000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.625000, Val Loss=1.195312, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.562500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.562500, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.488281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.488281, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.474609]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.474609, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.464844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.464844, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.458984]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 401.24it/s, Train Loss=0.464844, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 9 to trained_probes/logistic/layer_9_probe.json\n",
      "\n",
      "Training meandiff probe on layer 9\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 9 to trained_probes/meandiff/layer_9_probe.json\n",
      "\n",
      "Training linear probe on layer 9\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.656250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.656250, Val Loss=0.597656, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.408203]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.408203, Val Loss=0.605469, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.250000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.250000, Val Loss=0.605469, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.183594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.183594, Val Loss=0.605469, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.149414]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.149414, Val Loss=0.605469, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.135742]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 472.45it/s, Train Loss=0.149414, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 9 to trained_probes/linear/layer_9_probe.json\n",
      "\n",
      "Training pca probe on layer 9\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.85546875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 9 to trained_probes/pca/layer_9_probe.json\n",
      "\n",
      "Training logistic probe on layer 10\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.855469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.855469, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.617188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.617188, Val Loss=1.171875, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.507812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.507812, Val Loss=1.156250, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.478516]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.478516, Val Loss=1.148438, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.466797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.466797, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.464844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.464844, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.458984]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.458984, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.458984]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.458984, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.457031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 433.15it/s, Train Loss=0.457031, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 10 to trained_probes/logistic/layer_10_probe.json\n",
      "\n",
      "Training meandiff probe on layer 10\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.60546875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 10 to trained_probes/meandiff/layer_10_probe.json\n",
      "\n",
      "Training linear probe on layer 10\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.640625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.640625, Val Loss=0.476562, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.632812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.632812, Val Loss=0.457031, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.816406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.816406, Val Loss=0.472656, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.636719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.636719, Val Loss=0.480469, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.500000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.500000, Val Loss=0.484375, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.410156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.410156, Val Loss=0.484375, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.357422]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Training:  60%|▌| 6/10 [00:00<00:00, 470.18it/s, Train Loss=0.410156, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 10 to trained_probes/linear/layer_10_probe.json\n",
      "\n",
      "Training pca probe on layer 10\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.91796875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 10 to trained_probes/pca/layer_10_probe.json\n",
      "Layers:  34%|████████████                       | 11/32 [00:00<00:01, 15.51it/s]\n",
      "Training logistic probe on layer 11\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.757812, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.527344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.527344, Val Loss=0.750000, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.408203]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.408203, Val Loss=0.742188, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.330078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.330078, Val Loss=0.734375, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.296875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.296875, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.285156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.285156, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.277344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.277344, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.275391]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.275391, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.275391]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.275391, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.273438]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 404.43it/s, Train Loss=0.275391, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 11 to trained_probes/logistic/layer_11_probe.json\n",
      "\n",
      "Training meandiff probe on layer 11\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.59375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 11 to trained_probes/meandiff/layer_11_probe.json\n",
      "\n",
      "Training linear probe on layer 11\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.000000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.000000, Val Loss=1.312500, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.265625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.265625, Val Loss=1.296875, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.117188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.117188, Val Loss=1.273438, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.365234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.365234, Val Loss=1.257812, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.162109]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.162109, Val Loss=1.242188, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.125977]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.125977, Val Loss=1.234375, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.127930]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.127930, Val Loss=1.234375, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.128906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.128906, Val Loss=1.234375, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.127930]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.127930, Val Loss=1.234375, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.127930]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 502.62it/s, Train Loss=0.127930, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 11 to trained_probes/linear/layer_11_probe.json\n",
      "\n",
      "Training pca probe on layer 11\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.953125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 11 to trained_probes/pca/layer_11_probe.json\n",
      "\n",
      "Training logistic probe on layer 12\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.328125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.328125, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.253906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.253906, Val Loss=0.703125, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.216797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.216797, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.195312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.195312, Val Loss=0.707031, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.183594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 373.07it/s, Train Loss=0.195312, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 12 to trained_probes/logistic/layer_12_probe.json\n",
      "\n",
      "Training meandiff probe on layer 12\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.57421875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 12 to trained_probes/meandiff/layer_12_probe.json\n",
      "\n",
      "Training linear probe on layer 12\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.046875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.046875, Val Loss=0.617188, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.421875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.421875, Val Loss=0.648438, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.789062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.789062, Val Loss=0.671875, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.396484]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.396484, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.410156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.410156, Val Loss=0.691406, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.433594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 448.76it/s, Train Loss=0.410156, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 12 to trained_probes/linear/layer_12_probe.json\n",
      "\n",
      "Training pca probe on layer 12\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.98828125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 12 to trained_probes/pca/layer_12_probe.json\n",
      "Layers:  41%|██████████████▏                    | 13/32 [00:00<00:01, 15.97it/s]\n",
      "Training logistic probe on layer 13\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.750000, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.466797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.466797, Val Loss=0.761719, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.328125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.328125, Val Loss=0.765625, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.275391]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.275391, Val Loss=0.765625, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.253906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.253906, Val Loss=0.765625, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.239258]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 382.51it/s, Train Loss=0.253906, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 13 to trained_probes/logistic/layer_13_probe.json\n",
      "\n",
      "Training meandiff probe on layer 13\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.578125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 13 to trained_probes/meandiff/layer_13_probe.json\n",
      "\n",
      "Training linear probe on layer 13\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.812500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.812500, Val Loss=0.617188, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.648438]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.648438, Val Loss=0.589844, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.242188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.242188, Val Loss=0.562500, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.945312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.945312, Val Loss=0.554688, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.816406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.816406, Val Loss=0.546875, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.757812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.757812, Val Loss=0.546875, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.714844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.714844, Val Loss=0.546875, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.699219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.699219, Val Loss=0.546875, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.683594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.683594, Val Loss=0.546875, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.683594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 507.09it/s, Train Loss=0.683594, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 13 to trained_probes/linear/layer_13_probe.json\n",
      "\n",
      "Training pca probe on layer 13\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.015625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 13 to trained_probes/pca/layer_13_probe.json\n",
      "\n",
      "Training logistic probe on layer 14\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.265625, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.886719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.886719, Val Loss=1.234375, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.656250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.656250, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.535156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.535156, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.496094]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.496094, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.486328]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.486328, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.480469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.480469, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.476562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.476562, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.472656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.472656, Val Loss=1.187500, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.472656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 411.38it/s, Train Loss=0.472656, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 14 to trained_probes/logistic/layer_14_probe.json\n",
      "\n",
      "Training meandiff probe on layer 14\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.578125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 14 to trained_probes/meandiff/layer_14_probe.json\n",
      "\n",
      "Training linear probe on layer 14\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.703125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.703125, Val Loss=0.621094, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.320312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.320312, Val Loss=0.628906, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.664062, Val Loss=0.609375, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.125000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.125000, Val Loss=0.593750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.707031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.707031, Val Loss=0.582031, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.488281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.488281, Val Loss=0.574219, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.416016]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.416016, Val Loss=0.574219, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.384766]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.384766, Val Loss=0.574219, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.371094]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.371094, Val Loss=0.574219, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.369141]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 568.69it/s, Train Loss=0.369141, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 14 to trained_probes/linear/layer_14_probe.json\n",
      "\n",
      "Training pca probe on layer 14\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.1328125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 14 to trained_probes/pca/layer_14_probe.json\n",
      "Layers:  47%|████████████████▍                  | 15/32 [00:01<00:01, 16.11it/s]\n",
      "Training logistic probe on layer 15\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.476562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.476562, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.386719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.386719, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.343750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.343750, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.320312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.320312, Val Loss=0.695312, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.304688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 390.69it/s, Train Loss=0.320312, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 15 to trained_probes/logistic/layer_15_probe.json\n",
      "\n",
      "Training meandiff probe on layer 15\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.56640625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 15 to trained_probes/meandiff/layer_15_probe.json\n",
      "\n",
      "Training linear probe on layer 15\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.023438]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.023438, Val Loss=0.585938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.796875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.796875, Val Loss=0.535156, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.769531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.769531, Val Loss=0.494141, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.378906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.378906, Val Loss=0.476562, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.453125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.453125, Val Loss=0.470703, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.511719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.511719, Val Loss=0.470703, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.507812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.507812, Val Loss=0.470703, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.503906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.503906, Val Loss=0.470703, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.500000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.500000, Val Loss=0.470703, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.498047]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 506.59it/s, Train Loss=0.500000, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 15 to trained_probes/linear/layer_15_probe.json\n",
      "\n",
      "Training pca probe on layer 15\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.2421875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 15 to trained_probes/pca/layer_15_probe.json\n",
      "\n",
      "Training logistic probe on layer 16\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.777344, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.503906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.503906, Val Loss=0.781250, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.355469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.355469, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.292969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.292969, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.271484]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.271484, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.257812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.257812, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.250000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.250000, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.245117]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 8 epochs\n",
      "Training:  70%|▋| 7/10 [00:00<00:00, 399.63it/s, Train Loss=0.250000, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 16 to trained_probes/logistic/layer_16_probe.json\n",
      "\n",
      "Training meandiff probe on layer 16\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.55859375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 16 to trained_probes/meandiff/layer_16_probe.json\n",
      "\n",
      "Training linear probe on layer 16\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.757812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.757812, Val Loss=1.117188, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.781250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.781250, Val Loss=1.132812, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.382812, Val Loss=1.125000, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.542969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.542969, Val Loss=1.125000, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.298828]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.298828, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.257812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 443.26it/s, Train Loss=0.298828, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 16 to trained_probes/linear/layer_16_probe.json\n",
      "\n",
      "Training pca probe on layer 16\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.3046875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 16 to trained_probes/pca/layer_16_probe.json\n",
      "Layers:  53%|██████████████████▌                | 17/32 [00:01<00:00, 16.68it/s]\n",
      "Training logistic probe on layer 17\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.593750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.593750, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.490234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.490234, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.431641]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.431641, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.394531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.394531, Val Loss=1.218750, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.373047]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 364.42it/s, Train Loss=0.394531, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 17 to trained_probes/logistic/layer_17_probe.json\n",
      "\n",
      "Training meandiff probe on layer 17\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.53515625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 17 to trained_probes/meandiff/layer_17_probe.json\n",
      "\n",
      "Training linear probe on layer 17\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.257812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.257812, Val Loss=0.566406, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.617188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.617188, Val Loss=0.605469, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.597656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.597656, Val Loss=0.601562, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.431641]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.431641, Val Loss=0.593750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.265625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.265625, Val Loss=0.585938, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.179688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 448.31it/s, Train Loss=0.265625, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 17 to trained_probes/linear/layer_17_probe.json\n",
      "\n",
      "Training pca probe on layer 17\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.3828125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 17 to trained_probes/pca/layer_17_probe.json\n",
      "\n",
      "Training logistic probe on layer 18\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.609375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.609375, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.523438]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.523438, Val Loss=1.203125, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.470703]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.470703, Val Loss=1.210938, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.437500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.437500, Val Loss=1.210938, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.417969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 373.58it/s, Train Loss=0.437500, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 18 to trained_probes/logistic/layer_18_probe.json\n",
      "\n",
      "Training meandiff probe on layer 18\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.50390625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 18 to trained_probes/meandiff/layer_18_probe.json\n",
      "\n",
      "Training linear probe on layer 18\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.218750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.218750, Val Loss=0.933594, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.046875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.046875, Val Loss=0.976562, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.437500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.437500, Val Loss=0.957031, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.792969]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.792969, Val Loss=0.925781, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.511719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.511719, Val Loss=0.894531, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.402344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.402344, Val Loss=0.886719, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.376953]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.376953, Val Loss=0.875000, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.369141]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.369141, Val Loss=0.875000, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.365234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.365234, Val Loss=0.875000, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.363281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 523.86it/s, Train Loss=0.363281, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 18 to trained_probes/linear/layer_18_probe.json\n",
      "\n",
      "Training pca probe on layer 18\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.59375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 18 to trained_probes/pca/layer_18_probe.json\n",
      "Layers:  59%|████████████████████▊              | 19/32 [00:01<00:00, 17.14it/s]\n",
      "Training logistic probe on layer 19\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.742188, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.359375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.359375, Val Loss=0.765625, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.314453]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.314453, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.289062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.289062, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.271484]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.271484, Val Loss=0.773438, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.261719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 358.05it/s, Train Loss=0.271484, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 19 to trained_probes/logistic/layer_19_probe.json\n",
      "\n",
      "Training meandiff probe on layer 19\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.486328125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 19 to trained_probes/meandiff/layer_19_probe.json\n",
      "\n",
      "Training linear probe on layer 19\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.312500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.312500, Val Loss=0.500000, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.015625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.015625, Val Loss=0.443359, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.367188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.367188, Val Loss=0.376953, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.531250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.531250, Val Loss=0.339844, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.333984]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.333984, Val Loss=0.310547, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.320312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.320312, Val Loss=0.302734, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.330078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.330078, Val Loss=0.300781, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.330078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.330078, Val Loss=0.298828, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.330078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.330078, Val Loss=0.298828, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.328125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 520.53it/s, Train Loss=0.328125, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 19 to trained_probes/linear/layer_19_probe.json\n",
      "\n",
      "Training pca probe on layer 19\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.8671875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 19 to trained_probes/pca/layer_19_probe.json\n",
      "\n",
      "Training logistic probe on layer 20\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.839844, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.511719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.511719, Val Loss=0.843750, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.361328]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.361328, Val Loss=0.835938, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.302734]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.302734, Val Loss=0.832031, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.277344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.277344, Val Loss=0.828125, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.265625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.265625, Val Loss=0.828125, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.253906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.253906, Val Loss=0.828125, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.249023]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.249023, Val Loss=0.832031, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.243164]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.243164, Val Loss=0.832031, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.241211]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 10 epochs\n",
      "Training:  90%|▉| 9/10 [00:00<00:00, 394.80it/s, Train Loss=0.243164, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 20 to trained_probes/logistic/layer_20_probe.json\n",
      "\n",
      "Training meandiff probe on layer 20\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.48046875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 20 to trained_probes/meandiff/layer_20_probe.json\n",
      "\n",
      "Training linear probe on layer 20\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.265625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.265625, Val Loss=0.396484, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.832031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.832031, Val Loss=0.433594, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.601562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.601562, Val Loss=0.414062, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.687500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.687500, Val Loss=0.392578, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.660156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.660156, Val Loss=0.380859, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.589844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.589844, Val Loss=0.373047, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.531250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.531250, Val Loss=0.371094, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.498047]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.498047, Val Loss=0.367188, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.484375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.484375, Val Loss=0.369141, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.476562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 533.50it/s, Train Loss=0.476562, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 20 to trained_probes/linear/layer_20_probe.json\n",
      "\n",
      "Training pca probe on layer 20\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 2.03125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 20 to trained_probes/pca/layer_20_probe.json\n",
      "Layers:  66%|██████████████████████▉            | 21/32 [00:01<00:00, 16.67it/s]\n",
      "Training logistic probe on layer 21\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.472656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.472656, Val Loss=0.722656, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=0.726562, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.339844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.339844, Val Loss=0.734375, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.314453]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.314453, Val Loss=0.734375, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 381.53it/s, Train Loss=0.314453, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 21 to trained_probes/logistic/layer_21_probe.json\n",
      "\n",
      "Training meandiff probe on layer 21\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.515625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 21 to trained_probes/meandiff/layer_21_probe.json\n",
      "\n",
      "Training linear probe on layer 21\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.281250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.281250, Val Loss=1.007812, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.812500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.812500, Val Loss=0.976562, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.406250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.406250, Val Loss=0.917969, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.550781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.550781, Val Loss=0.886719, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.322266]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.322266, Val Loss=0.867188, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.287109]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.287109, Val Loss=0.859375, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.296875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.296875, Val Loss=0.863281, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.300781, Val Loss=0.863281, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.300781, Val Loss=0.863281, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 575.30it/s, Train Loss=0.300781, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 21 to trained_probes/linear/layer_21_probe.json\n",
      "\n",
      "Training pca probe on layer 21\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 2.265625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 21 to trained_probes/pca/layer_21_probe.json\n",
      "\n",
      "Training logistic probe on layer 22\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.710938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.466797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.466797, Val Loss=0.730469, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=0.742188, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.343750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.343750, Val Loss=0.742188, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.316406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.316406, Val Loss=0.746094, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.304688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 393.34it/s, Train Loss=0.316406, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 22 to trained_probes/logistic/layer_22_probe.json\n",
      "\n",
      "Training meandiff probe on layer 22\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.54296875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 22 to trained_probes/meandiff/layer_22_probe.json\n",
      "\n",
      "Training linear probe on layer 22\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.296875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.296875, Val Loss=0.055176, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.718750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.718750, Val Loss=0.013367, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.570312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.570312, Val Loss=0.001938, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.734375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.734375, Val Loss=0.003326, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.570312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.570312, Val Loss=0.007080, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.570312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.570312, Val Loss=0.008484, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.574219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.574219, Val Loss=0.008789, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.574219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 8 epochs\n",
      "Training:  70%|▋| 7/10 [00:00<00:00, 496.85it/s, Train Loss=0.574219, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 22 to trained_probes/linear/layer_22_probe.json\n",
      "\n",
      "Training pca probe on layer 22\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 2.546875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 22 to trained_probes/pca/layer_22_probe.json\n",
      "Layers:  72%|█████████████████████████▏         | 23/32 [00:01<00:00, 17.15it/s]\n",
      "Training logistic probe on layer 23\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.941406, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.394531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.394531, Val Loss=0.992188, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.355469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.355469, Val Loss=0.984375, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.306641]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.306641, Val Loss=0.968750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.275391]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.275391, Val Loss=0.953125, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.255859]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 394.77it/s, Train Loss=0.275391, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 23 to trained_probes/logistic/layer_23_probe.json\n",
      "\n",
      "Training meandiff probe on layer 23\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.47265625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 23 to trained_probes/meandiff/layer_23_probe.json\n",
      "\n",
      "Training linear probe on layer 23\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.531250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.531250, Val Loss=0.018433, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.187500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.187500, Val Loss=0.002045, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.242188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.242188, Val Loss=0.006287, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.589844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.589844, Val Loss=0.013489, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.494141]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.494141, Val Loss=0.017944, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.507812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.507812, Val Loss=0.018188, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.507812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Training:  60%|▌| 6/10 [00:00<00:00, 486.99it/s, Train Loss=0.507812, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 23 to trained_probes/linear/layer_23_probe.json\n",
      "\n",
      "Training pca probe on layer 23\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 2.890625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 23 to trained_probes/pca/layer_23_probe.json\n",
      "\n",
      "Training logistic probe on layer 24\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.519531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.519531, Val Loss=0.972656, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.390625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.390625, Val Loss=1.031250, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.347656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.347656, Val Loss=1.015625, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.300781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.300781, Val Loss=1.000000, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.271484]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.271484, Val Loss=0.992188, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.253906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 398.27it/s, Train Loss=0.271484, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 24 to trained_probes/logistic/layer_24_probe.json\n",
      "\n",
      "Training meandiff probe on layer 24\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.435546875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 24 to trained_probes/meandiff/layer_24_probe.json\n",
      "\n",
      "Training linear probe on layer 24\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.226562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.226562, Val Loss=0.026123, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.609375]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.609375, Val Loss=0.004395, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.195312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.195312, Val Loss=0.005096, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.820312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.820312, Val Loss=0.007935, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.574219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.574219, Val Loss=0.011597, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.433594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.433594, Val Loss=0.015015, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.367188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Training:  60%|▌| 6/10 [00:00<00:00, 494.58it/s, Train Loss=0.433594, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 24 to trained_probes/linear/layer_24_probe.json\n",
      "\n",
      "Training pca probe on layer 24\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 3.109375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 24 to trained_probes/pca/layer_24_probe.json\n",
      "Layers:  78%|███████████████████████████▎       | 25/32 [00:01<00:00, 17.83it/s]\n",
      "Training logistic probe on layer 25\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.460938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.730469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.730469, Val Loss=1.445312, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.582031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.582031, Val Loss=1.406250, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.490234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.490234, Val Loss=1.359375, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.447266]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.447266, Val Loss=1.343750, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.431641]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.431641, Val Loss=1.328125, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.423828]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.423828, Val Loss=1.320312, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.416016]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.416016, Val Loss=1.320312, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.412109]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.412109, Val Loss=1.312500, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.412109]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 474.25it/s, Train Loss=0.412109, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 25 to trained_probes/logistic/layer_25_probe.json\n",
      "\n",
      "Training meandiff probe on layer 25\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.5\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 25 to trained_probes/meandiff/layer_25_probe.json\n",
      "\n",
      "Training linear probe on layer 25\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.156250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.156250, Val Loss=0.585938, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.839844]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.839844, Val Loss=0.808594, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.242188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.242188, Val Loss=0.832031, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.007812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.007812, Val Loss=0.804688, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.722656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.722656, Val Loss=0.777344, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.535156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 488.10it/s, Train Loss=0.722656, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 25 to trained_probes/linear/layer_25_probe.json\n",
      "\n",
      "Training pca probe on layer 25\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 3.34375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 25 to trained_probes/pca/layer_25_probe.json\n",
      "\n",
      "Training logistic probe on layer 26\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=1.250000, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.539062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.539062, Val Loss=1.296875, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.435547]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.435547, Val Loss=1.312500, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=1.320312, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.347656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.347656, Val Loss=1.328125, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.328125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 386.99it/s, Train Loss=0.347656, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 26 to trained_probes/logistic/layer_26_probe.json\n",
      "\n",
      "Training meandiff probe on layer 26\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.486328125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 26 to trained_probes/meandiff/layer_26_probe.json\n",
      "\n",
      "Training linear probe on layer 26\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.281250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.281250, Val Loss=0.084961, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.046875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.046875, Val Loss=0.048584, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.570312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.570312, Val Loss=0.027832, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.015625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.015625, Val Loss=0.025635, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.769531]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.769531, Val Loss=0.029907, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.687500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.687500, Val Loss=0.032715, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.664062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.664062, Val Loss=0.033936, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.656250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.656250, Val Loss=0.034668, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.652344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 9 epochs\n",
      "Training:  80%|▊| 8/10 [00:00<00:00, 469.13it/s, Train Loss=0.656250, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 26 to trained_probes/linear/layer_26_probe.json\n",
      "\n",
      "Training pca probe on layer 26\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 3.8125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 26 to trained_probes/pca/layer_26_probe.json\n",
      "Layers:  84%|█████████████████████████████▌     | 27/32 [00:01<00:00, 17.74it/s]\n",
      "Training logistic probe on layer 27\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=0.996094, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.486328]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.486328, Val Loss=1.046875, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.365234]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.365234, Val Loss=1.054688, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.312500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.312500, Val Loss=1.054688, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.289062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.289062, Val Loss=1.054688, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.277344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 365.10it/s, Train Loss=0.289062, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 27 to trained_probes/logistic/layer_27_probe.json\n",
      "\n",
      "Training meandiff probe on layer 27\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.451171875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 27 to trained_probes/meandiff/layer_27_probe.json\n",
      "\n",
      "Training linear probe on layer 27\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.546875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.546875, Val Loss=0.394531, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.296875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.296875, Val Loss=0.431641, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.453125]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.453125, Val Loss=0.375000, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.093750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.093750, Val Loss=0.328125, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.804688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.804688, Val Loss=0.300781, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.640625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.640625, Val Loss=0.292969, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.582031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.582031, Val Loss=0.289062, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.550781]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.550781, Val Loss=0.287109, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.539062]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.539062, Val Loss=0.289062, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.535156]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 527.46it/s, Train Loss=0.535156, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 27 to trained_probes/linear/layer_27_probe.json\n",
      "\n",
      "Training pca probe on layer 27\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 4.0625\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 27 to trained_probes/pca/layer_27_probe.json\n",
      "\n",
      "Training logistic probe on layer 28\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=1.015625, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.503906]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.503906, Val Loss=1.078125, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=1.085938, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.330078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.330078, Val Loss=1.093750, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.308594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.308594, Val Loss=1.101562, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.298828]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 358.40it/s, Train Loss=0.308594, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 28 to trained_probes/logistic/layer_28_probe.json\n",
      "\n",
      "Training meandiff probe on layer 28\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 0.75\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 28 to trained_probes/meandiff/layer_28_probe.json\n",
      "\n",
      "Training linear probe on layer 28\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.015625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.015625, Val Loss=0.175781, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=3.125000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=3.125000, Val Loss=0.098145, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.281250]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.281250, Val Loss=0.086426, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.437500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.437500, Val Loss=0.099609, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.239258]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.239258, Val Loss=0.117188, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.229492]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.229492, Val Loss=0.125000, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.238281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.238281, Val Loss=0.128906, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.239258]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 8 epochs\n",
      "Training:  70%|▋| 7/10 [00:00<00:00, 463.20it/s, Train Loss=0.238281, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 28 to trained_probes/linear/layer_28_probe.json\n",
      "\n",
      "Training pca probe on layer 28\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 4.4375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 28 to trained_probes/pca/layer_28_probe.json\n",
      "Layers:  91%|███████████████████████████████▋   | 29/32 [00:01<00:00, 17.60it/s]\n",
      "Training logistic probe on layer 29\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=1.031250, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.558594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.558594, Val Loss=1.070312, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.443359]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.443359, Val Loss=1.078125, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.396484]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.396484, Val Loss=1.078125, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=1.078125, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.375000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 367.91it/s, Train Loss=0.382812, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 29 to trained_probes/logistic/layer_29_probe.json\n",
      "\n",
      "Training meandiff probe on layer 29\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.09375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 29 to trained_probes/meandiff/layer_29_probe.json\n",
      "\n",
      "Training linear probe on layer 29\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.062500]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.062500, Val Loss=0.945312, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.843750]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.843750, Val Loss=1.250000, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.070312]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.070312, Val Loss=1.539062, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.382812]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.382812, Val Loss=1.750000, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.277344]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.277344, Val Loss=1.906250, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.308594]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 441.93it/s, Train Loss=0.277344, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 29 to trained_probes/linear/layer_29_probe.json\n",
      "\n",
      "Training pca probe on layer 29\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 4.75\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 29 to trained_probes/pca/layer_29_probe.json\n",
      "\n",
      "Training logistic probe on layer 30\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.691406]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.691406, Val Loss=1.046875, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.460938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.460938, Val Loss=1.117188, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.390625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.390625, Val Loss=1.132812, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.357422]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.357422, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.337891]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.337891, Val Loss=1.140625, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.326172]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 378.39it/s, Train Loss=0.337891, Val Loss=1\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 30 to trained_probes/logistic/layer_30_probe.json\n",
      "\n",
      "Training meandiff probe on layer 30\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.078125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 30 to trained_probes/meandiff/layer_30_probe.json\n",
      "\n",
      "Training linear probe on layer 30\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=2.875000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=2.875000, Val Loss=1.398438, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.699219]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.699219, Val Loss=2.015625, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.355469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.355469, Val Loss=2.156250, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.472656]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.472656, Val Loss=2.203125, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.554688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.554688, Val Loss=2.171875, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.554688]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 452.79it/s, Train Loss=0.554688, Val Loss=2\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 30 to trained_probes/linear/layer_30_probe.json\n",
      "\n",
      "Training pca probe on layer 30\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 5.21875\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 30 to trained_probes/pca/layer_30_probe.json\n",
      "Layers:  97%|█████████████████████████████████▉ | 31/32 [00:01<00:00, 18.14it/s]\n",
      "Training logistic probe on layer 31\n",
      "[DEBUG get_probe_config] Creating config for logistic with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG main] Created logistic probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LogisticProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG _calculate_pos_weights] input dtype: torch.int64, output dtype: torch.float32\n",
      "[DEBUG train] Pos weights set to dtype: torch.bfloat16\n",
      "[DEBUG train] Loss function: BCEWithLogitsLoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.863281]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.863281, Val Loss=0.984375, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.601562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.601562, Val Loss=0.929688, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.546875]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.546875, Val Loss=0.906250, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.511719]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.511719, Val Loss=0.898438, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.492188]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.492188, Val Loss=0.890625, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.478516]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.478516, Val Loss=0.882812, \u001b[A\n",
      "\n",
      "Epoch 7/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 7/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.466797]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.466797, Val Loss=0.882812, \u001b[A\n",
      "\n",
      "Epoch 8/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 8/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.460938]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.460938, Val Loss=0.882812, \u001b[A\n",
      "\n",
      "Epoch 9/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 9/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.458984]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.458984, Val Loss=0.882812, \u001b[A\n",
      "\n",
      "Epoch 10/10:   0%|                                        | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([8, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.bias - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 10/10:   0%|                         | 0/1 [00:00<?, ?it/s, Loss=0.457031]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([2, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training: 100%|█| 10/10 [00:00<00:00, 452.68it/s, Train Loss=0.457031, Val Loss=\u001b[A\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved logistic probe for layer 31 to trained_probes/logistic/layer_31_probe.json\n",
      "\n",
      "Training meandiff probe on layer 31\n",
      "[DEBUG get_probe_config] Creating config for meandiff with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created meandiff probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG MeanDifferenceProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG MeanDifferenceProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] After conversion - x dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction dtype: torch.bfloat16\n",
      "[DEBUG MeanDifferenceProbe.fit] Initial direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 1.6953125\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved meandiff probe for layer 31 to trained_probes/meandiff/layer_31_probe.json\n",
      "\n",
      "Training linear probe on layer 31\n",
      "[DEBUG get_probe_config] Creating config for linear with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG main] Created linear probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe linear weight dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG SupervisedProbeTrainer.__init__] Initialized with train_ratio: 0.8\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Total examples: 10, Training examples: 8\n",
      "[DEBUG prepare_supervised_data] Final X_train_split dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Final y_train_split dtype: torch.int64\n",
      "[DEBUG train] Model class: LinearProbe, is_multi_class: False\n",
      "[DEBUG train] Model dtype: torch.bfloat16\n",
      "[DEBUG _create_optimizer] Creating Adam optimizer\n",
      "[DEBUG _create_optimizer] Parameter dtypes: {torch.bfloat16}\n",
      "[DEBUG train] Combined labels for class weights - shape: torch.Size([8, 1]), dtype: torch.int64\n",
      "[DEBUG train] Setting up loss function for dtype: torch.bfloat16\n",
      "[DEBUG train] Linear loss type: mse\n",
      "Warning: Class imbalance handling enabled, but may not be effective for LinearProbe with loss type 'mse'.\n",
      "[DEBUG train] Loss function: MSELoss\n",
      "\n",
      "Training:   0%|                                          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Epoch 1/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 1/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.765625]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.765625, Val Loss=0.283203, \u001b[A\n",
      "\n",
      "Epoch 2/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 2/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=1.101562]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=1.101562, Val Loss=0.341797, \u001b[A\n",
      "\n",
      "Epoch 3/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 3/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.855469]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.855469, Val Loss=0.492188, \u001b[A\n",
      "\n",
      "Epoch 4/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 4/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.625000]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.625000, Val Loss=0.574219, \u001b[A\n",
      "\n",
      "Epoch 5/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 5/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.455078]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Training:   0%| | 0/10 [00:00<?, ?it/s, Train Loss=0.455078, Val Loss=0.593750, \u001b[A\n",
      "\n",
      "Epoch 6/10:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A[DEBUG train_epoch] First batch - x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG train_epoch] Model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss function: MSELoss\n",
      "[DEBUG train_epoch] After moving to device - x dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Forward pass output dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Target for loss dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Loss computation dtype: torch.bfloat16\n",
      "[DEBUG train_epoch] Gradient for linear.weight - dtype: torch.bfloat16\n",
      "\n",
      "\n",
      "Epoch 6/10:   0%|                          | 0/1 [00:00<?, ?it/s, Loss=0.337891]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A[DEBUG validate] Validation batch - orig x dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG validate] Converted targets to model dtype: torch.bfloat16\n",
      "[DEBUG validate] Validation output dtype: torch.bfloat16\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Training:  50%|▌| 5/10 [00:00<00:00, 451.32it/s, Train Loss=0.455078, Val Loss=0\n",
      "Unscaling probe direction...\n",
      "[DEBUG train] Learned direction dtype before unscaling: torch.bfloat16\n",
      "[DEBUG train] Feature std dtype for unscaling: torch.bfloat16\n",
      "[DEBUG train] Unscaled case 1: shape torch.Size([1, 4096])\n",
      "[DEBUG train] Unscaled direction dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([1, 4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved linear probe for layer 31 to trained_probes/linear/layer_31_probe.json\n",
      "\n",
      "Training pca probe on layer 31\n",
      "[DEBUG get_probe_config] Creating config for pca with dtype_str: bfloat16\n",
      "[DEBUG get_probe_config] Input torch dtype: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "[DEBUG main] Created pca probe\n",
      "[DEBUG main] Probe dtype attribute: torch.bfloat16\n",
      "[DEBUG main] Probe direction_vector dtype: torch.bfloat16\n",
      "[DEBUG BaseProbeTrainer.__init__] Trainer initialized with device: cuda\n",
      "[DEBUG BaseProbeTrainer.__init__] standardize_activations: True\n",
      "[DEBUG DirectionalProbeTrainer.__init__] Initialized\n",
      "Examining position key: LIE_SPAN\n",
      "[DEBUG prepare_data] Raw X dtype from activation store: torch.bfloat16\n",
      "[DEBUG prepare_data] Raw y dtype from activation store: torch.int64\n",
      "[DEBUG prepare_data] X shape: torch.Size([10, 4096]), y shape: torch.Size([10])\n",
      "[DEBUG prepare_data] Applying standardization\n",
      "[DEBUG prepare_data] Feature mean dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] Feature std dtype: torch.bfloat16\n",
      "[DEBUG prepare_data] After standardization - X_train dtype: torch.bfloat16\n",
      "[DEBUG prepare_supervised_data] Created dataloader with batch size: 10\n",
      "[DEBUG prepare_supervised_data] X dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Model class: PCAProbe\n",
      "[DEBUG DirectionalProbeTrainer.train] Model dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loaded data - x_train dtype: torch.bfloat16, y dtype: torch.int64\n",
      "[DEBUG DirectionalProbeTrainer.train] Data moved to device cuda\n",
      "[DEBUG DirectionalProbeTrainer.train] Calling probe.fit() method\n",
      "[DEBUG PCAProbe.fit] Input x dtype: torch.bfloat16, shape: torch.Size([10, 4096])\n",
      "[DEBUG PCAProbe.fit] self.dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Converting from bfloat16 to float32 for NumPy\n",
      "[DEBUG PCAProbe.fit] NumPy array dtype: float32\n",
      "[DEBUG PCAProbe.fit] Direction dtype: torch.bfloat16\n",
      "[DEBUG PCAProbe.fit] Direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] After fit - initial_direction shape: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaling directional probe direction...\n",
      "[DEBUG DirectionalProbeTrainer.train] feature_std dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Unscaled with case 1 (same shape)\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction dtype after unscaling: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Final direction shape after unscaling: torch.Size([4096])\n",
      "[DEBUG DirectionalProbeTrainer.train] Setting final direction in probe\n",
      "[DEBUG DirectionalProbeTrainer.train] Computing metrics with original data\n",
      "[DEBUG DirectionalProbeTrainer.train] Prediction dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Target dtype for loss: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Squeezed y_target shape: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Using BCEWithLogitsLoss for binary\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss function: BCEWithLogitsLoss\n",
      "[DEBUG DirectionalProbeTrainer.train] Final shapes - preds: torch.Size([10]), y_target: torch.Size([10])\n",
      "[DEBUG DirectionalProbeTrainer.train] Final dtypes - preds: torch.bfloat16, y_target: torch.bfloat16\n",
      "[DEBUG DirectionalProbeTrainer.train] Loss calculated: 5.375\n",
      "[DEBUG save_json] Raw vector dtype: torch.bfloat16\n",
      "[DEBUG save_json] Raw vector shape: torch.Size([4096])\n",
      "[DEBUG save_json] Converting from bfloat16 to float32 for JSON serialization\n",
      "[DEBUG save_json] Numpy array dtype: float32\n",
      "Saved pca probe for layer 31 to trained_probes/pca/layer_31_probe.json\n",
      "Layers: 100%|███████████████████████████████████| 32/32 [00:02<00:00, 15.86it/s]\n",
      "\n",
      "Training complete. Summary saved to trained_probes/training_summary.json\n"
     ]
    }
   ],
   "source": [
    "!python scripts/probe_training.py --model_name meta-llama/Llama-3.1-8B-Instruct --train_dataset_dir data/two_truths_one_lie.json --probe_types logistic meandiff linear pca --layers all --probe_save_dir ./trained_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f293e5-118c-4426-b784-cd876e127228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation dataset from data/two_truths_one_lie.json\n",
      "Loading model meta-llama/Llama-3.1-8B-Instruct\n",
      "Loading checkpoint shards: 100%|█████████████████| 4/4 [00:00<00:00, 107.26it/s]\n",
      "Loaded pretrained model meta-llama/Llama-3.1-8B-Instruct into HookedTransformer\n",
      "\n",
      "Evaluating logistic probes\n",
      "logistic probes:   0%|                                   | 0/32 [00:00<?, ?it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:   3%|▊                          | 1/32 [00:00<00:21,  1.45it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:   6%|█▋                         | 2/32 [00:01<00:18,  1.60it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:   9%|██▌                        | 3/32 [00:01<00:17,  1.66it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  12%|███▍                       | 4/32 [00:02<00:16,  1.68it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  16%|████▏                      | 5/32 [00:03<00:15,  1.70it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  19%|█████                      | 6/32 [00:03<00:15,  1.71it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:  22%|█████▉                     | 7/32 [00:04<00:14,  1.71it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  25%|██████▊                    | 8/32 [00:04<00:13,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  28%|███████▌                   | 9/32 [00:05<00:13,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  31%|████████▏                 | 10/32 [00:05<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  34%|████████▉                 | 11/32 [00:06<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:  38%|█████████▊                | 12/32 [00:07<00:11,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  41%|██████████▌               | 13/32 [00:07<00:11,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  44%|███████████▍              | 14/32 [00:08<00:10,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  47%|████████████▏             | 15/32 [00:08<00:09,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  50%|█████████████             | 16/32 [00:09<00:09,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  53%|█████████████▊            | 17/32 [00:09<00:08,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  56%|██████████████▋           | 18/32 [00:10<00:08,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  59%|███████████████▍          | 19/32 [00:11<00:07,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  62%|████████████████▎         | 20/32 [00:11<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  66%|█████████████████         | 21/32 [00:12<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  69%|█████████████████▉        | 22/32 [00:12<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  72%|██████████████████▋       | 23/32 [00:13<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  75%|███████████████████▌      | 24/32 [00:14<00:04,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  78%|████████████████████▎     | 25/32 [00:14<00:04,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  81%|█████████████████████▏    | 26/32 [00:15<00:03,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:  84%|█████████████████████▉    | 27/32 [00:15<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  88%|██████████████████████▊   | 28/32 [00:16<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:  91%|███████████████████████▌  | 29/32 [00:16<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes:  94%|████████████████████████▍ | 30/32 [00:17<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "logistic probes:  97%|█████████████████████████▏| 31/32 [00:18<00:00,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LogisticProbe\n",
      "[DEBUG LogisticProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] Linear layer bias dtype: torch.float32\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.__init__] After dtype conversion - bias dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Input x dtype: torch.bfloat16, shape: torch.Size([1, 4096])\n",
      "[DEBUG LogisticProbe.forward] Linear weight dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] self.dtype: torch.bfloat16\n",
      "[DEBUG LogisticProbe.forward] Output dtype: torch.bfloat16\n",
      "logistic probes: 100%|██████████████████████████| 32/32 [00:18<00:00,  1.71it/s]\n",
      "\n",
      "Evaluating meandiff probes\n",
      "meandiff probes:   0%|                                   | 0/32 [00:00<?, ?it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "meandiff probes:   3%|▊                          | 1/32 [00:00<00:17,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:   6%|█▋                         | 2/32 [00:01<00:17,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:   9%|██▌                        | 3/32 [00:01<00:16,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  12%|███▍                       | 4/32 [00:02<00:16,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  16%|████▏                      | 5/32 [00:02<00:15,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  19%|█████                      | 6/32 [00:03<00:15,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  22%|█████▉                     | 7/32 [00:04<00:14,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  25%|██████▊                    | 8/32 [00:04<00:13,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  28%|███████▌                   | 9/32 [00:05<00:13,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  31%|████████▏                 | 10/32 [00:05<00:12,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  34%|████████▉                 | 11/32 [00:06<00:12,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "meandiff probes:  38%|█████████▊                | 12/32 [00:06<00:11,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  41%|██████████▌               | 13/32 [00:07<00:10,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  44%|███████████▍              | 14/32 [00:08<00:10,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  47%|████████████▏             | 15/32 [00:08<00:09,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  50%|█████████████             | 16/32 [00:09<00:09,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  53%|█████████████▊            | 17/32 [00:09<00:08,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  56%|██████████████▋           | 18/32 [00:10<00:08,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  59%|███████████████▍          | 19/32 [00:11<00:07,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  62%|████████████████▎         | 20/32 [00:11<00:06,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  66%|█████████████████         | 21/32 [00:12<00:06,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  69%|█████████████████▉        | 22/32 [00:12<00:05,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  72%|██████████████████▋       | 23/32 [00:13<00:05,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  75%|███████████████████▌      | 24/32 [00:13<00:04,  1.72it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  78%|████████████████████▎     | 25/32 [00:14<00:04,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  81%|█████████████████████▏    | 26/32 [00:15<00:03,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  84%|█████████████████████▉    | 27/32 [00:15<00:02,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  88%|██████████████████████▊   | 28/32 [00:16<00:02,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "meandiff probes:  91%|███████████████████████▌  | 29/32 [00:16<00:01,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "meandiff probes:  94%|████████████████████████▍ | 30/32 [00:17<00:01,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes:  97%|█████████████████████████▏| 31/32 [00:17<00:00,  1.73it/s]Warning: Could not determine specific config class for MeanDifferenceProbe. Using base ProbeConfig.\n",
      "[DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: MeanDifferenceProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "meandiff probes: 100%|██████████████████████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "\n",
      "Evaluating linear probes\n",
      "linear probes:   0%|                                     | 0/32 [00:00<?, ?it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:   3%|▉                            | 1/32 [00:00<00:17,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:   6%|█▊                           | 2/32 [00:01<00:17,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:   9%|██▋                          | 3/32 [00:01<00:16,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  12%|███▋                         | 4/32 [00:02<00:16,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  16%|████▌                        | 5/32 [00:02<00:15,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  19%|█████▍                       | 6/32 [00:03<00:15,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  22%|██████▎                      | 7/32 [00:04<00:14,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  25%|███████▎                     | 8/32 [00:04<00:13,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  28%|████████▏                    | 9/32 [00:05<00:13,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  31%|████████▊                   | 10/32 [00:05<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  34%|█████████▋                  | 11/32 [00:06<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  38%|██████████▌                 | 12/32 [00:06<00:11,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  41%|███████████▍                | 13/32 [00:07<00:11,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  44%|████████████▎               | 14/32 [00:08<00:10,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  47%|█████████████▏              | 15/32 [00:08<00:09,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  50%|██████████████              | 16/32 [00:09<00:09,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  53%|██████████████▉             | 17/32 [00:09<00:08,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  56%|███████████████▊            | 18/32 [00:10<00:08,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  59%|████████████████▋           | 19/32 [00:11<00:07,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  62%|█████████████████▌          | 20/32 [00:11<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  66%|██████████████████▍         | 21/32 [00:12<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  69%|███████████████████▎        | 22/32 [00:12<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  72%|████████████████████▏       | 23/32 [00:13<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  75%|█████████████████████       | 24/32 [00:13<00:04,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  78%|█████████████████████▉      | 25/32 [00:14<00:04,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  81%|██████████████████████▊     | 26/32 [00:15<00:03,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  84%|███████████████████████▋    | 27/32 [00:15<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  88%|████████████████████████▌   | 28/32 [00:16<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes:  91%|█████████████████████████▍  | 29/32 [00:16<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  94%|██████████████████████████▎ | 30/32 [00:17<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "linear probes:  97%|███████████████████████████▏| 31/32 [00:17<00:00,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: LinearProbe\n",
      "[DEBUG LinearProbe.__init__] Before Linear creation - self.dtype: torch.bfloat16\n",
      "[DEBUG LinearProbe.__init__] Linear layer weight dtype: torch.float32\n",
      "[DEBUG LinearProbe.__init__] After dtype conversion - weight dtype: torch.bfloat16\n",
      "linear probes: 100%|████████████████████████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "\n",
      "Evaluating pca probes\n",
      "pca probes:   0%|                                        | 0/32 [00:00<?, ?it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:   3%|█                               | 1/32 [00:00<00:18,  1.70it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:   6%|██                              | 2/32 [00:01<00:17,  1.71it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:   9%|███                             | 3/32 [00:01<00:16,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  12%|████                            | 4/32 [00:02<00:16,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  16%|█████                           | 5/32 [00:02<00:15,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  19%|██████                          | 6/32 [00:03<00:15,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  22%|███████                         | 7/32 [00:04<00:14,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  25%|████████                        | 8/32 [00:04<00:13,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  28%|█████████                       | 9/32 [00:05<00:13,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  31%|█████████▋                     | 10/32 [00:05<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  34%|██████████▋                    | 11/32 [00:06<00:12,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  38%|███████████▋                   | 12/32 [00:06<00:11,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  41%|████████████▌                  | 13/32 [00:07<00:11,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  44%|█████████████▌                 | 14/32 [00:08<00:10,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  47%|██████████████▌                | 15/32 [00:08<00:09,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  50%|███████████████▌               | 16/32 [00:09<00:09,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  53%|████████████████▍              | 17/32 [00:09<00:08,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  56%|█████████████████▍             | 18/32 [00:10<00:08,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  59%|██████████████████▍            | 19/32 [00:11<00:07,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  62%|███████████████████▍           | 20/32 [00:11<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  66%|████████████████████▎          | 21/32 [00:12<00:06,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  69%|█████████████████████▎         | 22/32 [00:12<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  72%|██████████████████████▎        | 23/32 [00:13<00:05,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  75%|███████████████████████▎       | 24/32 [00:13<00:04,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  78%|████████████████████████▏      | 25/32 [00:14<00:04,  1.73it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  81%|█████████████████████████▏     | 26/32 [00:15<00:03,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  84%|██████████████████████████▏    | 27/32 [00:15<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  88%|███████████████████████████▏   | 28/32 [00:16<00:02,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  91%|████████████████████████████   | 29/32 [00:16<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes:  94%|█████████████████████████████  | 30/32 [00:17<00:01,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "pca probes:  97%|██████████████████████████████ | 31/32 [00:17<00:00,  1.72it/s][DEBUG BaseProbe.__init__] Config dtype string: bfloat16\n",
      "[DEBUG BaseProbe.__init__] Set self.dtype to: torch.bfloat16\n",
      "[DEBUG BaseProbe.__init__] Probe class: PCAProbe\n",
      "[DEBUG DirectionalProbe.__init__] self.dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] Creating direction_vector with dtype: torch.bfloat16\n",
      "[DEBUG DirectionalProbe.__init__] direction_vector dtype after creation: torch.bfloat16\n",
      "pca probes: 100%|███████████████████████████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "\n",
      "Evaluating .ipynb_checkpoints probes\n",
      ".ipynb_checkpoints probes: 0it [00:00, ?it/s]\n",
      "Saved linear results to results/linear_results.csv\n",
      "Saved pca results to results/pca_results.csv\n",
      "Saved logistic results to results/logistic_results.csv\n",
      "Saved meandiff results to results/meandiff_results.csv\n",
      "\n",
      "Evaluation complete. Results saved to results\n",
      "\n",
      "Best performing configurations:\n",
      "linear: Layer 29 (AUROC: 0.9600)\n",
      "pca: Layer 12 (AUROC: 0.7400)\n",
      "logistic: Layer 14 (AUROC: 0.9200)\n",
      "meandiff: Layer 13 (AUROC: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/probe_eval.py --model_name meta-llama/Llama-3.1-8B-Instruct --eval_dataset_dir data/two_truths_one_lie.json --probe_dir ./trained_probes --results_save_dir ./results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
