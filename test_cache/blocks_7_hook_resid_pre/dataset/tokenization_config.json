{"tokenizer_name": "gpt2", "tokenizer_kwargs": {"padding": true, "max_length": 64, "add_special_tokens": true}, "vocab_size": 50257, "pad_token_id": 50256, "eos_token_id": 50256, "bos_token_id": 50256, "padding_side": "right"}